{"./":{"url":"./","title":"Introduction","keywords":"","body":"tech talk 技术笔记及分享 书籍地址 "},"git/user.html":{"url":"git/user.html","title":"I. 为不同的git项目配置各自独立的用户","keywords":"","body":"为不同的git项目配置各自独立的用户 我们在自己的开发机上往往会管理多个git仓库，可能有些git仓库是属于自己的私人github账号，有些是属于公司的个人gitlab开发账号，这样就需要为不同的仓库配置不同的用户 方法1: config命令 在git仓库目录下执行 $ git config user.name 'xxx' $ git config user.email 'xxx' ps: 配置全局git用户的方法： $ git config --global user.name 'xxx' $ git config --global user.email 'xxx' 方法2: 修改git配置 git仓库目录下，在.git/config文件中添加以下内容 [user] name = xxx email = xxx "},"git/gitbook.html":{"url":"git/gitbook.html","title":"II. gitbook的使用","keywords":"","body":"gitbook的使用 安装gitbook mac下安装gitbook 目录结构 gitbook项目的目录结构如下: - SUMMARY.md - README.md - book.json - _book/ - node_modules/ 其中，我们需要首先创建的是SUMMARY.md(书籍目录) 和 README.md(书籍介绍) SUMMARY.md 书籍目录是gitbook的基础，可以有层级结构，使用markdown写法 # Summary * [git相关](git.md) * [I. 为不同的git项目配置各自独立的用户](./git/user.md) * [II. gitbook的使用](./git/gitbook.md) ... 编译和预览书籍 书籍目录和目录中链接的内容(*.md)文件编辑完成后，执行gitbook serve即可完成书籍的编译 $ gitbook serve Live reload server started on port: 35729 Press CTRL+C to quit ... info: 7 plugins are installed info: loading plugin \"livereload\"... OK info: loading plugin \"highlight\"... OK info: loading plugin \"search\"... OK info: loading plugin \"lunr\"... OK info: loading plugin \"sharing\"... OK info: loading plugin \"fontsettings\"... OK info: loading plugin \"theme-default\"... OK info: found 4 pages info: found 1 asset files info: >> generation finished with success in 0.7s ! Starting server ... Serving book on http://localhost:4000 按照提示信息，访问本机4000端口，即可看到预览结果 执行完成后，会在项目下自动生成书籍的文件目录_book/ 默认的\"Introduction\"页面就是README.md 配置书籍 book.json 在项目目录下新建book.json文件，可以进行书籍配置；book.json示例如下: { \"author\": \"mania_fish\", \"description\": \"How to build effective golang project\", \"extension\": null, \"generator\": \"site\", \"links\": { \"sharing\": { \"all\": null, \"facebook\": null, \"google\": null, \"twitter\": null, \"weibo\": null }, \"sidebar\": { \"mania_fish's github\": \"https://github.com/maniafish\" } }, \"output\": null, \"pdf\": { \"fontSize\": 12, \"footerTemplate\": null, \"headerTemplate\": null, \"margin\": { \"bottom\": 36, \"left\": 62, \"right\": 62, \"top\": 36 }, \"pageNumbers\": false, \"paperSize\": \"a4\" }, \"plugins\": [ \"-lunr\", \"-search\", \"search-pro\", \"anchor-navigation-ex\", \"splitter\", \"sectionx\", \"prism\", \"-highlight\", \"prism-themes\" ], \"title\": \"real effective go\", \"variables\": {}, \"pluginsConfig\": { \"anchor-navigation-ex\": { \"isShowTocTitleIcon\": true, \"tocLevel2Icon\": \"fa fa-hand-o-right\", \"tocLevel3Icon\": \"fa fa-hand-o-right\", \"tocLevel4Icon\": \"fa fa-hand-o-right\" }, \"prism\": { \"css\": [ \"prism-themes/themes/prism-base16-ateliersulphurpool.light.css\" ], \"lang\": { \"flow\": \"typescript\" }, \"ignore\": [ \"mermaid\", \"eval-js\" ] } } } 官方配置字段说明 插件plugins \"-lunr\", \"-search\", \"search-pro\": 禁用掉gitbook默认的搜索插件，使用search-pro, 支持中文搜索 \"anchor-navigation-ex\": 页面章节锚点 由于前三级的标题会被自动锚点并编号，为了文章标题不被锚点，我们采用如下格式: #### 标题 --- # 文章第一节 ## 文章第一节的第一小节 效果如下: \"-highlight\", \"prism\", \"prism-themes\": 禁用原代码高亮功能，使用prism代码主题 更多插件，详见官网 载入配置 在项目目录下执行gitbook install即可安装配置插件；安装完成后，项目下会出现一个node_modules/目录 然后执行gitbook serve即可看到配置完成后的主页 集成发布到github pages 添加git仓库 在项目目录下执行git init新建git仓库 git remote add origin 添加github仓库 touch .gitignore 并且在里面添加以下内容 *~ *.swp *.DS_Store _book/ node_modules/ git add . 添加文件到git版本控制 git commit -m 'git init' 提交变动 git push origin master 推送分支 发布github pages git clone 在下执行git checkout --orphan gh-pages 创建孤儿分支gh-pages git rm --cached -r . 删除暂存区目录 git clean -df 删除未track的目录，不影响.gitignore中的文件 touch .gitignore 并且在里面添加以下内容 *~ *.swp *.DS_Store cp -rf /_book/* ./ 将生成的书籍html内容copy出来 git add . git commit -m 'publish book' git push origin gh-pages 推送完成后，进入github仓库主页，会多出一个environment图标 点击environment图标后，进入如下页面 点击view deployment图标，即可看到发布的gitbook书籍 后续更新github pages 只需执行上述6 - 9 步即可 参考链接： gitbook简明教程 "},"linux/vim_replace.html":{"url":"linux/vim_replace.html","title":"I. vim替换特殊符号","keywords":"","body":"vim替换特殊符号 替换特殊字符为实际控制符 替换换行符 :%s/\\\\r\\\\n/\\r/g 替换tab :%s/\\\\t/\\t/g ps: 设置tab为四个空格的方法 :set tabstop=4 :set expandtab 替换跨平台的控制符 替换^M换行符 :%s/[Ctrl-v][Ctrl-M]/\\r/g 替换^I制表符 :%s/[Ctrl-v][Ctrl-I]/\\t/g 替换首尾字符 第7-15行开头插入* :7,15s/^/* /g 第7-15行末尾插入* :7,15s/$/ */g "},"linux/vim_paste.html":{"url":"linux/vim_paste.html","title":"II. vim剪贴板的使用","keywords":"","body":"vim剪贴板的使用 vim复制命令 常用方法 复制当前行: yy 复制自选区域: 先 v 进入visual模式，用kjhl控制上下左右选择好要复制的区域，然后 y 复制选中区域 如果要按行选择的话，则使用[Shift-v]进入visual line模式即可 黏贴: 光标后黏贴: p 光标前黏贴: [Shift-p] 其他用法 nyy：n表示大于1的数字，复制n行 yw：从光标处复制至一个单子/单词的末尾，包括空格 ye：从光标处复制至一个单子/单词的末尾，不包括空格 y$：从当前光标复制到行末 y0：从当前光标位置（不包括光标位置）复制之行首 y3l：从光标位置（包括光标位置）向右复制3个字符 y5G：将当前行（包括当前行）至第5行（不包括它）复制 y3B：从当前光标位置（不包括光标位置）反向复制3个单词 使用寄存器实现丰富的剪贴板功能 vim提供了10类寄存器: 匿名寄存器 \"\" 编号寄存器 \"0 到 \"9 小删除寄存器 \"- 26个命名寄存器 \"a 到 \"z 3个只读寄存器 \":, \"., \"% Buffer交替文件寄存器 \"# 表达式寄存器 \"= 选择和拖放寄存器 \"*, \"+, \"~ 黑洞寄存器 \"_ 搜索模式寄存器 \"/ 可在vim中通过:help registers查看帮助，通过:reg可以查看当前各寄存器中的值。 匿名寄存器 使用d, c, s, x等删除字符的命令或者y等复制字符的命令时，被操作的字符会进入匿名寄存器\"\"。当你执行黏贴命令p时，黏贴的就是匿名寄存器里的值。 编号寄存器 编号寄存器从\"0到\"9共10个，其中\"0保存这最近拷贝的字符串，\"1到\"9保存着最近9次删除掉的字符串。 当用户指定拷贝操作的寄存器（如\"ay）时，该拷贝数据不会被写入\"0。 \"0寄存器很有用，比如我们copy了一段文本然后用它替换另一段文本。 这时默认匿名寄存器\"\"中的值就变成了被替换文本，如果还需要用copy的文本继续替换的话就需要\"0p了。 小删除寄存器 不足一行的小删除则会被放到小删除寄存器中（\"-），起作用的删除操作符也包括s, c, d, x。 例如： dw # 删除一个词 d9l # 删除9个字符 cb # 向前更改一个词 与\"0寄存器类似，当用户指定寄存器并进行删除时，\"-不会被写入。 命名寄存器 命名寄存器有\"a到\"z共26个，这些寄存器只有当我们指定时才会被使用。比如我们要复制一段文字，存入匿名寄存器\"a，只要使用v选中这段文字，执行\"ay录制宏，这段文字就进入了\"a寄存器；然后使用\"ap即可黏贴这段文字。 只读寄存器 只读寄存器共3个，它们的值是由vim提供的，不允许改变： \".：上次insert模式中插入的字符串。使用.命令可以重复上次操作，使用的就是\".寄存器。 \"%：当前文件名，不是全路径，也不是纯文件名，而是从当前vim的工作目录到该文件的路径。比如你执行vim golang/gc.md打开了一个文件，那么\"%p输出的就是golang/gc.md \":：上次命令模式下键入的命令。使用@:可以执行上次命令。 交替文件寄存器 交替文件寄存器\"#存储着当前vim窗口（Window）的交替文件。交替文件（alternate file）是指 Buffer中的上一个文件，可通过Ctrl+^来切换交替文件与当前文件。 表达式寄存器 表达式寄存器\"=主要用于计算vim脚本的返回值，并插入到文本中。当我们键入\"=后光标会移动到命令行，此时我们可以输入任何vim脚本的表达式。 例如3+2，按下回车并且p则会得到5。 选择和拖放寄存器 选择和拖放寄存器包括\"*, \"+, 和\"~，这三个寄存器的行为是和GUI相关的。 \"*和\"+都是指系统剪切板（clipboard），例如\"*yy即可复制当前行到剪切板，以供其他程序中粘贴；其他程序中复制的内容也会被存储到这两个寄存器中，可以通过\"*p在vim中进行黏贴。 在Mac下执行:set clipboard=unnamed会使得系统剪切板寄存器\"*和vim默认的匿名寄存器\"\"始终保有同样的值，即vim和系统共用剪切板。 有文本拖拽到vim时，被拖拽的文本被存储在\"~中。vim默认的行为是将\"~中内容插入到光标所在位置。 黑洞寄存器 所有删除或拷贝到黑洞寄存器\"_的文本将会消失。这是为了在删除文本的同时不影响任何寄存器的值。 搜索寄存器 搜索寄存器\"/用于存储上一次搜索的关键词。在normal模式下按下/即进入search模式，输入关键字并按下回车即可。 该寄存器是可写的，例如:let @/ = \"maniafish\"将会把\"maniafish\"写入该寄存器。 下次使用/搜索时不输入搜索词直接回车便会搜索\"maniafish\"。 参考链接: 使用 Vim 寄存器 "},"linux/vim_conf.html":{"url":"linux/vim_conf.html","title":"III. vim的插件及配置","keywords":"","body":"vim的插件及配置 我的vim配置 \" Uncomment the next line to make Vim more Vi-compatible \" NOTE: debian.vim sets 'nocompatible'. Setting 'compatible' changes numerous \" options, so any other options should be set AFTER setting 'compatible'. set nocompatible filetype off \" required \" set the runtime path to include Vundle and initialize set rtp+=~/.vim/bundle/Vundle.vim call vundle#begin() \" 4 vundle \" let Vundle manage Vundle Plugin 'gmarik/Vundle.vim' \" 4 background color vim主题设置 Plugin 'altercation/vim-colors-solarized' \" 4 file tree init input :NERDTree in vim 目录管理 Plugin 'scrooloose/nerdtree' \" 4 search file 文件检索(ctrl-p) Plugin 'kien/ctrlp.vim' \" 4 minibufexpl 文件缓冲区(顶端显示最近打开的文件) Plugin 'fholgado/minibufexpl.vim' \" 4 the syntax checking when saving 语法检查 Plugin 'scrooloose/syntastic' \" 4 pep8 style checking python格式检查 Plugin 'nvie/vim-flake8' \" 4 vim-python-pep8-indent python代码按照pep8规范自动缩进 Plugin 'hynek/vim-python-pep8-indent' \" 4 vim-go golang代码相关插件，要求已经安装了golang环境 Plugin 'fatih/vim-go' \" 4 YouCompleteMe 2 complete the code 代码补全器 Plugin 'Valloric/YouCompleteMe' \" 4 markdown .md文件编辑 Plugin 'godlygeek/tabular' Plugin 'plasticboy/vim-markdown' \" 4 mark 颜色标记插件 Plugin 'inkarkat/vim-ingo-library' Plugin 'inkarkat/vim-mark' call vundle#end() \" required \" To ignore plugin indent changes, instead use: \"filetype plugin on filetype on filetype plugin on filetype indent on \" \" Brief help \" :PluginList - lists configured plugins \" :PluginInstall - installs plugins; append `!` to update or just :PluginUpdate \" :PluginSearch foo - searches for foo; append `!` to refresh local cache \" :PluginClean - confirms removal of unused plugins; append `!` to auto-approve removal \" \" see :h vundle for more details or wiki for FAQ \" Put your non-Plugin stuff after this line \" 设置了自动缩进的情况下，通过以下配置使退格键生效 set backspace=indent,eol,start \" Vim5 and later versions support syntax highlighting. Uncommenting the next \" line enables syntax highlighting by default. 语法高亮 syntax enable syntax on \" colorscheme darkblue \" 设置vim主题为molokai，显示原色；将主题molokai.vim放到~/.vim/color目录下方可使用 \" https://github.com/tomasr/molokai let g:molokai_original = 1 let g:rehash256 = 1 colorscheme molokai \" 设置tab为4个空格 set tabstop=4 set softtabstop=4 set expandtab \" 设置缩进为4个空格 set shiftwidth=4 \" 设置自动缩进 set autoindent set cindent set smartindent \" 设置行号 set nu \" 高亮游标所在行 set cursorline \" 设置倒数第二行位置显示当前游标行列信息 set statusline=%f%r%m%*%=[Line:%l/%L,Col:%c] set laststatus=2 set ruler \" 搜索不区分大小写 set ic \" 搜索匹配时立刻反应 set incsearch \" 搜索高亮，这里不开启 \" set hlsearch \" 设置文件为unix系统格式 set fileformat=unix \" 设置文件解码方式，以下任意一种方式匹配则使用该方式解码 set fileencodings=utf-8,gb18030,gbk,gb2312,big5 \" 设置终端显示编码和实际编码一致 let &termencoding=&encoding \" 不生成备份文件.un~ set nobackup set nowritebackup \" 4 code fold 代码折叠 set foldmethod=indent \" 设高默认代码折叠级别，即默认不折叠 set foldlevelstart=99 \" normal模式下非递归映射: 空格键->代码折叠 nnoremap za \" 粘贴模式开关 nnoremapc :set paste nnoremapv :set nopaste \" p粘贴时使用0寄存器替换匿名寄存器; noremap P \"0p \" 水平分屏 nnoremapd :sp \" 垂直分屏 nnoremapf :vs \" 4 yaml 设置yaml文件的缩进为两个空格 autocmd FileType yaml,html setlocal ts=2 sts=2 sw=2 expandtab \" 4 vim-flake8 let g:flake8_cmd=\"/usr/local/bin/flake8\" \" 4 syntastic let g:syntastic_python_checkers = ['flake8'] \" 4 vim-go let g:go_highlight_functions = 1 let g:go_highlight_methods = 1 let g:go_highlight_fields = 1 let g:go_highlight_types = 1 let g:go_highlight_operators = 1 let g:go_highlight_build_constraints = 1 let g:go_fmt_command = \"goimports\" nnoremapg :GoMetaLinter nnoremapw :GoDef \" 4 NERDTree silent! nnoremapA :NERDTree silent! nnoremapa :NERDTreeFind silent! nnoremaps :NERDTreeClose \" 4 ycm nnoremap q :YcmCompleter GoToDefinitionElseDeclaration set completeopt=menu,menuone \" 4 mark let g:mwDefaultHighlightingPalette = 'maximum' let g:mwDefaultHighlightingNum = 9 nnoremapN :MarkClear nmap IgnoreMarkSearchNext MarkSearchNext nmap IgnoreMarkSearchPrev MarkSearchPrev 使用Vundle进行插件管理 安装流程见：官方github中的\"Quick Start\" 通过Vundle安装的插件在\"~/.vim/bundle\"目录下 YouCompleteMe代码补全插件安装 安装7.5+版本的vim，添加python3支持(以下with-python-xxx和with-python3-xxx配置对应的是机器上实际的python目录，没有安装python的需要安装后再指定) $ git clone https://github.com/vim/vim.git $ cd vim $ ./configure --with-features=huge \\ --enable-multibyte \\ --enable-rubyinterp=yes \\ --enable-pythoninterp=yes \\ --with-python-config-dir=/usr/lib/python2.7/config \\ --enable-python3interp=yes \\ --with-python3-config-dir=/usr/lib/python3.4/config \\ --enable-perlinterp=yes \\ --enable-luainterp=yes \\ --enable-gui=gtk2 \\ --enable-cscope \\ --prefix=$HOME/runtime $ make && make install 安装YouCompleteMe：官网github，通过vundle安装即可 "},"linux/ab.html":{"url":"linux/ab.html","title":"IV. ab压测工具","keywords":"","body":"ab压测工具 ab压测出现\"Failed Requests\"的情况： Failed requests: 101 (Connect: 0, Receive: 0, Length: 101, Exceptions: 0) Connect: 连接失败 Receive: 没有收到返回 Length: 返回长度和之前不一致 Exceptions: 未预期错误 "},"linux/zsh.html":{"url":"linux/zsh.html","title":"V. 非root用户安装终极shell zsh","keywords":"","body":"非root用户安装终极shell zsh 下载zsh源码包: wget https://sourceforge.net/projects/zsh/files/zsh/5.7.1/zsh-5.7.1.tar.xz 解压: $ xz -d zsh-5.7.1.tar.xz $ tar -xvf zsh-5.7.1.tar 安装zsh，配置安装在用户目录下 $ cd zsh-5.7.1 $ ./configure --prefix=$HOME/ $ make && make install 完成后zsh会安装到$HOME/bin下 设置默认shell为zsh，在主目录下的.bashrc中添加 export PATH=$PATH:$HOME/bin # 添加PATH export SHELL=`which zsh` # 设置$SHELL为zsh exec `which zsh` -l # 设置登录为zsh 完成后执行source ~/.bashrc即可生效 安装oh-my-zsh: sh -c \"$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\" enjoy it ! 推荐设置.zshrc中的ZSH_THEME为\"clean\" 参考链接： download zsh from source oh-my-zsh官网 "},"linux/plantuml.html":{"url":"linux/plantuml.html","title":"VI. Sublime Text + PlantUML高效画图","keywords":"","body":"Sublime Text + PlantUML高效画图 1. 安装Sublime Text文本编辑器 官网安装即可：官网地址 2. 安装Plant​Uml​Diagrams插件 安装流程参考：PlantUML For Sublime 3. 使用PlantUML画图 语法速查参考：PlantUML语法 完成后在Sublime Text中执行Alt + m即可生成图 注意： 直接执行命令如果没有生成图片的话，可以Alt + a选定所有文本后再执行Alt + m 如果文本的语法写得有问题，也有可能不会直接生成并弹出图片，这个时候可以在当前文本的目录下找和当前文本同名的png文件，文件里会显示语法错误的地方 "},"mysql/sql_mode.html":{"url":"mysql/sql_mode.html","title":"I. 浅谈sql_mode对数据库的影响","keywords":"","body":"浅谈sql_mode对数据库的影响 什么是sql_mode mysql的sql_mode用于设定数据库进行数据和sql语法校验的严格程度，某些情况下会影响数据操作和迁移的结果，忽略它的话很容易踩坑。 操作sql_mode 查看全局sql_mode: SELECT @@GLOBAL.sql_mode; 查看当前会话的sql_mode: SELECT @@SESSION.sql_mode; 修改全局sql_mode: SET GLOBAL sql_mode = '' 修改全局sql_mode: SET SESSION sql_mode = '' 接下来我们依次介绍一下mysql都有哪些sql_mode，以及它们各自的作用是什么。 sql_mode的类型 以下示例使用的TEST表结构为: Create Table | CREATE TABLE `TEST` ( `id` int(11) NOT NULL AUTO_INCREMENT, `d` date DEFAULT NULL, `dt` datetime DEFAULT CURRENT_TIMESTAMP, `ts` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP, `value` varchar(255) NOT NULL DEFAULT '', `num` bigint(20) NOT NULL DEFAULT '0', PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 mysql版本为5.7.28 ALLOW_INVALID_DATES 该值用于允许插入非法的日期。一般情况下，月份范围是 1 - 12，日范围是 1 - 31。当没有设置该值时，非法日期输入会被置为0000-00-00： 示例1 INSERT INTO TEST(d, dt) VALUES('2020-13-13', '2020-13-13 55:55:55'); 插入结果如下(非法插入默认被设置为0000-00-00 00:00:00)： d | 0000-00-00 dt | 0000-00-00 00:00:00 示例2 INSERT INTO TEST(d, dt) VALUES('2020-11-31', '2020-11-31 12:12:12'); 插入结果如下(即便时间有效，只要日期无效，同样会被设置为0000-00-00 00:00:00)： d | 0000-00-00 dt | 0000-00-00 00:00:00 当设置了该值，即SET SESSION sql_mode = 'ALLOW_INVALID_DATES';时： 示例1 INSERT INTO TEST(d, dt) VALUES('2020-13-13', '2020-13-13 55:55:55') 插入结果如下(和没设置ALLOW_INVALID_DATES时一样)： d | 0000-00-00 dt | 0000-00-00 00:00:00 示例2 INSERT INTO TEST(d, dt) VALUES('2020-11-31', '2020-11-31 12:12:12'); 插入结果如下(可以看到，只要插入的日期在限定范围内：1~12月、1~31日，就允许插入；即便当前日期11-31是不存在的)： d | 2020-11-31 dt | 2020-11-31 12:12:12 配置建议：不要设置该值，以免程序读取数据库时读出无效的日期 ANSI_QUOTES 该值用于设定将双引号\"作为引用标识符 ` 使用。当没有设置该值时，双引号表示正常的字符串引用： 示例1 > INSERT INTO TEST(value) VALUES(\"data\"); > SELECT `value` FROM TEST; +-------+ | value | +-------+ | data | +-------+ > SELECT \"value\" FROM TEST; +-------+ | value | +-------+ | value | +-------+ 当设置了该值，即SET SESSION sql_mode = 'ANSI_QUOTES';，双引号和 ` 等价： 示例1(由于data字段不存在，因此返回错误) > INSERT INTO TEST(value) VALUES(\"data\"); (1054, \"Unknown column 'data' in 'field list'\") 示例2(选择字符串变成了选择value字段值) > SELECT \"value\" FROM TEST; +-------+ | value | +-------+ | data | +-------+ 配置建议：不要设置该值，插入时可能引发错误，查询时容易引起歧义。 ERROR_FOR_DIVISION_BY_ZERO 该值用于设定除 0 时的合法性校验。当没有设置该值时，默认除以0的操作不报错，结果作为NULL值处理： 示例1(查询返回的是NULL值） > SELECT 1/0; +--------+ | 1/0 | +--------+ | | +--------+ 示例2 > INSERT INTO TEST(num) VALUES(1/0); (1048, \"Column 'num' cannot be null\") 这里报错的原因是我们设定的num bigint(20) NOT NULL DEFAULT '0'，要求是NOT NULL，而1/0返回的是NULL，所以不允许插入。(ps: 建议建表的时候对数值类型设置为NOT NULL，可以避免一些不可预期的空值带来的影响) 单独设置该值，即SET SESSION sql_mode = 'ERROR_FOR_DIVISION_BY_ZERO';是无效的；需要和严格模式(Strict SQL Mode)结合使用才行，如SET SESSION sql_mode = 'ERROR_FOR_DIVISION_BY_ZERO,STRICT_TRANS_TABLES';时： 示例1 > SELECT 1/0; +--------+ | 1/0 | +--------+ | | +--------+ 虽然查询结果还是NULL，但是有warning报出： > SHOW WARNINGS; +---------+------+---------------+ | Level | Code | Message | +---------+------+---------------+ | Warning | 1365 | Division by 0 | +---------+------+---------------+ 示例2(插入时由于除 0 ，直接报出了相应的错误) > INSERT INTO TEST(num) VALUES(1/0); (1365, 'Division by 0') mysql官方文档关于该值有这样的说明： Because ERROR_FOR_DIVISION_BY_ZERO is deprecated, it will be removed in a future MySQL release as a separate mode name and its effect included in the effects of strict SQL mode. 由于该值需要和严格模式结合使用，因此官方在之后的版本会将其废弃，直接作为严格模式中的一部分功能来对外提供。 配置建议：没有设置严格模式(`STRICT_ALL_TABLES`或`STRICT_TRANS_TABLES`)的，无需设置该值；设置了严格模式的，该值可配可不配(未来版本也会废弃，相比之下设置好表结构，数值型字段不允许NULL才是一劳永逸的方法)。 HIGH_NOT_PRECEDENCE 该值用于提高 not 运算符的优先级。当没有设置该值时，默认 not 运算符的优先级是在最后的： 示例1(先做BETWEEN判断再做not取反) > SELECT NOT 1 BETWEEN -5 AND 5; +------------------------+ | NOT 1 BETWEEN -5 AND 5 | +------------------------+ | 0 | +------------------------+ 当设置了该值，即SET SESSION sql_mode='HIGH_NOT_PRECEDENCE'时： 示例1(先做NOT取反，再做BETWEEN判断) > SELECT NOT 1 BETWEEN -5 AND 5; +------------------------+ | NOT 1 BETWEEN -5 AND 5 | +------------------------+ | 1 | +------------------------+ 配置建议：不要设置该值，以免由于运算符优先级改变导致程序处理结果和预期不符 IGNORE_SPACE 该值用于允许函数名和(之间有空格；除此之外，设置该值时，会将mysql内建函数名等作为保留字，使用和保留字相同的名字作为库名/表名/列名时，会报错。当没有设置该值时： 示例1(用内建函数count同名来建表是被允许的) > CREATE TABLE count (i int(11) NOT NULL DEFAULT '0'); Query OK, 0 rows affected Time: 0.021s > SHOW CREATE TABLE count; +-------+----------------------------------------+ | Table | Create Table | +-------+----------------------------------------+ | count | CREATE TABLE `count` ( | | | `i` int(11) NOT NULL DEFAULT '0' | | | ) ENGINE=InnoDB DEFAULT CHARSET=latin1 | +-------+----------------------------------------+ 示例2(调用方法中间不能有空格) > SELECT count(i) FROM count; +----------+ | count(i) | +----------+ | 0 | +----------+ > SELECT count (i) FROM count; (1630, \"FUNCTION mode_test.count does not exist. Check the 'Function Name Parsing and Resolution' section in the Reference Manual\") 当设置该值，即SET SESSION sql_mode='IGNORE_SPACE';时： 示例1(用内建函数count同名来建表被禁止，需要加上引用标识符 ` ) > CREATE TABLE count (i int(11) NOT NULL DEFAULT '0'); (1064, \"You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'count (i int(11) NOT NULL DEFAULT '0')' at line 1\") > CREATE TABLE `count` (i int(11) NOT NULL DEFAULT '0'); Query OK, 0 rows affected Time: 0.021s > SHOW CREATE TABLE count; +-------+----------------------------------------+ | Table | Create Table | +-------+----------------------------------------+ | count | CREATE TABLE `count` ( | | | `i` int(11) NOT NULL DEFAULT '0' | | | ) ENGINE=InnoDB DEFAULT CHARSET=latin1 | +-------+----------------------------------------+ 示例2(调用方法中间允许有空格) > SELECT count(i) FROM count; +----------+ | count(i) | +----------+ | 0 | +----------+ > SELECT count (i) FROM count; +-----------+ | count (i) | +-----------+ | 0 | +-----------+ 配置建议：建议设置该值，可以一定程度上避免使用内建函数同名的元素造成歧义，另外允许空格的特性可以稍微提升一点用户使用友好度 NO_AUTO_CREATE_USER 该值用于禁止自动创建密码为空的用户。当没有设置该值时： 示例1(给不存在的用户授权时，自动创建了密码为空的新用户) > GRANT SELECT ON *.* TO testuser1; > SELECT user, host, authentication_string FROM mysql.user WHERE user = 'testuser1'; +-----------+------+-----------------------+ | user | host | authentication_string | +-----------+------+-----------------------+ | testuser1 | % | | +-----------+------+-----------------------+ > SHOW GRANTS FOR 'testuser1'@'%'; +----------------------------------------+ | Grants for testuser1@% | +----------------------------------------+ | GRANT SELECT ON *.* TO 'testuser1'@'%' | +----------------------------------------+ 当设置了该值，即SET SESSION sql_mode='NO_AUTO_CREATE_USER';时： 示例1(给不存在的用户授权时返回错误) > GRANT SELECT ON *.* TO testuser2; (1133, \"Can't find any matching row in the user table\") 示例2(给不存在的用户授权并添加密码即可授权成功) > GRANT SELECT ON *.* TO testuser2 IDENTIFIED BY 'test'; > SELECT user, host, authentication_string FROM mysql.user WHERE user = 'testuser2'; +-----------+------+-------------------------------------------+ | user | host | authentication_string | +-----------+------+-------------------------------------------+ | testuser2 | % | *94BDCEBE19083CE2A1F959FD02F964C7AF4CFC29 | +-----------+------+-------------------------------------------+ > SHOW GRANTS FOR 'testuser2'@'%'; +----------------------------------------+ | Grants for testuser2@% | +----------------------------------------+ | GRANT SELECT ON *.* TO 'testuser2'@'%' | +----------------------------------------+ 配置建议：建议设置该值，可以防止创建空密码用户导致数据库访问安全问题 NO_AUTO_VALUE_ON_ZERO 该值用于允许自增字段插入0值。当没有设置该值时： 示例1(由于id的定义是自增值AUTO_INCREMENT，因此默认从1开始) > INSERT INTO TEST(id) VALUES(0); > SELECT id FROM TEST; +----+ | id | +----+ | 1 | +----+ 示例2(当表中已经有自增id时，插入0值实际入库的值以当前AUTO_INCREMENT为准) > SELECT id FROM TEST; +----+ | id | +----+ | 1 | | 2 | | 4 | | 6 | +----+ > SHOW CREATE TABLE TEST; +-------+----------------------------------------------------------+ | Table | Create Table | +-------+----------------------------------------------------------+ | TEST | CREATE TABLE `TEST` ( | | | `id` int(11) NOT NULL AUTO_INCREMENT, | | | `d` date DEFAULT NULL, | | | `dt` datetime DEFAULT CURRENT_TIMESTAMP, | | | `ts` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP, | | | `value` varchar(255) NOT NULL DEFAULT '', | | | `num` bigint(20) NOT NULL DEFAULT '0', | | | PRIMARY KEY (`id`) | | | ) ENGINE=InnoDB AUTO_INCREMENT=7 DEFAULT CHARSET=utf8mb4 | +-------+----------------------------------------------------------+ # AUTO_INCREMENT=7，因此下一次插入的0值被设置为7 > INSERT INTO TEST(id) VALUES(0); > SELECT id FROM TEST; +----+ | id | +----+ | 1 | | 2 | | 4 | | 6 | | 7 | +----+ 当设置了该值，即SET SESSION sql_mode='NO_AUTO_VALUE_ON_ZERO';时： 示例1(插入0值，实际入库也为0) > INSERT INTO TEST(id) VALUES(0); > SELECT id FROM TEST; +----+ | id | +----+ | 0 | +----+ 示例2(对已有0值的，继续插入会返回错误) > INSERT INTO TEST(id) VALUES(0); (1062, \"Duplicate entry '0' for key 'PRIMARY'\") 示例3(当前表的AUTO_INCREMENT不再影响0值插入的实际值) > SELECT id FROM TEST; +----+ | id | +----+ | 1 | | 2 | | 4 | | 6 | +----+ > SHOW CREATE TABLE TEST; +-------+----------------------------------------------------------+ | Table | Create Table | +-------+----------------------------------------------------------+ | TEST | CREATE TABLE `TEST` ( | | | `id` int(11) NOT NULL AUTO_INCREMENT, | | | `d` date DEFAULT NULL, | | | `dt` datetime DEFAULT CURRENT_TIMESTAMP, | | | `ts` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP, | | | `value` varchar(255) NOT NULL DEFAULT '', | | | `num` bigint(20) NOT NULL DEFAULT '0', | | | PRIMARY KEY (`id`) | | | ) ENGINE=InnoDB AUTO_INCREMENT=7 DEFAULT CHARSET=utf8mb4 | +-------+----------------------------------------------------------+ > INSERT INTO TEST(id) VALUES(0); # 实际入库依然为0 > SELECT id FROM TEST; +----+ | id | +----+ | 0 | | 1 | | 2 | | 4 | | 6 | +----+ 配置建议：一般我们不建议在入库时去设置自增字段的值，这样可以保持自增字段在每次入库记录时保持自增连续性。在规范的数据库操作前提下，该值设置与否影响不大 NO_BACKSLASH_ESCAPES 该值用于将反斜杠\\作为普通字符使用。默认反斜杠是作为转义字符使用的，当没有设置该值时： 示例1(入库转义字符)： > INSERT INTO TEST(value) VALUES(\"1\\t2\"); # \\t被作为转义字符tab入库 > SELECT value FROM TEST; +--------+ | value | +--------+ | 1 2 | +--------+ 示例2(入库反斜杠): > INSERT INTO TEST(value) VALUES(\"1\\\\2\") > SELECT value FROM TEST; +-------+ | value | +-------+ | 1\\2 | +-------+ 当设置了该值，即SET SESSION sql_mode='NO_BACKSLASH_ESCAPES';时： 示例1(入库普通字符)： > INSERT INTO TEST(value) VALUES(\"1\\t2\"); # \\t被作为普通字符入库 > SELECT value FROM TEST; +-------+ | value | +-------+ | 1\\t2 | +-------+ 配置建议：正常情况下反斜杠都是作为转义字符使用的，若用户有特殊需求，可以配置该值 NO_DIR_IN_CREATE 该值用于忽略所有INDEX DIRECTORY和DATA DIRECTORY选项；这两个选项用于指定创建表时存放索引和数据的目录位置，通常存放在mysql默认路径下，不会专门去设定这个目录。 NO_ENGINE_SUBSTITUTION 参考链接： mysql out-of-range-and-overflow mysql sql_mode "},"python/character.html":{"url":"python/character.html","title":"I. 浅析json dump的字符编码问题","keywords":"","body":"浅析json dump的字符编码问题 说到python json dump的字符编码问题之前，要先了解一个老生常谈的问题，\"unicode\" 和 \"str\" 有什么区别 unicode 和 str unicode是通用的字符编码，它被不同的编码方式(如utf-8, gbk...)编码后，变成由不同byte组成的str Unicode 提供了所有我们需要的字符的空间，但是计算机的传输只能通过bytes 。我们需要一种用 bytes 来表示 Unicode 的方法这样才可以存储和传播他们，这个过程就是encoding 在python中，unicode通过encode转换成str，str通过decode转换成unicode >>> a = \"测试\" >>> type(a), a (, '\\xe6\\xb5\\x8b\\xe8\\xaf\\x95') # a是utf-8编码的str >>> b = a.decode(\"utf-8\") >>> type(b), b (, u'\\u6d4b\\u8bd5') # b是a用utf-8解码后的unicode >>> c = b.encode(\"gbk\") >>> type(c), c (, '\\xb2\\xe2\\xca\\xd4') # c是b用gbk编码后的str，可以看到，编码后的c和a已经不同了，虽然它在gbk终端下显示出来的仍然是中文\"测试\" python2对unicode和str会做一些隐式操作，允许二者混用 当你进行unicode 和 str 拼接的时候，python会对str做decode操作，隐式转换成unicode进行拼接 >>> a = \"test\" >>> b = u\"test\" >>> type(a), type(b) (, ) >>> type(a + b) # 拼接后的结果为unicode，因为python帮你完成了b(str)到b(unicode)的转换 python默认用ascii编码来对str做decode，这种转换，在字符串是全英文时没有任何问题；但是当字符串存在中文时，一旦编码不符，这种隐式转换就会报错 >>> a = \"测试\" >>> b = u\"测试\" >>> type(a), type(b) (, ) >>> c = a + b Traceback (most recent call last): File \"\", line 1, in UnicodeDecodeError: 'ascii' codec can't decode byte 0xe6 in position 0: ordinal not in range(128) # 这里的报错原因是：\"测试\"是utf-8终端编码输入的str，在用ascii编码方式做decode时，会出现解码错误 理论上，str是编码后的字符串，只允许做解码(decode)；unicode是解码后的字符串，只允许做编码(encode)。但是实际上，python的隐式操作使得二者可以任意编解码 >>> a = \"test\" >>> type(a) >>> a.encode(\"utf-8\") # python底层处理为a.decode(\"ascii\").encode(\"utf-8\") 'test' >>> a.decode(\"utf-8\") u'test' >>> b = u\"test\" >>> type(b) >>> b.encode(\"utf-8\") 'test' >>> b.decode(\"utf-8\") # python底层处理为a.encode(\"ascii\").decode(\"utf-8\") u'test' # 同样，当字符串中存在中文时，这种通过ascii编码方式做的隐式转换，在编码不符时就会报错 >>> a = \"测试\" >>> type(a) >>> a.encode(\"utf-8\") Traceback (most recent call last): File \"\", line 1, in UnicodeDecodeError: 'ascii' codec can't decode byte 0xe6 in position 0: ordinal not in range(128) python2这种隐式转换的存在，看起来是让程序员在写程序的时候不用考虑unicode和str的类型；但实际上看看上面演示的那些情况，当你的接口处理过程中存在中文字符，而你又忽略了unicode和str的区别，在python2做隐式转换时，程序就会出错 最安全的做法是，在程序处理返回时，对字符串采用统一的编码；不同编码的str按照各自编码decode成unicode后，再采用统一的编码方式encode成str来进行返回 >>> a = u\"测试\".encode(\"utf-8\") >>> b = u\"测试\".encode(\"gbk\") >>> c = (a.decode(\"utf-8\") + b.decode(\"gbk\")).encode(\"utf-8\") >>> print c 测试测试 json处理中的字符编码问题 python的官方json包用于做字典字符串之间的转换工作，然而这个转换的过程中，对字符编码的处理上有一些需要额外注意的地方 >>> a = {\"data\": \"测试\"} >>> print json.dumps(a) {\"data\": \"\\u6d4b\\u8bd5\"} 可以看到，当通过json.dumps()将字典a转换为字符串的过程中，对字典中的元素返回的是unicode的结果(\"\\u6d4b\\u8bd5\")。我们知道，unicode是通过str解码来的。在调用json.dumps()时，可以指定一个参数encoding，这个参数默认为utf-8，也就是默认以utf-8编码方式来进行解码，官方包里对encoding的描述如下： ``encoding`` is the character encoding for str instances, default is UTF-8. 因此，如果你需要解析一个gbk编码的字典对象，就需要指定encoding=\"gbk\" >>> a = {\"data\": u\"测试\".encode(\"gbk\")} >>> print json.dumps(a) # 没有指定编码方式时，默认用utf-8解码，会报错 Traceback (most recent call last): File \"\", line 1, in File \"/usr/local/Cellar/python/2.7.13_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/json/__init__.py\", line 244, in dumps return _default_encoder.encode(obj) File \"/usr/local/Cellar/python/2.7.13_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/json/encoder.py\", line 207, in encode chunks = self.iterencode(o, _one_shot=True) File \"/usr/local/Cellar/python/2.7.13_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/json/encoder.py\", line 270, in iterencode return _iterencode(o, 0) UnicodeDecodeError: 'utf8' codec can't decode byte 0xb2 in position 0: invalid start byte >>> print json.dumps(a, encoding=\"gbk\") # 指定encoding=\"gbk\"后，可以正常输出json字符串 {\"data\": \"\\u6d4b\\u8bd5\"} 不过，此时输出的json字符串中，中文字符是unicode的，不能正常显示；当你的接口想要返回一个可正常显示的含有中文字符的json字符串时，需要在调用json.dumps()时指定ensure_ascii参数为False >>> a = {\"data\": u\"测试\".encode(\"gbk\")} >>> print json.dumps(a, encoding=\"gbk\", ensure_ascii=False) {\"data\": \"测试\"} 虽然可以正常显示了，但是这时候引入了一个新的问题 >>> a = {\"data\": u\"测试\".encode(\"gbk\")} >>> b = json.dumps(a, encoding=\"gbk\") >>> c = json.dumps(a, encoding=\"gbk\", ensure_ascii=False) >>> print type(b), b {\"data\": \"\\u6d4b\\u8bd5\"} # 原始json.dumps()的结果类型为str >>> print type(c), c {\"data\": \"测试\"} # 设置ensure_ascii后json.dumps()的结果类型为unicode 要知道，当结果中存在中文字符的时候，是需要格外注意字符串类型是unicode还是str的，否则会在程序处理过程中出现问题。比如我们的接口中需要处理一个含有gbk编码元素的字典，然后返回utf-8编码的json结果 >>> a = {\"data\": u\"测试\".encode(\"gbk\")} >>> b = json.dumps(a, encoding=\"gbk\", ensure_ascii=False) >>> b.decode(\"gbk\").encode(\"utf-8\") # 进行gbk解码，并进行utf-8编码返回 Traceback (most recent call last): File \"\", line 1, in UnicodeEncodeError: 'ascii' codec can't encode characters in position 10-11: ordinal not in range(128) # 由于设置ensure_ascii=False时，json.dumps()返回的结果从str变成了unicode；因此当我们对一个unicode的结果进行decode解码时，就会报错 可能有人会说，那我碰到ensure_ascii=False的情况时，既然都知道返回的和原来不一样，是个unicode了；那我直接对它做encode，不按照原来处理str的方法(先decode成unicode，再encode成目标编码的str)，不就行了吗？但是事实上并没有那么简单。当我们的原始编码是utf-8，目标编码是gbk时，情况又不一样了 >>> a = {\"data\": u\"测试\".encode(\"utf-8\")} >>> b = json.dumps(a, encoding=\"utf-8\", ensure_ascii=False) >>> b.encode(\"gbk\") Traceback (most recent call last): File \"\", line 1, in UnicodeDecodeError: 'ascii' codec can't decode byte 0xe6 in position 10: ordinal not in range(128) 当ensure_ascii=False的时候，json.dumps()返回的结果不是unicode吗？对一个unicdoe的字符串，我们应该是可以encode成任意str的，怎么上面又报错了呢？我们来看一下现在json.dumps()的结果类型 >>> type(b) 说好的unicode，在utf-8编码下又变回了str。我们来看下这个ensure_ascii的官方注解 可以看到，json.dumps()当设定ensure_ascii=False，且使用了encoding参数时，才会返回unicode。encoding=utf-8时之所以返回的是str，是因为json.dumps()方法默认的encoding=utf-8，相当于encoding parameter is not used，因此仍然保持原str返回。 总结 当使用json.dumps()处理含有中文字符的字典时，需要格外注意编码问题 如果源输入是utf-8编码，直接使用json.dumps(a, ensure_ascii=False)即可，默认encoding=utf-8，返回的就是一个utf-8编码的str 如果源输入是其他编码，如gbk，则使用json.dumps(a, ensure_ascii=False, encoding=\"gbk\")，返回的是一个unicode，可以根据需要encode成目标编码的str进行传输 参考链接: python unicode 之痛 "},"python/dbutils.html":{"url":"python/dbutils.html","title":"II. python数据库连接池DBUtils","keywords":"","body":"python数据库连接池DBUtils 概述 当我们的程序需要复用数据库连接时，使用连接池替代短连接可以提高数据库的访问效率，避免频繁地创建和销毁数据库连接。python的第三方库DBUtils提供了高效、线程安全的连接池。 DBUtils提供三种类型的数据库连接，分别是： SteadyDB PersistentDB PooledDB SteadyDB SteadyDB提供了一种“强硬”的数据库连接，当数据库连接丢失或断开时，它会强制重连。它是DBUtils实现的一种最基本的数据库连接，底层采用DB-API 2规范的数据库模型。通常我们不直接使用SteadyDB，而是使用以下两种封装了SteadyDB的连接类型：PersistentDB和PooledDB。 PersistentDB PersistentDB实现了一种线程安全的数据库连接池 当一个线程a启用数据库连接时，PersistentDB会打开一个专供该线程使用的数据库连接 当线程a关闭数据库连接时，该数据库连接会继续保持open状态，下次线程a调用时可以直接使用 直到线程a消亡时，该数据库连接会自动关闭 PersistentDB可以在同一个线程中通过连接复用来提高数据库访问效率；但是同一个数据库连接不能在不同线程间复用，最大限度地保证数据库连接的线程安全。 PooledDB PooledDB同样提供了线程安全的数据库连接池，和PersistentDB的区别是：同一个连接可以在不同线程间复用。 PooledDB提供了mincached和maxcached选项；分别用于指定连接池的初始化连接数，以及连接池里允许的最大空闲连接数 PooledDB提供了maxshared选项，用于设定共享连接池大小。当打开一个数据库连接时，只有在配置了maxshared > 0才会创建PooledSharedDBConnection，从_shared_cache中取出连接供不同线程共用；默认该参数为0，创建的是PooledDedicatedDBConnection，从当前空闲的连接池中取一个连接供当前线程专用，使用完毕后放回空闲连接池中 maxshared参数只有在creator.threadsafety > 1时才生效 由于pymysql和MySQLdb模块的threadsafety都为1，因此当使用这些模块作为creator时，maxshared不生效，使用的都是PooledDedicatedDBConnection 实际上还有一种SimplePooledDB，实现了基本的连接池功能；但是它比起PooledDB少了故障重连功能，因此官方文档上不建议将其直接用于生产环境 使用 示例代码： # coding: utf-8 import pymysql from DBUtils.PooledDB import PooledDB import threading import time dbopt = { 'user': 'root', 'passwd': 'test', 'host': '127.0.0.1', 'port': 3306, 'connect_timeout': 5, 'write_timeout': 5, 'read_timeout': 5, 'db': 'DM0' } db_pool = PooledDB( creator=pymysql, # 使用数据库连接的模块 maxconnections=10, # 连接池允许的最大连接数，0和None表示不限制连接数 mincached=2, # 初始化时，连接池中至少创建的空闲的链接，0表示不创建 maxcached=5, # 连接池中最多闲置的链接，0和None不限制 maxshared=0, # 连接池中最多共享的链接数量，0表示不共享。PS: 无用，因为pymysql和MySQLdb等模块的 threadsafety都为1，此值只有在creator.threadsafety > 1时设置才有效，否则创建的都是dedicated connection，即此连接是线程专用的。 blocking=True, # 连接池中如果没有可用连接后，是否阻塞等待。True，等待；False，不等待然后报错 maxusage=None, # 一个连接最多被重复使用的次数，None表示无限制 setsession=[\"set autocommit=1\"], # 开始会话前执行的命令列表。如：[\"set datestyle to ...\", \"set time zone ...\"]；务必要设置autocommit，否则可能导致该session的sql未提交 ping=1, # 每次从pool中取连接时ping一次检查可用性 reset=False, # 每次将连接放回pool时，将未提交的内容回滚；False时只对事务操作进行回滚 **dbopt ) class DBThread (threading.Thread): def __init__(self, threadID): threading.Thread.__init__(self) self.threadID = threadID def run(self): conn = db_pool.connection() cur = conn.cursor(pymysql.cursors.DictCursor) cur.execute(\"INSERT INTO TestTb(name) VALUES(%s)\", [\"t-{0}\".format(self.threadID), ]) print \"thread-{0}\".format(self.threadID) if __name__ == \"__main__\": time.sleep(10) for i in xrange(100): t = DBThread(i) t.start() time.sleep(10) DBUtils的使用方式很简单，通过PooledDB()创建连接池；然后通过connection()方法取出连接进行操作即可 这里我们创建了100个线程进行并发插入操作，设定最大数据库连接数maxconnections为10 DBUtils建立的是惰性连接，也就是只有调用connection()取出连接时才会和数据库建立实际的连接，一开始创建PooledDB时是不建立实际连接的；不过可以通过mincached参数设定连接池初始化的连接数，这里我们设定mincached=2。可以看到，在线程并发操作前，就已经建立了两个数据库连接 +------+------+-----------------+-----+---------+------+----------+-----------------------+ | Id | User | Host | db | Command | Time | State | Info | +------+------+-----------------+-----+---------+------+----------+-----------------------+ | 4423 | root | localhost:58091 | dm0 | Sleep | 4 | | | | 4424 | root | localhost:58092 | dm0 | Sleep | 4 | | | +------+------+-----------------+-----+---------+------+----------+-----------------------+ 线程并发数据库操作完成后，PooledDB会保持和数据库的连接；这里我们设定了连接池最大连接数maxconnections=10，当数据库操作完成后，仍然会有10个连接keepalive 可以通过maxcached参数设定最大闲置连接数，这里我们设定maxcached=5，数据库操作完成后，只有5个闲置连接保留 +------+------+-----------------+-----+---------+------+----------+-----------------------+ | Id | User | Host | db | Command | Time | State | Info | +------+------+-----------------+-----+---------+------+----------+-----------------------+ | 4425 | root | localhost:58093 | dm0 | Sleep | 5 | | | | 4427 | root | localhost:58095 | dm0 | Sleep | 5 | | | | 4428 | root | localhost:58096 | dm0 | Sleep | 5 | | | | 4430 | root | localhost:58098 | dm0 | Sleep | 5 | | | | 4434 | root | localhost:58102 | dm0 | Sleep | 5 | | | +------+------+-----------------+-----+---------+------+----------+-----------------------+ 查看数据库表，正常入库了100条数据 mysql root@localhost:DM0> select count(distinct name) from TestTb; +----------------------+ | count(distinct name) | +----------------------+ | 100 | +----------------------+ 需要注意的是，创建连接池时必须设定setsession=[\"set autocommit=1\"]，保证连接池内每个会话的sql能够及时提交；当数据库连接断线重连时，新建的连接也会执行这个setsession操作 参考链接： DBUtils官方指南 "},"golang/performance.html":{"url":"golang/performance.html","title":"I. Go的性能指标","keywords":"","body":"Go的性能指标 指标 latency cost 影响Go性能指标的几个因素 algorithm gc mechanical sympathy "},"golang/heap_stack.html":{"url":"golang/heap_stack.html","title":"II. Go的堆栈分配","keywords":"","body":"Go的堆栈分配 Golang的程序栈 每个goroutine维护着一个栈空间，默认最大为4KB 当goroutine的栈空间不足时，golang会调用runtime.morestack(汇编实现：asm_xxx.s)来进行动态扩容 连续栈：当栈空间不足的时候申请一个2倍于当前大小的新栈，并把所有数据拷贝到新栈， 接下来的所有调用执行都发生在新栈上。 每个function维护着各自的栈帧(stack frame)，当function退出时会释放栈帧 function内部的栈操作 用一段简单的代码来说明Go函数调用及传参时的栈操作： package main func g(p int) int { return p+1; } func main() { c := g(4) + 1 _ = c } 执行go tool compile -S main.go生成汇编，并截取其中的一部分来说明一下程序调用时的栈操作 \"\".g t=1 size=17 args=0x10 locals=0x0 // 初始化函数的栈地址 // 0-16表示函数初始地址为0，数据大小为16字节(input: 8字节，output: 8字节) // SB是函数寄存器 0x0000 00000 (test_stack.go:3) TEXT \"\".g(SB), $0-16 // 函数的gc收集提示。提示0和1是用于局部函数调用参数，需要进行回收 0x0000 00000 (test_stack.go:3) FUNCDATA $0, gclocals·aef1f7ba6e2630c93a51843d99f5a28a(SB) 0x0000 00000 (test_stack.go:3) FUNCDATA $1, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) // FP(frame point)指向栈底 // 将FP+8位置的数据(参数p)放入寄存器AX 0x0000 00000 (test_stack.go:4) MOVQ \"\".p+8(FP), AX 0x0005 00005 (test_stack.go:4) MOVQ (AX), AX // 寄存器值自增 0x0008 00008 (test_stack.go:4) INCQ AX // 从寄存器中取出值，放入FP+16位置(返回值) 0x000b 00011 (test_stack.go:4) MOVQ AX, \"\".~r1+16(FP) // 返回，返回后程序栈的空间会被回收 0x0010 00016 (test_stack.go:4) RET 0x0000 48 8b 44 24 08 48 8b 00 48 ff c0 48 89 44 24 10 H.D$.H..H..H.D$. 0x0010 c3 . \"\".main t=1 size=32 args=0x0 locals=0x10 0x0000 00000 (test_stack.go:7) TEXT \"\".main(SB), $16-0 0x0000 00000 (test_stack.go:7) SUBQ $16, SP 0x0004 00004 (test_stack.go:7) MOVQ BP, 8(SP) 0x0009 00009 (test_stack.go:7) LEAQ 8(SP), BP 0x000e 00014 (test_stack.go:7) FUNCDATA $0, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 0x000e 00014 (test_stack.go:7) FUNCDATA $1, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) // SP(stack point)指向栈顶 // 把4存入SP的位置 0x000e 00014 (test_stack.go:8) MOVQ $4, \"\".c(SP) // 这里会看到没有第9行`call g()`的调用出现，这是因为go汇编编译器会把一些短函数变成内嵌函数，减少函数调用 0x0016 00022 (test_stack.go:10) MOVQ 8(SP), BP 0x001b 00027 (test_stack.go:10) ADDQ $16, SP 0x001f 00031 (test_stack.go:10) RET 事实上，即便我定义了指针调用，以上的数据也都是在栈上拷贝的；那么Golang中的数据什么时候会被分配到堆上呢？ Golang逃逸分析 在编译程序优化理论中，逃逸分析是一种确定指针动态范围的方法，用于分析在程序的哪些地方可以访问到指针。 Golang在编译时的逃逸分析可以减少gc的压力，不逃逸的对象分配在栈上，当函数返回时就回收了资源，不需要gc标记清除。 如果你定义的对象的方法上有同步锁，但在运行时，却只有一个线程在访问，此时逃逸分析后的机器码，会去掉同步锁运行，提高效率。 举个栗子 还是1.1里的那段程序代码，我们可以执行go build -gcflags '-m -l' test_stack.go来进行逃逸分析，输出结果如下 # command-line-arguments ./test_stack.go:3: g p does not escape ./test_stack.go:9: main &c does not escape 可以看到，对象c是没有逃逸的，还是分配在栈上。 即便在一开始定义的时候直接把c定义为指针： package main func g(p *int) int { return *p + 1 } func main() { c := new(int) (*c) = 4 _ = g(c) } 逃逸分析的结果仍然不会改变 # command-line-arguments ./test_stack.go:3: g p does not escape ./test_stack.go:8: main new(int) does not escape 那么，什么时候指针对象才会逃逸呢？ 按值传递和按址传递 按值传递 package main func g(p int) int { ret := p + 1 return ret } func main() { c := 4 _ = g(c) } 返回值ret是按值传递的，执行的是栈拷贝，不存在逃逸 按址传递 package main func g(p *int) *int { ret := *p + 1 return &ret } func main() { c := new(int) *c = 4 _ = g(c) } 返回值&ret是按址传递，传递的是指针对象，发生了逃逸，将对象存放在堆上以便外部调用 # command-line-arguments ./test_stack.go:5:9: &ret escapes to heap ./test_stack.go:4:14: moved to heap: ret ./test_stack.go:3:17: g p does not escape ./test_stack.go:9:10: main new(int) does not escape golang只有在function内的对象可能被外部访问时，才会把该对象分配在堆上 在g()方法中，ret对象的引用被返回到了方法外，因此会发生逃逸；而p对象只在g()内被引用，不会发生逃逸 在main()方法中，c对象虽然被g()方法引用了，但是由于引用的对象c没有在g()方法中发生逃逸，因此对象c的生命周期还是在main()中的，不会发生逃逸 再看一个栗子 package main type Ret struct { Data *int } func g(p *int) *Ret { var ret Ret ret.Data = p return &ret } func main() { c := new(int) *c = 4 _ = g(c) } 逃逸分析结果 # command-line-arguments ./test_stack.go:10:9: &ret escapes to heap ./test_stack.go:8:6: moved to heap: ret ./test_stack.go:7:17: leaking param: p to result ~r1 level=-1 ./test_stack.go:14:10: new(int) escapes to heap 可以看到，ret和2.2中一样，存在外部引用，发生了逃逸 由于ret.Data是一个指针对象，p赋值给ret.Data后，也伴随p发生了逃逸 main()中的对象c，由于作为参数p传入g()后发生了逃逸，因此c也发生了逃逸 当然，如果定义ret.Data为int(instead of *int)的话，对象p也是不会逃逸的(执行了拷贝) 对开发者的一些建议 大对象按址传递，小对象按值传递 按址传递更高效，按值传递更安全(from William Kennedy) 90%的bug都来自于指针调用 初始化一个结构体，使用引用的方式来传递指针 func r() *Ret{ var ret Ret ret.Data = ... ... return &ret } 只有返回ret对象的引用时才会把对象分配在堆上，我们不必要在一开始的时候就显式地把ret定义为指针 ret = &Ret{} ... return ret 对阅读代码也容易产生误导 参考链接： Golang汇编快速指南 Golang汇编 Golang汇编命令解读 Go语言逃逸分析 go语言连续栈 为何说Goroutine的栈空间可以无限大 Goroutine stack "},"golang/gc.html":{"url":"golang/gc.html","title":"III. Go的垃圾回收","keywords":"","body":"Go的垃圾回收 GC算法 go1.5以前使用标记清除法(Mark-Sweep)： 从程序根节点开始递归遍历所有对象，将能遍历到的对象打上标记 将所有未标记的的对象当作垃圾销毁 不用担心循环引用问题，但是需要一段时间来暂停程序以便标记 go1.5后采用的是三色标记算法(white-grey-black)： 打开write barrier(写屏障) write barrier是编译器在每个内存写操作前生成的一个小的代码段，用于在golang gc时监控指针的引用操作，防止误回收。 将所有escape to heap的对象放入白色集合中 遍历程序栈(非递归)，将遍历到白色集合中的对象放入灰色集合中 遍历灰色集合中的对象，将遍历到的灰色对象放到黑色集合中，并将此灰色对象引用到的白色对象放入灰色集合中 重复4，直到灰色集合中没有对象。在此过程中，若write barrier检测到有黑色对象引用了白色对象，会将此白色对象放入灰色集合中 回收掉白色集合中的对象 STW(Stop the World) golang在进行GC的时候是需要一小段时间来暂停程序的运行的。golang每升级一个大版本，都会对GC做一定的优化，以提升GC效率、缩短STW的时间： go1.4前使用标记清除法，在每次GC标记内存对象时都需要一段STW时间(毫秒到秒级) go1.4并行处理标记和清理协程，但是仍然需要在标记时STW go1.5-1.7使用三色标记算法，只在write barrier和rescan grey stacks时STW(毫秒级) go1.8使用hybrid write barrier，去除了rescan grey stacks的STW，STW时间在10-100微秒 go1.9后提升了对大对象的收集效率，STW时间基本稳定在100微秒内 减轻GC压力 golang gc的时间长短，主要和待GC的对象数量有关，待GC的对象越少，GC的时间越短。 sync.Pool 临时对象池，用于复用已产生的对象，减少程序内对象的数量，减轻GC压力。sync.Pool是并发安全的。 参考链接： gotraining/pointers/gc golang垃圾回收机制 Golang 垃圾回收剖析 知乎: write barrier 为Go语言GC正名－2秒到1毫秒的演变史 go 1.8 eliminate stw stack re-scanning sync.Pool "},"golang/goroutine.html":{"url":"golang/goroutine.html","title":"IV. Go的协程","keywords":"","body":"Go的协程 Go协程和线程的区别 资源调度 线程由内核调度，根据cpu时间片执行抢占式调度 协程由程序调度(runtime包)，执行协同式调度(2中会详述) 内存占用 执行线程所需的栈内存至少是MB级别 执行协程只需要4KB左右的栈内存 上下文切换 线程涉及到用户态和内核态的切换：需要切换通用寄存器(8个)，程序计数器PC，指令寄存器IR，地址寄存器AR，累加寄存器AC，状态寄存器EFLAGS等 协程上下文切换只涉及到栈指针和三个寄存器(程序计数器PC, 栈指针寄存器SP, 数据寄存器DX）的切换 Go协程调度 M：内核线程 G：goroutine，并发的最小逻辑单元，由程序创建 P：处理器，执行G的上下文环境，每个P会维护一个本地的goroutine队列 goroutine有三个状态： waiting: 协程处于全局的队列等待调度 runnable: 协程处于本地队列，等待执行 running: 协程正在运行 G的创建 go调用runtime.newproc()方法来创建G 首先，检查当前P的空闲队列中有没有可用的G，如果有，就直接从中取一个；如果没有，则分配一个新的G，挂载到P的本地队列中 获取了G之后，将调用参数保存到G的栈中，将SP, PC等上下文环境保存到G的sched域中 此时的G处于runnable状态，一旦分配到CPU，就可以进入running状态 G何时被调度 当G被创建时，会立即获得一次运行的机会 如果此时正在运行的P的数量没有达到上限，go会调用runtime.wakep()方法唤醒P；然后调度器选择M绑定P来执行G，必要时会新建M 当此时正在运行的P数量到达上限时，G会进入本地队列等待，当队列前面的G处于以下几种状态时，会触发切换，进入waiting状态： 加锁 io操作 系统调用 运行时间过长(runnable) G的消亡 当G执行完毕返回后，go会调用runtime.exit()方法回收G(包括回收栈指针, 清空寄存器SP、 PC...) 然后将G放入P的空闲队列中，等待runtime.newproc()方法取出 Go channel channel是go协程通信的主要方式。channel不是队列，可以把它理解为一种信号模型(from William Kennedy) channel分为以下两种类型： 一种是无缓冲的channel，在创建channel时不指定长度。无缓冲的channel若没有用户读取，在写入时会始终阻塞，通常可以作为保证信号使用 另一种是缓冲的channel，即buffer channel，在创建channel时指定长度(>=1)。buffer channel为空时会阻塞读，buffer channel满时会阻塞写，可以作为数据传输使用 当buffer channel的长度指定为1时，可以作为延迟保证信号使用(信号发送方发送信号后不阻塞等待接收方接收) channel有以下三种状态： nil：初始化channel。无法读写 open：通过make分配channel空间。可读可写 close: 通过close()关闭channel。close的channel != nil；可以继续从中读取数据，但是不能写入(panic) 基于channel实现的异步日志模型 package main import ( \"fmt\" \"io\" \"os\" \"strconv\" \"sync\" ) var globalWg sync.WaitGroup // Logger struct implement log type Logger struct { channel chan string wg sync.WaitGroup } // NewLog return a new Logger func NewLog(w io.Writer, cap int) *Logger { l := Logger{ channel: make(chan string, cap), } l.wg.Add(1) go func() { defer l.wg.Done() for v := range l.channel { fmt.Fprintln(w, v) } fmt.Println(\"close\") }() return &l } // Close close logger func (l *Logger) Close() { close(l.channel) l.wg.Wait() } // Println print msg func (l *Logger) Println(v string) { select { case l.channel 执行结果： output: 11 0 5 1 2 3 4 8 6 7 9 10 close 可以看到，超过并发数的时候执行了default行为输出了output: 11 当然，我们也可以自定义default行为，比如超过并发数的时候停等一小段时间再写入；或者是不设置default行为，超过并发时阻塞写入直到解除阻塞为止。 这个模型还可以结合协程池grpool，来做一个后台并发写入的日志系统 效率和安全始终是一对矛盾，异步日志虽然能很大程度提高程序效率(不需要等待io操作)；但是如果程序crash，在channel中尚未写入的数据就会丢失。因此在使用的时候也要注意channel的长度设置，如果需要guarantee的，甚至要设置成unbuffer(基本等于同步日志)或者buffer = 1。 Suggestion 单核过多线程未必会提高效率，更多的抢占式调度和上下文切换，有时反而会让效率降低；经验之谈：3 thread per core is best(from William Kennedy) 对于cpu-bound work，高并发未必会提高效率(cpu密集型工作的切换还是需要cpu来调度) 对于io-bound work，应该最大限度地利用并发来提高效率 参考链接： golang之协程 goroutine的生老病死 谈goroutine调度器 Golang协程详解 通用寄存器 gotraining/concurrency/channels "},"golang/stack_trace.html":{"url":"golang/stack_trace.html","title":"V. Go的调试信息","keywords":"","body":"Go的调试信息 当golang程序出现panic的时候会输出一段堆栈调试信息，开发人员可以通过这些调试信息快速地定位问题。 举个栗子 我们通过下面这段程序，直接让程序panic package main func main() { slice := make([]string, 2, 4) Example(slice, \"hello\", 10) } func Example(slice []string, str string, i int) { panic(\"stack trace\") } 运行后输出的调试信息如下 panic: stack trace goroutine 1 [running]: main.Example(0xc42003ff30, 0x2, 0x4, 0x106b75a, 0x5, 0xa) /Users/maniafish/Myworkspace/go_project/src/test/test_panic.go:9 +0x39 main.main() /Users/maniafish/Myworkspace/go_project/src/test/test_panic.go:5 +0x76 exit status 2 第一行是panic信息: stack trace 第二行是发生panic的goroutine及其运行状态(running) 接下来就是发生panic的function调用情况了。我们通常会关注显示的文件和行号，可以快速定位到是哪一行代码抛出的异常 除此之外我们还可以从中看到发生panic的function的输入参数，如main.Example(0xc42003ff30, 0x2, 0x4, 0x106b75a, 0x5, 0xa)对应func Example(slice []string, str string, i int)的三个输入参数： slice: 0xc42003ff30(slice指针地址), 0x2(slice的长度), 0x4(slice的容量) str: 0x106b75a(str字符串头指针地址), 0x5(str字符串长度) i: 0xa(i = 10) 空指针错误 package main import \"fmt\" type S struct { Msg string } func (s *S) f(a int) { fmt.Printf(\"%v: %d\\n\", s.Msg, a) } func main() { Example(nil) } func Example(s *S) { s.f(1) } 以上这段程序运行结果如下： panic: runtime error: invalid memory address or nil pointer dereference [signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x1095257] goroutine 1 [running]: main.(*S).f(0x0, 0x1) /Users/maniafish/Myworkspace/go_project/src/test/test_panic.go:10 +0x57 main.Example(0x0) /Users/maniafish/Myworkspace/go_project/src/test/test_panic.go:18 +0x34 main.main() /Users/maniafish/Myworkspace/go_project/src/test/test_panic.go:14 +0x2a exit status 2 panic信息(invalid memory address or nil pointer dereference)告诉我们是无效的地址调用 我们通过main.(*S).f(0x0, 0x1)的第一个参数，可以知道这个指针*S的方法f()调用时使用的是空指针 然后通过main.Example(0x0)，知道这个空指针是通过Example()方法传进来的，定位到了问题所在。 参考链接： Go stack trace "},"golang/composition.html":{"url":"golang/composition.html","title":"VI. Go的interface","keywords":"","body":"Go的interface go的interface类型定义了一组方法，如果某个对象实现了某个interface的所有方法，此对象就实现了此interface。 interface focus on what the data does, instead of what the data is(From William Kennedy) interface能够帮助我们更好地做泛型编程，实现代码逻辑的抽象和灵活组合，更方便地进行面向对象的编程。 下面通过一个例子来说明一下go中基于interface的编程设计思路。 场景1 设计思路 定义结构体A，实现方法Store() 定义结构体B，实现方法Pull() 定义System封装A和B，并通过System向外提供api 代码示例 // A is a system for data collection type A struct { ... } // Store function for storing data func (a *A) Store(data interface{}) { ... } // B is a system for data pulling type B struct { ... } // Pull function for pulling data func (b *B) Pull(data interface{}) { ... } // System wraps A and B together type System struct { A B } // Api providing api for users func Api(s *System, data []interface{}) error { ... for _, v := range data { s.Store(v) } ... dp := ... err = s.Pull(dp) ... return } func main() { a := A { ... } b := B { ... } s := System{a, b} data := ... err := Api(&s, data) if err != nil { ... } ... } 场景2 设计思路 系统组件A1~A3都实现了同样的方法Store()，B1~B3实现了Pull()，考虑使用interface进行抽象解耦 system无需关心具体的A和B，只需要做interface的组合即可 代码示例 // Storer is an interface for data collection type Storer interface { Store(data interface{}) } // A1 is a system for data collection type A1 struct { ... } // Store function for storing data func (a *A1) Store(data interface{}) { ... } // define A2 ~ A3 implementing Storer ... // Puller is an interface for data pulling type Puller interface { Pull(data interface{}) } // B1 is a system for data pulling type B1 struct { ... } // Pull function for pulling data func (b *B1) Pull(data interface{}) { ... } // define B2 ~ B3 implementing Puller ... // System wraps Storer and Puller together type System struct { Storer Puller } // Api providing api for users func Api(s *System, data []interface{}) error { ... for _, v := range data { s.Store(v) } ... dp := ... err = s.Pull(dp) ... return } func main() { ... a := A1 { ... } b := B1 { ... } // s can be any composition of An and Bn s := System{&a, &b} data := ... err := Api(&s, data) if err != nil { ... } ... } 进一步抽象 我们希望Api()方法变得更加通用，它无需关心System的具体结构，只关心System提供的Pull()和Store()方法 因此我们可以定义一个PullStorer来做Puller和Storer的interface组合，这样一来只要是实现了Puller和Storer的结构体，都可以由Api()方法调用来对外提供服务 ... // PullStorer is an interface implementing Storer and Puller type PullStorer interface { Storer Puller } // Api providing api for users func Api(s PullStorer, data []interface{}) error { ... for _, v := range data { s.Store(v) } ... dp := ... err = s.Pull(dp) ... return } func main() { ... // s can be any composition of An and Bn s := System{ ... } data := ... err := Api(&s, data) if err != nil { ... } ... } interface滥用问题 我们现在定义了以下interface // Storer is an interface for data collection type Storer interface { Store(data interface{}) } // Puller is an interface for data pulling type Puller interface { Pull(data interface{}) } // PullStorer is an interface implementing Storer and Puller type PullStorer interface { Storer Puller } 我们的Api()里关注的是Store()和Pull()方法 // Api providing api for users func Api(s PullStorer, data []interface{}) error { ... for _, v := range data { s.Store(v) } ... dp := ... err = s.Pull(dp) ... return } 这个传入Api()的s，可以是任意实现了Store()方法的An和任意实现了Pull()方法的Bn的组合 我们在Api()中调用s.Store()，实际上调用的是s.Storer.Store()；调用s.Pull()，实际上调用的是s.Puller.Pull() 既然我们的Api()关注的只是Puller和Storer，那么我们为什么要额外让他们组合成一个PullStorer来传入呢 基于以上设计思路，我们可以去掉System和PullStorer，得到以下简洁且可扩展性强的代码 // Storer is an interface for data collection type Storer interface { Store(data interface{}) } // A1 is a system for data collection type A1 struct { ... } // Store function for storing data func (a *A1) Store(data interface{}) { ... } // define A2 ~ A3 implementing Storer ... // Puller is an interface for data pulling type Puller interface { Pull(data interface{}) } // B1 is a system for data pulling type B1 struct { ... } // Pull function for pulling data func (b *B1) Pull(data interface{}) { ... } // define B2 ~ B3 implementing Puller ... // Api providing api for users func Api(s Storer, p Puller, data []interface{}) error { ... for _, v := range data { s.Store(v) } ... dp := ... err = p.Pull(dp) ... return } func main() { ... a := A1 { ... } b := B1 { ... } // a can be any An, b can be any Bn data := ... err := Api(&a, &b, data) if err != nil { ... } ... } "},"golang/operator.html":{"url":"golang/operator.html","title":"VII. Go的变量作用域","keywords":"","body":"Go的变量作用域 变量作用域 全局变量 package a var g int // 本包内可见 var G int // 外部import a后可见 局部变量 func Test() { var a int // a在Test()内可见 ... for i := 1; i 参数变量 func Test(a int) { // a在Test()方法内可见，在Test()外赋值。 ... } 局部变量声明后未使用会编译失败；参数变量在function内可以不使用，比如以下情况也是可以编译通过的。 func main() { a := 1 Test(a) // a作为参数调用 } func Test(a) { // a在Test()内部没有使用 fmt.Println(\"test\") } 对按值传参的情况，方法内对参数a的修改不影响传入前的原参数a 对按址传参的情况，方法内对参数a的修改也会影响到传入前的原参数a 循环并发中的变量传参问题 理解了go中的变量作用域后，我们来看看下面这段代码 package main import ( \"fmt\" \"sync\" ) var wg sync.WaitGroup func main() { for i := 0; i 输出结果如下 10 10 10 10 10 10 10 10 10 10 这是因为变量i作为局部变量，同时在for循环和go协程中被引用，循环递增和打印的是同一个地址的数据 实际上这个输出是无法预期的，这里都输出10是因为后台协程完成创建时，for循环已经完成了对i的递增操作 如果要想让循环中的go协程如我们预期的一样输出1~10的值，要采取以下写法，使用参数变量 package main import ( \"fmt\" \"sync\" ) var wg sync.WaitGroup func main() { for i := 0; i Go的:=操作符 Go的:=操作符用于声明变量的同时给变量赋值，它也会定义新变量的作用域。以下面这段代码为例 package main import ( \"fmt\" \"sync\" ) var wg sync.WaitGroup func main() { a := 1 fmt.Printf(\"a in main: %p, %d\\n\", &a, a) // a in main: 0xc420016090, 1 // 在main中声明了变量a，地址为0xc420016090，并给a赋值为1 for a := 2; a "},"golang/slice.html":{"url":"golang/slice.html","title":"VIII. Go的slice","keywords":"","body":"Go的slice go的slice可以理解为一种动态可变长的数组，初始化时可以指定长度len和容量cap；可以通过append()方法在slice末尾追加元素。 一个append的栗子 package main import \"fmt\" func main() { s0 := []int{1, 2, 3, 4} fmt.Printf(\"s0: %v, len(s): %d, cap(s): %d\\n\\n\", s0, len(s0), cap(s0)) // s0: [1 2 3 4], len(s): 4, cap(s): 4 // 初始化一个slice s0，len = cap = 4(不指定cap的情况下，默认cap = len) s1 := s0[:2] fmt.Printf(\"s1: %v, len(s1): %d, cap(s1): %d\\n\\n\", s1, len(s1), cap(s1)) // s1: [1 2], len(s1): 2, cap(s1): 4 // 取s0的前个元素构成s1，len = 2, cap = 4 s2 := append(s1, 5, 6, 7) fmt.Printf(\"s2: %v, len(s2): %d, cap(s2): %d\\n\", s2, len(s2), cap(s2)) fmt.Printf(\"s0: %v, len(s0): %d, cap(s0): %d\\n\\n\", s0, len(s0), cap(s0)) // s2: [1 2 5 6 7], len(s2): 5, cap(s2): 8 // append 5, 6, 7到s1，此时空间不足，按照两倍cap动态扩容，分配一块新的内存空间给s2 // s0: [1 2 3 4], len(s0): 4, cap(s0): 4 // s0不变 s3 := append(s1, 8, 9) fmt.Printf(\"s3: %v, len(s3): %d, cap(s3): %d\\n\", s3, len(s3), cap(s3)) fmt.Printf(\"s0: %v, len(s0): %d, cap(s0): %d\\n\\n\", s0, len(s0), cap(s0)) // s3: [1 2 8 9], len(s3): 4, cap(s3): 4 // append 8, 9到s1，空间足够，无须扩容 // s0: [1 2 8 9], len(s0): 4, cap(s0): 4 // s0的后两个元素被append的8, 9取代 } 通过以上栗子可以看出： go的slice只有在空间不足时，才会进行动态扩容，分配新的内存地址。所以在日常开发的时候，要尽量避免以下操作： func A(i []int){ ... b := append(i, ...) ... } func main(){ ... a := []int{...} A(a[:2]) ... } 要防止slice b的操作影响到slice a，可以使用copy()方法 func A(i []int){ ... b := append(i, ...) ... } func main(){ ... a := []int{...} i := make([]int, 2) copy(i, a[:2]) A(i) ... } go的slice执行的动态扩容是一个内存拷贝的操作，分配一块新的2倍cap的空间给slice。因此在平时开发的时候，应该尽可能地分配确定的len和cap给slice，防止频繁append进行内存拷贝带来的性能损耗。 比如以下这段代码 func main() { a := make([]int, 0) for i := 0; i 可以改写成下面这样，使用确定的len func main() { a := make([]int, 10) for i := 0; i 即便在不确定len的情况下，也应该尽量预留一个相对充足的cap，来减少2倍cap扩容的次数 func main() { a := make([]int, 0, 10) for i := 0; i 默认按地址传递 通过1.1中的栗子 func A(i []int){ ... b := append(i, ...) // 操作b的时候也会影响到a ... } func main(){ ... a := []int{...} A(a[:2]) ... } 就可以知道，go中slice传参默认是按址传递的，因此在function内对传入的slice进行写操作的时候要注意：这种操作是会影响到function调用方的原slice的。go的map也是默认按址传递 "},"golang/defer.html":{"url":"golang/defer.html","title":"IX. Go的defer处理","keywords":"","body":"Go的defer处理 package main import \"fmt\" func deferFunc() (b int) { b = 1 a := true defer func() { b = 2 }() return } func main() { fmt.Println(deferFunc()) // 这里打印出来的是1，而不是2 // https://stackoverflow.com/questions/37248898/how-does-defer-and-named-return-value-work-in-golang } TODO: go的defer底层机制 "},"golang/rand.html":{"url":"golang/rand.html","title":"X. Go随机数生成的并发安全问题","keywords":"","body":"Go随机数生成的并发安全问题 问题分析 golang中的随机数生成是由官方包math/rand来处理的，使用方法很简单： package main import ( \"fmt\" \"math/rand\" \"time\" ) func main() { // 使用当前的纳秒时间作为随机因子，生成一个rand对象 r := rand.New(rand.NewSource(time.Now().UnixNano())) // 生成100以内的随机数 fmt.Println(r.Intn(100)) } 在实际的使用场景中，我们经常会碰到需要重复生成随机数的情况。最常见的就是，在调用某个方法A时，在A的逻辑中需要用到一个范围内的随机数，我们就在A方法中采用r.Intn(n)生成这样一个随机数；由于每次调用A时，都要使用rand对象r来生成一个随机数，因此我们通常会对这个rand对象做提前定义，以免每次生成随机数都要重复创建对象造成不必要的开销。 package main import ( \"math/rand\" \"time\" ) var Rand = rand.New(rand.NewSource(time.Now().UnixNano())) func A() { ... p := Rand.Intn(n) ... } func main() { ... A() ... } 这种做法在平时单协程内做随机数生成时没有任何问题，但是一旦碰到高并发的情况，问题就来了。我们来看下面这段服务器代码。 package main import ( \"log\" \"math/rand\" \"net/http\" \"time\" ) // base64使用的字符集 const letterBytes = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789/+=\" var letterRand = rand.New(rand.NewSource(time.Now().UnixNano())) func main() { handler := func(w http.ResponseWriter, req *http.Request) { body := make([]byte, 1024) for i := range body { body[i] = letterBytes[letterRand.Intn(len(letterBytes))] } w.Write(body) } http.HandleFunc(\"/random_bytes\", handler) log.Fatal(http.ListenAndServe(\":8080\", nil)) } 这段代码的功能是返回长度为1k的随机base64字符串，接下来，我们通过ab压测工具来并发访问一下这个接口 $ ab -n 10000 -c 100 '127.0.0.1:8080/random_bytes' This is ApacheBench, Version 2.3 Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking 127.0.0.1 (be patient) Completed 1000 requests Completed 2000 requests Completed 3000 requests Completed 4000 requests Completed 5000 requests Completed 6000 requests Completed 7000 requests Completed 8000 requests Completed 9000 requests Completed 10000 requests Finished 10000 requests Server Software: Server Hostname: 127.0.0.1 Server Port: 8080 Document Path: /random_bytes Document Length: 1024 bytes Concurrency Level: 100 Time taken for tests: 1.240 seconds Complete requests: 10000 Failed requests: 94 (Connect: 0, Receive: 0, Length: 94, Exceptions: 0) Total transferred: 11322542 bytes HTML transferred: 10143744 bytes Requests per second: 8063.88 [#/sec] (mean) Time per request: 12.401 [ms] (mean) Time per request: 0.124 [ms] (mean, across all concurrent requests) Transfer rate: 8916.37 [Kbytes/sec] received Connection Times (ms) min mean[+/-sd] median max Connect: 0 5 2.3 5 15 Processing: 0 7 3.7 6 36 Waiting: 0 5 3.7 5 36 Total: 1 12 3.6 12 38 Percentage of the requests served within a certain time (ms) 50% 12 66% 13 75% 13 80% 14 90% 16 95% 18 98% 22 99% 27 100% 38 (longest request) 这里我们设定的是100并发，共10000个请求，可以看到，其中有94个请求都失败了。 Failed requests: 94 检查服务端输出，发现抛出了panic http: panic serving 127.0.0.1:57330: runtime error: index out of range goroutine 19898 [running]: net/http.(*conn).serve.func1(0xc42054c320) /go/src/net/http/server.go:1697 +0xd0 panic(0x1250aa0, 0x13f9e20) /go/src/runtime/panic.go:491 +0x283 math/rand.(*rngSource).Uint64(...) /go/src/math/rand/rng.go:246 math/rand.(*rngSource).Int63(0xc420097500, 0xf67aee49c000000) /go/src/math/rand/rng.go:231 +0x8a math/rand.(*Rand).Int63(0xc42007cbd0, 0xf67aee49c000000) /go/src/math/rand/rand.go:82 +0x33 math/rand.(*Rand).Int31(0xc42007cbd0, 0xf67aee4) /go/src/math/rand/rand.go:96 +0x2b math/rand.(*Rand).Int31n(0xc42007cbd0, 0xc400000041, 0xc400000019) /go/src/math/rand/rand.go:131 +0x4f math/rand.(*Rand).Intn(0xc42007cbd0, 0x41, 0x19) /go/src/math/rand/rand.go:145 +0x45 main.main.func1(0x13d0da0, 0xc420561260, 0xc4203d8d00) /go_project/src/test/test_server/main.go:19 +0xaf net/http.HandlerFunc.ServeHTTP(0x12af8a0, 0x13d0da0, 0xc420561260, 0xc4203d8d00) /go/src/net/http/server.go:1918 +0x44 net/http.(*ServeMux).ServeHTTP(0x1403920, 0x13d0da0, 0xc420561260, 0xc4203d8d00) /go/src/net/http/server.go:2254 +0x130 net/http.serverHandler.ServeHTTP(0xc420082dd0, 0x13d0da0, 0xc420561260, 0xc4203d8d00) /go/src/net/http/server.go:2619 +0xb4 net/http.(*conn).serve(0xc42054c320, 0x13d1220, 0xc42027c800) /go/src/net/http/server.go:1801 +0x71d created by net/http.(*Server).Serve /go/src/net/http/server.go:2720 +0x288 根据报错信息，我们可以定位到panic位置在官方包math/rand/rng.go: func (rng *rngSource) Uint64() uint64方法的以下行： 实际上rand包在生成随机数时，底层都是通过上面这个方法，从vec数组中取出int64元素来进行计算，返回一个伪随机数的。这个方法中对数组的两个索引值tap和feed，都存在着一个递减到0以下时增加_LEN值的非原子操作。 也就是说，在并发环境下，如果其中一个协程A对tap(或feed)递减到0以下，在重设tap(或feed)前，协程B同时在进行以下操作 x := rng.vec[rng.feed] + rng.vec[rng.tap] rng.vec[rng.feed] = x 就会因为取数组的索引为负数(如vec[-1])，导致panic。 全局rand对象 我们在生成rand对象时使用的NewSource()方法，在官方包里有明确注释说明，使用该方法返回的对象是非协程安全的 事实上，官方的rand包里提供了一个全局的rand对象var globalRand = New(&lockedSource{src: NewSource(1).(Source64)})，这个对象使用的是lockedSource，通过加锁来保证随机数生成时的协程安全。在使用时，直接通过rand.Intn(n)调用官方包方法，默认就会使用这个globalRand对象来生成随机数。 我们将之前服务端生成随机字符串的那行代码改为 body[i] = letterBytes[rand.Intn(len(letterBytes))] 使用官方包的全局rand对象来生成随机数，然后通过ab压测看一下效果 $ ab -n 10000 -c 100 '127.0.0.1:8080/random_bytes' This is ApacheBench, Version 2.3 Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking 127.0.0.1 (be patient) apr_socket_recv: Connection refused (61) maniafish:tech_talk/ (master✗) $ ab -n 10000 -c 100 '127.0.0.1:8080/random_bytes' This is ApacheBench, Version 2.3 Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking 127.0.0.1 (be patient) Completed 1000 requests Completed 2000 requests Completed 3000 requests Completed 4000 requests Completed 5000 requests Completed 6000 requests Completed 7000 requests Completed 8000 requests Completed 9000 requests Completed 10000 requests Finished 10000 requests Server Software: Server Hostname: 127.0.0.1 Server Port: 8080 Document Path: /random_bytes Document Length: 1024 bytes Concurrency Level: 100 Time taken for tests: 7.892 seconds Complete requests: 10000 Failed requests: 0 Total transferred: 11429968 bytes HTML transferred: 10240000 bytes Requests per second: 1267.06 [#/sec] (mean) Time per request: 78.923 [ms] (mean) Time per request: 0.789 [ms] (mean, across all concurrent requests) Transfer rate: 1414.30 [Kbytes/sec] received Connection Times (ms) min mean[+/-sd] median max Connect: 0 50 297.4 16 2958 Processing: 0 28 55.7 22 923 Waiting: 0 22 54.0 18 914 Total: 1 78 302.0 38 2991 Percentage of the requests served within a certain time (ms) 50% 38 66% 43 75% 46 80% 48 90% 57 95% 78 98% 888 99% 2927 100% 2991 (longest request) 可以看到，现在没有失败的请求了 Complete requests: 10000 Failed requests: 0 但是使用全局rand对象有一个问题，由于全局对象使用的随机因子固定是1，因此每次重启服务器后，顺序生成的随机数都会是一样的。 以上面那段服务端代码为例，每次重启程序后，访问返回的随机字符串都是： $ curl '127.0.0.1:8080/random_bytes' KVLoZ6Oavp=40jWjUThPTPHn/h/x3fqn5PyFwFOPxOessrsjXCLqNjOOCsn8lTT4ZnPrMq+4Q+hymRlJWWcWZ2sRFr6ZbGasr6usOZEw/aJaJrxRbr=5Qmq24/KoAkWq=lcTTzGtC1NnNGLLvNkA44k9yIkW4fcCGAsjLn56RHFf8zNBmfZof1Oj8s3tmfawtksZ8b8gyBPBUO2rQ/HPd1M4eVw0EZ+aGxY4UcJk5XbTYeNozbgVKfj5WZNYoT=SYmTE7dTRZ3=D3v+couthoigsrYc9c9uLNhSA9JUHWUIrHsdstD8=KclVXHeUCI5VI=4g1MlAr/Pgz/jxm8Ino9mxkv1JTvOq=g4kYNLBs3Wf6Pa62ws/dVsiBUHsF=bJqVG5XMOqwmD46iPTBJIlXyESXmy5RoEOD=ONq4Za2nEwcJcmHQtwzuAyoRShs7zapSiT=hOlM+yte9VgJF5bo6T2A31A4EEhn7=JqK=MbGnRYUtzyTZfvyoAd3vBXIFSFTp+2kZXVU14LgaQ6wnLeEdEQ=V+LcehPjIbtjHLeIJo6p=YFRq6/DwCZJ8TQmZClVckA5WYDfyRO5/XELRqKKudG1PA121ThZlui39HMmpOUCFw=jWKZu0IIsnOnk35Jq2ODTAPZGa2M0i0+3+ibAngLLhQNOcB8f1kDVrkS5MKM4YpzGXCDJJsuY=H4c1vg288l6SxAYTqARMAroM15r+HkkmZF0nVtNlLDWmkQdfB7Cd0Wyw4ACGxklqgX0l12S5xsou58I/s0z9RXr9u0DuXdNaa=LEu1nkiPaLB5sDCNCtUgm0M26bMvCyaa4pHiqKa/HNqm1qTZtCoFsFPqKXFLe5MAPNW=ldNurqh8GtHV14dcD9AEpkptPitNcdgERJVhG2MqfLV6tDjyHrCTOCmk6oEzGKQ24/1Un1HdqRIPW+qyDsfgShBIIDu6nk0wrQKcd/3if66k49TUA2bSDdhf/goqCo4i0hxAJJwTNdh9hIQr21/=8D=yc9YQBfH 另外一个问题是，加锁会带来严重的性能下降。之前使用本地生成的rand对象，压测的rps为 Requests per second: 8063.88 [#/sec] (mean) 使用全局对象后，rps连原来的1/6都达不到 Requests per second: 1267.06 [#/sec] (mean) 开发建议 鉴于官方包的全局rand对象存在 随机因子固定 加锁效率低下 两大缺陷；不建议直接调用rand.Intn(n)，使用全局rand对象 不同协程使用各自独立的rand对象来生成随机数 对golang http server而言，每次收到请求时，底层都会启动新的goroutine来进行处理，因此每次handler处理都需要使用新的rand对象；虽然增加了一点回收开销，但是比起用一个对象同步加锁的开销已经是九牛一毛了 随机数的生成受限于生成rand对象时使用的随机因子，若随机因子相同，则生成的随机数序列就是重复的。建议使用纳秒级时间戳。 "},"go_tool/go_test.html":{"url":"go_tool/go_test.html","title":"XI. Go程序基准测试","keywords":"","body":"Go程序基准测试 golang自带了程序单元测试工具go test，可以用来做程序的单元测试和性能测试，简单的使用教程可以参考: golang 编写测试用例 高效优雅地编写测试用例 这里推荐一个用于编写golang测试用例的第三方库：goconvey。goconvey是一款针对Golang的测试框架，可以管理和运行测试用例，同时提供了丰富的断言函数，并支持很多 Web 界面特性。 goconvey实践 通过go get github.com/smartystreets/goconvey即可完成安装 一个简单的狄波拉契序列的栗子，源码fibo.go如下 package gotest import ( \"errors\" ) // fibonacci 斐波那契闭包 func fibonacci() func() int { a, b := 0, 1 return func() int { a, b = b, a+b return a } } // Fibo 返回斐波那契序列的第n个元素 func Fibo(n int) (int, error) { if n 测试代码fibo_test.go如下 package gotest import ( \"testing\" . \"github.com/smartystreets/goconvey/convey\" ) func TestFibo(t *testing.T) { Convey(\"Fibonacci test\\n\", t, func() { Convey(\"fibonacci first element\\n\", func() { res, err := Fibo(1) So(res, ShouldEqual, 1) So(err, ShouldBeNil) }) Convey(\"fibonacc 10th element\\n\", func() { res, err := Fibo(10) So(res, ShouldEqual, 55) So(err, ShouldBeNil) }) Convey(\"fibonacci 50th element\\n\", func() { res, err := Fibo(50) So(res, ShouldEqual, 12586269025) So(err, ShouldBeNil) }) Convey(\"invalid input num\\n\", func() { _, err := Fibo(0) So(err, ShouldNotBeNil) _, err = Fibo(-1) So(err, ShouldNotBeNil) }) }) } 在项目目录下执行goconvey，会在页面输出测试结果 可以看到，这里有四个测试用例，每个用例有两个断言，断言成功会打勾(错误会打叉)；所有断言成功执行则测试用例“pass” goconvey提供的断言名称都十分直观，比如\"ShouldBeNil\", \"ShouldNotEqual\"等，完整的断言定义可以参考assertions.go 这个页面在执行goconvey命令后会自动弹出，也可以通过http://127.0.0.1:8080/访问到 红框标识的部分是本次单元测试的包，点击可以看到这个包内代码的覆盖率情况，显示页面如下 Go基准测试选项 推荐的golang基准测试指令: go test -bench=\"BenchmarkLogger\" -benchtime=3s -run=none -count=5 -cpuprofile=cpu.prof -bench: 执行哪些基准测试方法 这里是执行所有匹配了\"BenchmarkLogger\"的基准测试方法 如果希望执行包内所有的基准测试方法，则设置-bench=.即可 支持正则表达式，如^BenchmarkLogger$，就能唯一定位到BenchmarkLogger方法 -benchtime: 执行每个基准测试方法的时间，默认为1s，一般不超过3s -count: 执行几次基准测试 -run: 执行哪些单元测试用例 -run=none表示只执行基准测试，不执行单元测试用例 -cpuprofile: 生成用于做性能分析的cpu profile文件，具体分析方法可以参考: Go代码调优利器pprof + go-torch "},"go_tool/delve.html":{"url":"go_tool/delve.html","title":"XII. Go调试工具delve","keywords":"","body":"Go调试工具delve 开发程序过程中调试代码是开发者经常要做的一件事情，当然Go语言可以通过Println之类的打印数据来调试，但是每次都需要重新编译，这是一件相当麻烦的事情。庆幸的是golang内置支持gdb来进行调试，但是对于golang这种多用于并发编程的语言，gdb调试对于goroutine协程来说并不是特别友好。因此，我们需要一个更加适合golang的调试器。这里介绍一个github上star数超高，简单易用的golang调试器 —— delve。 安装 按照github官网上的教程进行安装即可，首先检查xcode-select是否安装 $ xcode-select -v 通过go get安装（鉴于各人代理加速的情况，可能会很慢，请耐心等待） $ go get -u github.com/go-delve/delve/cmd/dlv TODO "},"go_tool/trace.html":{"url":"go_tool/trace.html","title":"XIII. Go程序运行跟踪器trace","keywords":"","body":"Go程序运行跟踪器trace TODO 参考链接: 7种go程序性能分析的方法 深入浅出 Go trace "},"go_tool/go-torch.html":{"url":"go_tool/go-torch.html","title":"XIV. Go代码调优利器pprof + go-torch","keywords":"","body":"Go代码调优利器go-torch pprof的使用 如何分析我们golang服务端代码的运行性能，并且找到程序的性能瓶颈和优化点呢？golang提供了pprof工具来帮助我们分析cpu、堆栈、goroutine、锁占用等程序运行信息。简单的使用教程可以参考：Golang 大杀器之性能剖析 PProf 对于golang的http server应用，如果使用的是默认的http handler，只需要import _ \"net/http/pprof\"；pprof会自动在你的http server上注册以下接口: /debug/pprof/ /debug/pprof/cmdline /debug/pprof/profile /debug/pprof/symbol /debug/pprof/trace 若你使用的是其他的第三方库进行路由注册，如github.com/gorilla/mux，就需要自行注册pprof接口: import ( \"github.com/gorilla/mux\" \"net/http/pprof\" ) func AttachProfiler(router *mux.Router) { router.HandleFunc(\"/debug/pprof/\", pprof.Index) router.HandleFunc(\"/debug/pprof/cmdline\", pprof.Cmdline) router.HandleFunc(\"/debug/pprof/profile\", pprof.Profile) router.HandleFunc(\"/debug/pprof/symbol\", pprof.Symbol) } go-torch的使用 pprof可以为我们提供基本的性能分析图，如果需要更加直观的可视化性能调优，可以使用第三方火焰图工具go-torch 安装Flame Graph git clone https://github.com/brendangregg/FlameGraph.git cp FlameGraph/flamegraph.pl /usr/local/bin 安装go-torch go get -v github.com/uber/go-torch 使用go-torch分析程序代码，比如以下这段服务器代码： package main import ( \"log\" \"math/rand\" \"net/http\" _ \"net/http/pprof\" \"time\" ) // base64使用的字符集 const letterBytes = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789/+=\" func main() { handler := func(w http.ResponseWriter, req *http.Request) { body := make([]byte, 2048) for i := range body { body[i] = letterBytes[rand.Intn(len(letterBytes))] } time.Sleep(100 * time.MillisecondSecond) w.Write(body) } http.HandleFunc(\"/random_bytes\", handler) log.Fatal(http.ListenAndServe(\":8080\", nil)) } 这段代码的功能很简单，就是访问127.0.0.1:8080/random_bytes接口，100毫秒后返回长度为2048的随机字符串 执行go run main.go运行程序后，使用ab工具持续压测接口 $ ab -n10000 -c 20 '127.0.0.1:8080/random_bytes' 于此同时，通过go-torch获取性能分析数据，采样时间为30秒，采样结果输出到main.svg文件中 $ go-torch -u http://127.0.0.1:8080/debug/pprof/profile -t 30 -f main.svg 采样完成后，打开main.svg即可看到分析结果，横轴的宽度表示当前方法运行时间占总时间的百分比 参考链接: go-torch官网 Flame Graphs 代码调优利器-火焰图 "},"golang/container.html":{"url":"golang/container.html","title":"XV. Go实现队列、堆、栈","keywords":"","body":"Go实现队列、堆、栈 用golang标准库的container包，可以轻松地实现队列、堆、栈的数据结构 container/list list添加元素 func (l *List) PushFront(v interface{}) *Element: 添加 v 至开头 func (l *List) PushBack(v interface{}) *Element: 添加 v 至末尾 func (l *List) InsertBefore(v interface{}, mark *Element) *Element: 在 mark 元素前添加 v func (l *List) InsertAfter(v interface{}, mark *Element) *Element: 在 mark 元素后添加 v 以上方法返回的均为被添加的元素 v list删除元素 func (l *List) remove(e *Element) *Element: 移出 e，并返回 e func (l *List) Init() *List: 清空 l，并返回 l list移动元素 func (l *List) MoveToFront(e *Element): 将 e 移动到开头 func (l *List) MoveToBack(e *Element): 将 e 移动到末尾 func (l *List) MoveBefore(e, mark *Element): 将 e 移动到 mark 前 func (l *List) MoveAfter(e, mark *Element): 将 e 移动到 mark 后 以上方法中的 e 和 mark 需要在 l 内，且不为nil list实现队列和栈 package main import ( \"container/list\" \"fmt\" ) func main() { q := list.New() // 作为栈使用 // 入栈 q.PushBack(1) q.PushBack(2) q.PushBack(3) q.PushBack(4) // 此时栈元素为1,2,3,4; 栈顶元素为4 // 遍历并弹出栈元素，先入后出，出栈顺序：4, 3, 2, 1 for q.Len() > 0 { fmt.Println(q.Remove(q.Back())) } // 作为队列使用 // 入队 q.PushBack(1) q.PushBack(2) q.PushBack(3) q.PushBack(4) // 此时队列元素为1,2,3,4; 队头元素为1 // 遍历并弹出队列元素，先入先出，出队顺序：1, 2, 3, 4 for q.Len() > 0 { fmt.Println(q.Remove(q.Front())) } } container/heap heap包提供了以下方法进行堆操作： func Init(h Interface): 初始化一个堆 func Pop(h Interface) interface{}: 弹出堆顶元素(交换堆顶和末尾元素，调整堆并弹出末尾元素) func Push(h Interface, x interface{}): 将 x 加入 h 末尾，并调整堆 func Remove(h Interface, i int) interface{}: 删除 h 第 i 个位置的元素(交换第 i 个位置的元素和末尾元素，调整堆并弹出末尾元素) func Fix(h Interface, i int): 当 h 中第 i 个位置的元素变化时，进行堆调整 heap实现最小堆 heap包构建堆的前提是输入一个实现了以下方法的接口: type Interface interface { // Len is the number of elements in the collection. Len() int // Less reports whether the element with // index i should sort before the element with index j. Less(i, j int) bool // Swap swaps the elements with indexes i and j. Swap(i, j int) // add x as element Len() Push(x interface{}) // remove and return element Len() - 1. Pop() interface{} } 其实前三个方法就是go实现排序所需的Interface接口方法，详见：Go标准库sort；后两个方法的Push用于将元素添加到末尾，Pop用于将末尾的元素弹出。以下是最小堆实现： package main import ( \"container/heap\" \"fmt\" ) type IntHeap []int func (h IntHeap) Len() int { return len(h) } func (h IntHeap) Less(a, b int) bool { return h[a] 0 { fmt.Println(heap.Pop(&h)) } } 若要实现最大堆，只需要修改Less()方法即可： func (h IntHeap) Less(a, b int) bool { return h[a] > h[b] } heap实现优先级队列 基于heap的特性，我们可以实现更加复杂的数据结构：以priority最大值优先的优先级队列 package main import ( \"container/heap\" \"fmt\" ) type Item struct { Priority int // 优先级 Value string // 数据 } type PriorityQueue []*Item func (q PriorityQueue) Len() int { return len(q) } // Less 把优先级高的元素往前排 func (q PriorityQueue) Less(a, b int) bool { return q[a].Priority > q[b].Priority } func (q PriorityQueue) Swap(a, b int) { q[a], q[b] = q[b], q[a] } func (q *PriorityQueue) Push(x interface{}) { *q = append(*q, x.(*Item)) } func (q *PriorityQueue) Pop() interface{} { n := q.Len() x := (*q)[n-1] *q = (*q)[0 : n-1] return x } func main() { h := PriorityQueue([]*Item{ &Item{1, \"d1\"}, &Item{2, \"d2\"}, &Item{5, \"d5\"}, }) heap.Init(&h) heap.Push(&h, &Item{3, \"d3\"}) // 遍历弹出堆顶元素，依次为d5, d3, d2, d1 for h.Len() > 0 { fmt.Println(heap.Pop(&h)) } } 参考链接： golang package list golang package heap "},"kubernetes/traefik.html":{"url":"kubernetes/traefik.html","title":"I. Kubernetes使用Traefik反向代理","keywords":"","body":"Kubernetes使用Traefik反向代理 Traefik Traefik是一个云原生边界网关，可以实现http反向代理和负载均衡，并且可以作为k8s集群的Ingress Controller，结合Ingress实现k8s的服务注册和路由等功能。 官网地址 github地址 反向代理实践(Deployment模式) 准备工作 启动k8s: mac下载桌面版docker，打开Enable Kubernetes即可启动 安装MiniKube 启动MiniKube: minikube start 运行Traefik 下载github代码: git clone https://github.com/containous/traefik 进入traefik/examples/k8s目录 deployment模式部署，创建对外服务：kubectl create -f traefik-deployment.yaml 加载资源: kubectl apply -f traefik-deployment.yaml 去除资源：kubectl delete -f traefik-deployment.yaml kind: Service apiVersion: v1 metadata: name: traefik-ingress-service namespace: kube-system spec: selector: k8s-app: traefik-ingress-lb ports: - protocol: TCP port: 80 nodePort: 32044 name: web - protocol: TCP port: 8080 nodePort: 30423 name: admin type: NodePort 默认type: NodePort会随机指定一个对外服务端口，若需要设定指定的端口，要在ports里配置实际的nodePort kubectl get pods -n kube-system可以看到trafik-ingress-controller已启动 NAME READY STATUS RESTARTS AGE coredns-86c58d9df4-cffc8 1/1 Running 0 8h coredns-86c58d9df4-n5dsv 1/1 Running 0 8h etcd-minikube 1/1 Running 0 7h kube-addon-manager-minikube 1/1 Running 0 7h kube-apiserver-minikube 1/1 Running 0 7h kube-controller-manager-minikube 1/1 Running 0 7h kube-proxy-ltkl5 1/1 Running 0 8h kube-scheduler-minikube 1/1 Running 1 7h storage-provisioner 1/1 Running 0 8h traefik-ingress-controller-8c8b85bbc-9kn5p 1/1 Running 0 11m kubectl get services -n kube-system可以看到服务启动的ip和端口 NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kube-dns ClusterIP 10.96.0.10 53/UDP,53/TCP 7h traefik-ingress-service NodePort 10.98.51.165 80:32044/TCP,8080:30423/TCP 11m 访问$(minikube ip):32044可以看到当前对外端口返回的页面 访问$(minikube ip):30423可以看到当前Traefik的dashboard 配置服务路由 启动后端服务 kubectl apply -f cheese-deployments.yaml kubectl apply -f cheese-services.yaml kubectl get services可以看到，启动的TYPE都是ClusterIP，集群内部服务，不对外暴露端口 NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE cheddar ClusterIP 10.98.97.163 80/TCP 17s kubernetes ClusterIP 10.96.0.1 443/TCP 7h stilton ClusterIP 10.108.91.83 80/TCP 17s wensleydale ClusterIP 10.110.187.225 80/TCP 17s 通过Ingress建立路由规则：kubectl apply -f cheeses-ingress.yaml，配置如下： apiVersion: extensions/v1beta1 kind: Ingress metadata: name: cheeses annotations: traefik.frontend.rule.type: PathPrefixStrip spec: rules: - host: stilton.minikube http: paths: - path: / backend: serviceName: stilton servicePort: http - host: cheeses.minikube http: paths: - path: /cheddar backend: serviceName: cheddar servicePort: http - path: /wensleydale backend: serviceName: wensleydale servicePort: http traefik.frontend.rule.type: PathPrefixStrip表示使用路由前缀匹配，且转发到后端前会将匹配到的前缀去掉(strip)；因此当你访问/cheddar/call时候，转发到后端的请求中的path会变成/call；如果只需要做前缀匹配，可以使用PathPrefix 目前traefik.ingress.kubernetes.io/rule-type支持Path, PathPrefix, PathStrip, PathPrefixStrip这五种规则 Traefik的路由规则支持正则匹配，格式为$param:$pattern，若:$pattern为空，则采取通配符匹配；如/cheddar/{name}/{id:[0-9]+}，匹配/cheddar/a/123等。Traefik采用golang的正则规则 PathPrefixStrip不支持去除带有正则表达式的路径 kubectl describe ingress cheeses 查看 Ingress Name: cheeses Namespace: default Address: Default backend: default-http-backend:80 () Rules: Host Path Backends ---- ---- -------- stilton.minikube / stilton:http () cheeses.minikube /cheddar cheddar:http () /wensleydale wensleydale:http () Annotations: kubectl.kubernetes.io/last-applied-configuration: {\"apiVersion\":\"extensions/v1beta1\",\"kind\":\"Ingress\",\"metadata\":{\"annotations\":{\"traefik.frontend.rule.type\":\"PathPrefixStrip\"},\"name\":\"cheeses\",\"namespace\":\"default\"},\"spec\":{\"rules\":[{\"host\":\"stilton.minikube\",\"http\":{\"paths\":[{\"backend\":{\"serviceName\":\"stilton\",\"servicePort\":\"http\"},\"path\":\"/\"}]}},{\"host\":\"cheeses.minikube\",\"http\":{\"paths\":[{\"backend\":{\"serviceName\":\"cheddar\",\"servicePort\":\"http\"},\"path\":\"/cheddar\"},{\"backend\":{\"serviceName\":\"wensleydale\",\"servicePort\":\"http\"},\"path\":\"/wensleydale\"}]}}]}} traefik.frontend.rule.type: PathPrefixStrip Events: 添加dns: echo \"$(minikube ip) cheeses.minikube stilton.minikube\" | sudo tee -a /etc/hosts 开启rbac，授权角色访问dashboard权限kubectl apply -f traefik-rbac.yaml 访问$(minikube ip):30423查看当前Traefik的dashboard 访问以下地址，可以看到根据路由规则返回了相应的服务页面；访问其他地址会返回404 not found http://stilton.minikube:32044/ http://cheeses.minikube:32044/cheddar http://cheeses.minikube:32044/wensleydale 通过ConfigMap对Traefik网关进行配置 创建ConfigMap，在k8s上注册Traefik配置资源 $ cat traefik-config.yaml apiVersion: v1 kind: ConfigMap metadata: name: traefik-config namespace: kube-system data: traefik.toml: | defaultEntryPoints = [\"http\"] [entryPoints] [entryPoints.http] address = \":80\" [accessLog] filePath = \"/logs/traefik.access.log\" format = \"json\" $ kubectl apply -f traefik-config.yaml 这里我们做一个简单的配置，设置Traefik的accesslog以json格式打印到/logs/traefik.access.log路径下。 更多丰富的Traefik配置选项可以查阅官方文档：Traefik Configuration 让Traefik Deployment引用ConfigMap资源 $ cat traefik-deployment.yaml --- apiVersion: v1 kind: ServiceAccount metadata: name: traefik-ingress-controller namespace: kube-system --- kind: Deployment apiVersion: extensions/v1beta1 metadata: name: traefik-ingress-controller namespace: kube-system labels: k8s-app: traefik-ingress-lb spec: replicas: 2 selector: matchLabels: k8s-app: traefik-ingress-lb template: metadata: labels: k8s-app: traefik-ingress-lb name: traefik-ingress-lb spec: serviceAccountName: traefik-ingress-controller terminationGracePeriodSeconds: 60 containers: - image: traefik name: traefik-ingress-lb ports: - name: http containerPort: 80 - name: admin containerPort: 8080 args: - --configfile=/config/traefik.toml - --api - --kubernetes - --logLevel=INFO volumeMounts: - mountPath: /config name: traefik-config - mountPath: /logs name: traefik-log volumes: - name: traefik-config configMap: name: traefik-config - name: traefik-log hostPath: path: /tmp/log/traefik --- kind: Service apiVersion: v1 metadata: name: traefik-ingress-service namespace: kube-system spec: selector: k8s-app: traefik-ingress-lb ports: - protocol: TCP port: 80 nodePort: 30036 name: web - protocol: TCP port: 8080 nodePort: 30037 name: admin type: NodePort $ kubectl apply -f traefik-deployment.yaml 这里我们通过volumeMounts将之前注册的ConfigMap资源traefik-config挂载到容器的/config目录下；并且制定启动Traefik的参数args: --configfile=/config/traefik.toml，使用traefik.toml的配置 通过volumeMounts将容器的日志挂载到宿主机的/tmp/log/traefik目录下 启动Traefik后，会发现宿主机的/tmp/log/traefik目录下出现了traefik.access.log 访问localhost:30036，即可在traefik.access.log中看到请求日志 $ tail -f /tmp/log/traefik/traefik.access.log {\"BackendAddr\":\"\",\"BackendName\":\"Traefik\",\"BackendURL\":{\"Scheme\":\"\",\"Opaque\":\"\",\"User\":null,\"Host\":\"\",\"Path\":\"/\",\"RawPath\":\"\",\"ForceQuery\":false,\"RawQuery\":\"\",\"Fragment\":\"\"},\"ClientAddr\":\"192.168.65.3:54144\",\"ClientHost\":\"192.168.65.3\",\"ClientPort\":\"54144\",\"ClientUsername\":\"-\",\"DownstreamContentSize\":19,\"DownstreamStatus\":404,\"DownstreamStatusLine\":\"404 Not Found\",\"Duration\":264044,\"FrontendName\":\"backend not found\",\"OriginContentSize\":19,\"OriginDuration\":20445,\"OriginStatus\":404,\"OriginStatusLine\":\"404 Not Found\",\"Overhead\":243599,\"RequestAddr\":\"localhost:30036\",\"RequestContentSize\":0,\"RequestCount\":98,\"RequestHost\":\"localhost\",\"RequestLine\":\"GET / HTTP/1.1\",\"RequestMethod\":\"GET\",\"RequestPath\":\"/\",\"RequestPort\":\"30036\",\"RequestProtocol\":\"HTTP/1.1\",\"RetryAttempts\":0,\"StartLocal\":\"2019-04-17T10:19:18.315341342Z\",\"StartUTC\":\"2019-04-17T10:19:18.315341342Z\",\"downstream_Content-Type\":\"text/plain; charset=utf-8\",\"downstream_X-Content-Type-Options\":\"nosniff\",\"level\":\"info\",\"msg\":\"\",\"origin_Content-Type\":\"text/plain; charset=utf-8\",\"origin_X-Content-Type-Options\":\"nosniff\",\"request_Accept\":\"*/*\",\"request_User-Agent\":\"curl/7.51.0\",\"time\":\"2019-04-17T10:19:18Z\"} 配置服务优先级 Traefik-Ingress路由默认采用最长路径匹配原则，比如以下两个Ingress都使用前缀匹配 $ cat cheddar-ingress.yaml apiVersion: extensions/v1beta1 kind: Ingress metadata: name: cheddar annotations: kubernetes.io/ingress.class: traefik traefik.frontend.rule.type: PathPrefixStrip spec: rules: - host: cheeses.minikube http: paths: - path: /cheddar backend: serviceName: cheddar servicePort: http $ cat wensleydale-ingress.yaml apiVersion: extensions/v1beta1 kind: Ingress metadata: name: wensleydale annotations: kubernetes.io/ingress.class: traefik traefik.frontend.rule.type: PathPrefixStrip spec: rules: - host: cheeses.minikube http: paths: - path: /cheddar/wensleydale backend: serviceName: wensleydale servicePort: http 我们载入这两个Ingress：kubectl apply -f cheddar-ingress.yaml，kubectl apply -f wensleydale-ingress.yaml，当你访问cheeses.minikube:32044/cheddar/wensleydale/xxx时，请求会被分发到wensleydale服务上。 我们可以通过配置指定路由优先级，使用traefik.ingress.kubernetes.io/priority，对应的值越大，优先级越高。 $ cat cheddar-ingress.yaml apiVersion: extensions/v1beta1 kind: Ingress metadata: name: cheddar annotations: kubernetes.io/ingress.class: traefik traefik.frontend.rule.type: PathPrefixStrip traefik.ingress.kubernetes.io/priority: \"2\" spec: rules: - host: cheeses.minikube http: paths: - path: /cheddar backend: serviceName: cheddar servicePort: http $ cat wensleydale-ingress.yaml apiVersion: extensions/v1beta1 kind: Ingress metadata: name: wensleydale annotations: kubernetes.io/ingress.class: traefik traefik.frontend.rule.type: PathPrefixStrip traefik.ingress.kubernetes.io/priority: \"1\" spec: rules: - host: cheeses.minikube http: paths: - path: /cheddar/wensleydale backend: serviceName: wensleydale servicePort: http 此时访问cheeses.minikube:32044/cheddar/wensleydale/xxx时，请求会被分发到cheddar服务上。 默认不设置traefik.ingress.kubernetes.io/priority时的路由优先级最高；所以建议是都手动设置一个默认值，以免设置了优先级的路由被未设置优先级的路由覆盖 负载均衡 Traefik可以做到细粒度的负载均衡。 比如我们现在有两个服务，cheddar和wensleydale，我们希望同一个入口75%的流量导向cheddar，25%的流量导向wensleydale，那么可以做以下配置 $ cat cheeses-ingress.yaml apiVersion: extensions/v1beta1 kind: Ingress metadata: name: cheeses annotations: kubernetes.io/ingress.class: traefik traefik.frontend.rule.type: PathPrefixStrip traefik.ingress.kubernetes.io/service-weights: | cheddar: 75% wensleydale: 25% spec: rules: - host: cheeses.minikube http: paths: - path: / backend: serviceName: cheddar servicePort: http - path: / backend: serviceName: wensleydale servicePort: http $ kubectl apply -f cheeses-ingress.yaml 接下来批量访问cheeses.minikube:32044/，就会发现流量按照比例被导入到两个服务上去了 Traefik也支持默认自动配置。比如上面这个例子，如果你只配置了wensleydale: 25%，即便不配置cheddar: 75%，Traefik也会把余下75%的流量自动导入到cheddar上去。 负载均衡的两个服务中，任意一个服务未启用，该规则都不会生效。如cheddar服务关闭的话，访问cheeses.minikube:32044/的请求就会全部返回404 Not Found 灰度发布 应用部署 创建本地镜像，一个简单的http服务器 注意，如果要使用本地镜像的话，不能使用minikube虚拟机，否则会由于虚拟机环境没有镜像而导致拉取镜像失败 $ cat demo.go package main import ( \"fmt\" \"io\" \"log\" \"net/http\" \"github.com/gorilla/mux\" ) type my404Handler struct{} func (h *my404Handler) ServeHTTP(w http.ResponseWriter, r *http.Request) { io.WriteString(w, \"gm-v1: 404 not Found!\\n\") } // DemoServer the web server func DemoServer(w http.ResponseWriter, r *http.Request) { gameid, _ := mux.Vars(r)[\"gameid\"] io.WriteString(w, fmt.Sprintf(\"gm-v1: game %v\\n\", gameid)) } func main() { router := mux.NewRouter() router.HandleFunc(\"/{gameid}/gm/call\", DemoServer) router.NotFoundHandler = &my404Handler{} log.Fatal(http.ListenAndServe(\":8080\", router)) } $ cat Dockerfile FROM golang:1.9.6 COPY ./demo.go /go/src/ WORKDIR /go/src RUN go get github.com/gorilla/mux CMD [\"go\", \"run\", \"demo.go\"] $ docker build -t demo-gm:v1 . 我们将上述镜像文件中的v1改成v2，再创建一个demo-gm:v2镜像 使用Deployment模式部署应用镜像，对外提供服务 $ cat gm-v1.yaml apiVersion: extensions/v1beta1 kind: Deployment metadata: name: gm-v1 labels: app: gm-v1 spec: replicas: 2 selector: matchLabels: app: gm-v1 template: metadata: labels: app: gm-v1 spec: containers: - name: gm-v1 image: demo-gm:v1 ports: - containerPort: 8080 --- apiVersion: v1 kind: Service metadata: name: gm-v1 spec: ports: - name: http port: 80 targetPort: 8080 selector: app: gm-v1 $ kubectl apply -f gm-v1.yaml 使用Ingress注册服务 $ cat gm-v1-ingress.yaml apiVersion: extensions/v1beta1 kind: Ingress metadata: name: gm-v1 annotations: kubernetes.io/ingress.class: traefik traefik.frontend.rule.type: PathPrefix spec: rules: - host: localhost http: paths: - path: /dm0/gm backend: serviceName: gm-v1 servicePort: http $ kubectl apply -f gm-v1-ingress.yaml 启动traefik $ cat traefik-deployment.yaml --- apiVersion: v1 kind: ServiceAccount metadata: name: traefik-ingress-controller namespace: kube-system --- kind: Deployment apiVersion: extensions/v1beta1 metadata: name: traefik-ingress-controller namespace: kube-system labels: k8s-app: traefik-ingress-lb spec: replicas: 2 selector: matchLabels: k8s-app: traefik-ingress-lb template: metadata: labels: k8s-app: traefik-ingress-lb name: traefik-ingress-lb spec: serviceAccountName: traefik-ingress-controller terminationGracePeriodSeconds: 60 containers: - image: traefik name: traefik-ingress-lb ports: - name: http containerPort: 80 - name: admin containerPort: 8080 args: - --api - --kubernetes - --logLevel=INFO --- kind: Service apiVersion: v1 metadata: name: traefik-ingress-service namespace: kube-system spec: selector: k8s-app: traefik-ingress-lb ports: - protocol: TCP port: 80 nodePort: 30036 name: web - protocol: TCP port: 8080 nodePort: 30037 name: admin type: NodePort $ kubectl apply -f traefik-deployment.yaml 访问gm-v1服务 $ curl 'localhost:30036/dm0/gm/call' gm-v1: game dm0 $ curl 'localhost:30036/dm0/gm/test gm-v1: 404 not Found! 应用升级 部署gm-v2服务 $ cat gm-v2.yaml apiVersion: extensions/v1beta1 kind: Deployment metadata: name: gm-v2 labels: app: gm-v2 spec: replicas: 2 selector: matchLabels: app: gm-v2 template: metadata: labels: app: gm-v2 spec: containers: - name: gm-v2 image: demo-gm:v2 ports: - containerPort: 8080 --- apiVersion: v1 kind: Service metadata: name: gm-v2 spec: ports: - name: http port: 80 targetPort: 8080 selector: app: gm-v2 $ kubectl apply -f gm-v2.yaml \"50%\"灰度 使用Ingress注册gm-v2服务 $ cat gm-v2-ingress.yaml apiVersion: extensions/v1beta1 kind: Ingress metadata: name: gm-v2 annotations: kubernetes.io/ingress.class: traefik traefik.frontend.rule.type: PathPrefix spec: rules: - host: localhost http: paths: - path: /dm0/gm backend: serviceName: gm-v2 servicePort: http $ kubectl apply -f gm-v2-ingress.yaml 通过kubectl get ingress可以看到，此时gm-v1和gm-v2是并存的 NAME HOSTS ADDRESS PORTS AGE gm-v1 localhost 80 4h gm-v2 localhost 80 3h 通过简单的程序20次访问服务可以发现，此时“50%”的流量被分发到了gm-v2 gm-v2: game dm0 gm-v2: game dm0 gm-v1: game dm0 gm-v1: game dm0 gm-v2: game dm0 gm-v2: game dm0 gm-v1: game dm0 gm-v1: game dm0 gm-v2: game dm0 gm-v2: game dm0 gm-v1: game dm0 gm-v1: game dm0 gm-v2: game dm0 gm-v2: game dm0 gm-v1: game dm0 gm-v1: game dm0 gm-v2: game dm0 gm-v2: game dm0 gm-v1: game dm0 gm-v1: game dm0 map[unknown:0 v1:10 v2:10] 之所以给这“50%”加个引号是因为，实际上，此时的流量会均匀地分发给gm-v1和gm-v2所有的pod，如果gm-v1启动了2个pod，gm-v2启动了4个pod，那么分发到gm-v1和gm-v2的流量为1:2 通过kubectl delete ingress gm-v1，删除gm-v1的路由 然后再次访问服务，可以发现流量全部到分发到了gm-v2 gm-v2: game dm0 gm-v2: game dm0 gm-v2: game dm0 gm-v2: game dm0 gm-v2: game dm0 gm-v2: game dm0 gm-v2: game dm0 gm-v2: game dm0 gm-v2: game dm0 gm-v2: game dm0 gm-v2: game dm0 gm-v2: game dm0 gm-v2: game dm0 gm-v2: game dm0 gm-v2: game dm0 gm-v2: game dm0 gm-v2: game dm0 gm-v2: game dm0 gm-v2: game dm0 gm-v2: game dm0 map[v1:0 v2:20 unknown:0] 精准灰度 通过Ingress注册/dm0/gm访问gm-v1服务，此时流量全部转发到gm-v1 $ cat gm-v1-ingress.yaml apiVersion: extensions/v1beta1 kind: Ingress metadata: name: dm0-gm annotations: kubernetes.io/ingress.class: traefik traefik.frontend.rule.type: PathPrefix spec: rules: - host: localhost http: paths: - path: /dm0/gm backend: serviceName: gm-v1 servicePort: http $ kubectl apply -f gm-v1-ingress.yaml 使用同样的name(dm0-gm)，注册灰度路由；此时由于Ingress name相同，会覆盖之前的路由 $ cat gm-v2-ingress.yaml apiVersion: extensions/v1beta1 kind: Ingress metadata: name: dm0-gm annotations: kubernetes.io/ingress.class: traefik traefik.frontend.rule.type: PathPrefix traefik.ingress.kubernetes.io/service-weights: | gm-v1: 75% gm-v2: 25% spec: rules: - host: localhost http: paths: - path: /dm0/gm backend: serviceName: gm-v1 servicePort: http - path: /dm0/gm backend: serviceName: gm-v2 servicePort: http $ kubectl apply -f gm-v2-ingress.yaml 此时访问服务会发现，25%的流量被转发到了gm-v2 gm-v1: game dm0 gm-v1: game dm0 gm-v1: game dm0 gm-v1: game dm0 gm-v2: game dm0 gm-v1: game dm0 gm-v1: game dm0 gm-v2: game dm0 gm-v1: game dm0 gm-v1: game dm0 gm-v1: game dm0 gm-v1: game dm0 gm-v2: game dm0 gm-v1: game dm0 gm-v1: game dm0 gm-v2: game dm0 gm-v1: game dm0 gm-v1: game dm0 gm-v1: game dm0 gm-v1: game dm0 map[v2:4 unknown:0 v1:16] 更新Ingress: dm0-gm $ cat gm-v2-ingress.yaml apiVersion: extensions/v1beta1 kind: Ingress metadata: name: dm0-gm annotations: kubernetes.io/ingress.class: traefik traefik.frontend.rule.type: PathPrefix spec: rules: - host: localhost http: paths: - path: /dm0/gm backend: serviceName: gm-v2 servicePort: http $ kubectl apply -f gm-v2-ingress.yaml 此时访问服务会发现，所有流量都被转发到了gm-v2 gm-v2: game dm0 gm-v2: game dm0 gm-v2: game dm0 gm-v2: game dm0 gm-v2: game dm0 gm-v2: game dm0 gm-v2: game dm0 gm-v2: game dm0 gm-v2: game dm0 gm-v2: game dm0 gm-v2: game dm0 gm-v2: game dm0 gm-v2: game dm0 gm-v2: game dm0 gm-v2: game dm0 gm-v2: game dm0 gm-v2: game dm0 gm-v2: game dm0 gm-v2: game dm0 gm-v2: game dm0 map[v1:0 v2:20 unknown:0] IP限制 Traefik支持对指定的路由做ip白名单限制 $ cat gm-v1-ingress.yaml kind: Ingress metadata: name: dm0-gm annotations: kubernetes.io/ingress.class: traefik traefik.frontend.rule.type: PathPrefix spec: rules: - host: localhost http: paths: - path: /dm0/gm backend: serviceName: gm-v1 servicePort: http --- apiVersion: extensions/v1beta1 kind: Ingress metadata: name: dm1-gm annotations: kubernetes.io/ingress.class: traefik traefik.frontend.rule.type: PathPrefix traefik.ingress.kubernetes.io/whitelist-source-range: \"127.0.0.1\" spec: rules: - host: localhost http: paths: - path: /dm1/gm backend: serviceName: gm-v1 servicePort: http $ kubectl apply -f gm-v1-ingress.yaml 此时，访问/dm1/gm的来源ip若不是127.0.0.1，反向代理会返回403 Forbidden；访问dm0/gm的不受ip限制 也可以指定ingress.kubernetes.io/whitelist-x-forwarded-for: \"true\"，使用HTTP头部的X-Forwarded-For字段的ip做校验 支持多ip和通配符，如traefik.ingress.kubernetes.io/whitelist-source-range: \"1.2.3.0/24, fe80::/16\" 定制Header 定制请求头 $ cat gm-v1-ingress.yaml apiVersion: extensions/v1beta1 kind: Ingress metadata: name: dm2-gm annotations: kubernetes.io/ingress.class: traefik traefik.frontend.rule.type: PathPrefix ingress.kubernetes.io/custom-request-headers: \"X-Custom-Id: test\" spec: rules: - host: localhost http: paths: - path: /dm2/gm backend: serviceName: gm-v1 servicePort: http $ kubectl apply -f gm-v1-ingress.yaml 后端收到的请求中会包含请求头X-Custom-Id 可以通过\"Header1: Value1||Header2: Value2||...的方式设定多个请求头 经过traefik反向代理转发的请求会自动带上以下头部 X-Forwarded-Host X-Forwarded-Port X-Forwarded-Server X-Forwarded-For X-Real-Ip X-Forwarded-Proto User-Agent Accept-Encoding 定制返回头的方法和请求头一样，只是annotations换成了ingress.kubernetes.io/custom-response-headers 参考链接 traefik kubernetes user guide traefik ingress provider kubernetes ingress kubernetes官网 kubernetes中文手册 例程1 例程2 使用traefik作为kubernetes的ingress "},"kubernetes/configmap.html":{"url":"kubernetes/configmap.html","title":"II. ConfigMap的使用","keywords":"","body":"ConfigMap的使用 ConfigMap用于将配置文件从容器镜像中解耦，从而增强容器应用的可移植性。ConfigMap API Resource将配置数据以键值对的形式存储，这些数据可以在Pod中消费或者为系统组件提供配置，用来设定应用环境参数、配置文件等。 这里我们用ConfigMap来进行配置文件加载。 注册ConfigMap资源 和k8s的其他资源一样，ConfigMap也可以通过yaml文件来进行注册，资源类型为ConfigMap $ cat config.yaml apiVersion: v1 kind: ConfigMap metadata: name: special-config namespace: default data: response: | hello, world $ kubectl apply -f config.yaml 通过kubectl describe configmap special-config可以看到，该name为special-config的ConfigMap资源已经完成了注册 Name: special-config Namespace: default Labels: Annotations: kubectl.kubernetes.io/last-applied-configuration={\"apiVersion\":\"v1\",\"data\":{\"response\":\"hello, world\\n\"},\"kind\":\"ConfigMap\",\"metadata\":{\"annotations\":{},\"name\":\"special-config\",\"namespace\":\"default\"}}... Data ==== response: ---- hello, world Events: 注册的内容为一个key-value对：response: hello, world 引用ConfigMap资源 创建一个简单的镜像 $ cat demo.go package main import ( \"io\" \"io/ioutil\" \"log\" \"net/http\" ) // HelloServer the web server func HelloServer(w http.ResponseWriter, req *http.Request) { b, err := ioutil.ReadFile(\"config.toml\") if err != nil { io.WriteString(w, err.Error()) } else { w.Write(b) } } func main() { http.HandleFunc(\"/\", HelloServer) log.Fatalf(\"ListenAndServe: %v\", http.ListenAndServe(\":8080\", nil)) } $ cat Dockerfile FROM golang:1.9.6 COPY ./demo.go /go/src/ WORKDIR /go/src CMD [\"go\", \"run\", \"demo.go\"] $ docker build -t demo-hello:v1 . 该镜像启动一个服务器，每次收到请求时把config.toml文件中配置的内容返回给客户端 使用Deployment模式部署应用服务 $ cat hello.yaml apiVersion: extensions/v1beta1 kind: Deployment metadata: name: gm-v1 labels: app: gm-v1 spec: replicas: 2 selector: matchLabels: app: gm-v1 template: metadata: labels: app: gm-v1 spec: containers: - name: gm-v1 image: demo-hello:v1 volumeMounts: - name: config-volume mountPath: /etc/config volumes: - name: config-volume configMap: name: special-config --- apiVersion: v1 kind: Service metadata: name: gm-v1 spec: ports: - name: http port: 80 targetPort: 8080 nodePort: 30011 type: NodePort selector: app: gm-v1 $ kubectl apply -f hello.yaml 在这里，我们通过volumeMounts将config-volume挂载到容器的/etc/config目录 设定config-volume对应name为special-config的ConfigMap资源，则该ConfigMap里的所有内容都会被挂载到指定的目录里去 如果需要挂载多个ConfigMap，只要在volumeMounts里指定多个name，并且在volumes里指定这些name对应的ConfigMap即可 通过kubectl get pods可以看到该服务启动了两个pod NAME READY STATUS RESTARTS AGE gm-v1-745d88999d-782ck 1/1 Running 0 5m gm-v1-745d88999d-t48rn 1/1 Running 0 5m 通过volumeMount挂载的ConfigMap会覆盖挂载的路径(如果路径不存在，则会创建路径并挂载），挂载在该路径下的文件以注册ConfigMap时的key-value对命名；key为文件名，value为文件内容 $ kubectl exec -it gm-v1-745d88999d-782ck cat /etc/config/response hello, world 进入容器内部，通过cat命令可以看到，挂载在/etc/config下的文件以ConfigMap注册的key(response)命名，内容为value(hello, world) 如果在注册ConfigMap时指定了多个key-value对，如 data: response: | hello, world test.conf: | a = b 则会在挂载路径下创建以response、test.conf命名的文件，文件内容分别为hello, world，a = b 引用指定的key 如果我们不希望引入的ConfigMap覆盖整个挂载路径，只希望引用ConfigMap中指定的key，并且在挂载路径中生成指定的文件名，可以通过以下方法 $ cat hello.yaml apiVersion: extensions/v1beta1 kind: Deployment metadata: name: gm-v1 labels: app: gm-v1 spec: replicas: 2 selector: matchLabels: app: gm-v1 template: metadata: labels: app: gm-v1 spec: containers: - name: gm-v1 image: demo-hello:v1 volumeMounts: - name: config-volume mountPath: /go/src/config.toml subPath: config.toml volumes: - name: config-volume configMap: name: special-config items: - key: response path: config.toml --- apiVersion: v1 kind: Service metadata: name: gm-v1 spec: ports: - name: http port: 80 targetPort: 8080 nodePort: 30011 type: NodePort selector: app: gm-v1 $ kubectl apply -f hello.yaml 这里我们使用subPath指定具体的文件名，只挂载该文件路径 指定挂载的ConfigMap key: response，对应挂载的文件config.toml 由于我们的http服务是就是打印config.toml中的内容，返回给客户端，因此访问服务对外的接口即可看到引用的ConfigMap中response对应的value $ curl '127.0.0.1:30011' hello, world 注意 参考以上的例子，可以在k8s中通过ConfigMap动态地为服务加载配置资源 引用ConfigMap的服务，其namespace要和对应的ConfigMap资源一致 如果使用的是subPath的方式来加载配置文件，当变更了ConfigMap里相应key对应的内容并重载后，容器内的配置文件内容并不会更新(issue-50345) 用Path的方式加载整个目录，配置路径的内容会更新 用subPath的方式，重启pod后，配置才会更新 参考链接： kubernetes configmap "},"kubernetes/commands.html":{"url":"kubernetes/commands.html","title":"附. 部分指令参考","keywords":"","body":"部分指令参考 Kubernetes 干掉一直停留在Terminating状态的pod kubectl delete pod $pod_id --grace-period=0 --force Docker 干掉一直停留在Exited状态的container docker rm $(docker ps -f status=exited -q) "},"kafka/quick_start.html":{"url":"kafka/quick_start.html","title":"I. Kafka入门","keywords":"","body":"Kafka入门 什么是kafka Kafka 是由 Linkedin 公司开发的，它是一个分布式的，支持多分区、多副本，基于 Zookeeper 的分布式消息流平台，它同时也是一款开源的基于发布订阅模式的消息引擎系统。它具备以下特性： 高吞吐、低延迟：kakfa 最大的特点就是收发消息非常快，kafka 每秒可以处理几十万条消息，它的最低延迟只有几毫秒。 高伸缩性： 每个主题(topic) 包含多个分区(partition)，主题中的分区可以分布在不同的主机(broker)中。 持久性、可靠性： Kafka 能够允许数据的持久化存储，消息被持久化到磁盘，并支持数据备份防止数据丢失，Kafka 底层的数据存储是基于 Zookeeper 存储的，Zookeeper 我们知道它的数据能够持久存储。 容错性： 允许集群中的节点失败，某个节点宕机，Kafka 集群能够正常工作 高并发： 支持数千个客户端同时读写 基本术语 消息：Kafka 中的数据单元被称为消息，也被称为记录，可以把它看作数据库表中某一行的记录。 批次：为了提高效率， 消息会分批次写入 Kafka，批次就代指的是一组消息。 主题：消息的种类称为 主题（Topic）,可以说一个主题代表了一类消息。相当于是对消息进行分类。主题就像是数据库中的表。 分区：主题可以被分为若干个分区（partition），同一个主题中的分区可以不在一个机器上，有可能会部署在多个机器上，由此来实现 kafka 的伸缩性，单一主题中的分区有序，但是无法保证主题中所有的分区有序 生产者： 向主题发布消息的客户端应用程序称为生产者（Producer），生产者用于持续不断的向某个主题发送消息。 消费者：订阅主题消息的客户端程序称为消费者（Consumer），消费者用于处理生产者产生的消息。 消费者群组：生产者与消费者的关系就如同餐厅中的厨师和顾客之间的关系一样，一个厨师对应多个顾客，也就是一个生产者对应多个消费者，消费者群组（Consumer Group）指的就是由一个或多个消费者组成的群体。 偏移量：偏移量（Consumer Offset）是一种元数据，它是一个不断递增的整数值，用来记录消费者发生重平衡时的位置，以便用来恢复数据。 broker: 一个独立的 Kafka 服务器就被称为 broker，broker 接收来自生产者的消息，为消息设置偏移量，并提交消息到磁盘保存。 broker 集群：broker 是集群 的组成部分，broker 集群由一个或多个 broker 组成，每个集群都有一个 broker 同时充当了集群控制器的角色（自动从集群的活跃成员中选举出来）。 副本：Kafka 中消息的备份又叫做 副本（Replica），副本的数量是可以配置的，Kafka 定义了两类副本：领导者副本（Leader Replica） 和 追随者副本（Follower Replica），前者对外提供服务，后者只是被动跟随。 重平衡：Rebalance。消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。Rebalance 是 Kafka 消费者端实现高可用的重要手段。 系统架构 如上图所示，一个典型的 Kafka 集群中包含若干Producer（可以是web前端产生的Page View，或者是服务器日志，系统CPU、Memory等），若干broker（Kafka支持水平扩展，一般broker数量越多，集群吞吐率越高），若干Consumer Group，以及一个Zookeeper集群。Kafka通过Zookeeper管理集群配置，选举leader，以及在Consumer Group发生变化时进行rebalance。Producer使用push模式将消息发布到broker，Consumer使用pull模式从broker订阅并消费消息。 本地安装 下载源码包：https://www.apache.org/dyn/closer.cgi?path=/kafka/2.4.1/kafka-2.4.1-src.tgz 解压tar zxvf kafka_2.12-2.4.1.tgz后进入目录 启动zookeeper： $ ./gradlew jar -PscalaVersion=2.12.10 $ ./bin/zookeeper-server-start.sh config/zookeeper.properties 启动kafka $ ./bin/kafka-server-start.sh config/server.properties 将当前bin添加到PATH(也可把下列操作放到~/.zshrc中) $ export KAFKA=/bin $ export PATH=$KAFKA:$PATH 创建topic $ kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic test # 检查topic创建情况 $ kafka-topics.sh --list --bootstrap-server localhost:9092 删除topic命令：kafka-topics.sh --delete --bootstrap-server localhost:9092 --topic test 启动消费者 $ kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test 启动生产者 $ kafka-console-producer.sh --broker-list localhost:9092 --topic test 当你在生产者中输入任意字符时，消费者将会接收到并且同步打印 如果在启动消费者的时候添加了--from-beginning参数，那么消费者会将生产者所有的历史输入都进行输出 参考链接： 掘金：Kafka 入门一篇文章就够了 kafka doc: quick start "},"network/chunk.html":{"url":"network/chunk.html","title":"I. HTTP协议之chunk(分块传输编码)","keywords":"","body":"HTTP协议之chunk(分块传输编码) 分块传输编码 分块传输编码（Chunked transfer encoding）是超文本传输协议（HTTP）中的一种数据传输机制，允许HTTP由应用服务器发送给客户端应用（通常是网页浏览器）的数据可以分成多个部分。在HTTP协议1.1版本（HTTP/1.1）中提供。 通常，HTTP应答消息中发送的数据是整个发送的，Content-Length消息头字段表示数据的长度。数据的长度很重要，因为客户端需要知道哪里是应答消息的结束，以及后续应答消息的开始。然而，使用分块传输编码，数据分解成一系列数据块，并以一个或多个块流式传输，这样服务器可以发送数据而不需要预先知道发送内容的总大小。 HTTP 1.1引入分块传输编码提供了以下几点好处： HTTP分块传输编码允许服务器为动态生成的内容维持HTTP持久链接。通常，持久链接需要服务器在开始发送消息体前发送Content-Length消息头字段，但是对于动态生成的内容来说，在内容创建完之前是不可知的。 分块传输编码允许服务器在最后发送消息头字段。对于那些头字段值在内容被生成之前无法知道的情形非常重要，例如消息的内容要使用散列进行签名，散列的结果通过HTTP消息头字段进行传输。没有分块传输编码时，服务器必须缓冲内容直到完成后计算头字段的值并在发送内容前发送这些头字段的值。 HTTP服务器有时使用压缩以缩短传输花费的时间。分块传输编码可以用来分隔压缩对象的多个部分。在这种情况下，块不是分别压缩的，而是整个负载进行压缩，压缩的输出使用本文描述的方案进行分块传输。在压缩的情形中，分块编码有利于一边进行压缩一边发送数据，而不是先完成压缩过程以得知压缩后数据的大小。 分块传输编码的格式： 如果一个HTTP消息（请求消息或应答消息）的Transfer-Encoding消息头的值为chunked，那么，消息体由数量未定的块组成，并以最后一个大小为0的块为结束。传输过程中的消息头没有Content-Length字段 每一个非空的块都以该块包含数据的字节数（字节数以十六进制表示）开始，跟随一个CRLF（回车及换行），然后是数据本身，最后块CRLF结束。在一些实现中，块大小和CRLF之间填充有白空格（0x20）。 最后一块是单行，由块大小（0），一些可选的填充白空格，以及CRLF。最后一块不再包含任何数据，但是可以发送可选的尾部，包括消息头字段。消息最后以CRLF结尾。 golang http server 与 chunk golang http 包中，处理请求返回的response结构体里，用于写入body的Writer是一个chunkWriter。我们可以通过官方包net/http/server.go: func (c *conn) readRequest(ctx context.Context) (w *response, err error)方法看到： 这里使用w.cw(定义为response.chunkWriter)生成一个*bufio.Writer，设定buffer大小为bufferBeforeChunkingSize，并赋值给w.w(定义为response.Writer)。在http包中，bufferBeforeChunkingSize的值为2048 因此，当返回的response写入的内容超过2048个字节时，golang的http包底层会自动进行分块传输编码(chunk)。这里我们可以通过一个简单的demo来验证一下： package main import ( \"bytes\" \"log\" \"net/http\" ) func main() { handler := func(w http.ResponseWriter, req *http.Request) { unitByte := []byte(\"1\") w.Write(bytes.Repeat(unitByte, 2049)) } http.HandleFunc(\"/test_chunked\", handler) log.Fatal(http.ListenAndServe(\":8080\", nil)) } 这里我们返回2049个字符。访问127.0.0.1:8080/test_chunked，看一下返回的消息头 可以看到，当返回的传输字节超过2048时，服务端的返回默认使用了分块传输编码，头部不包含Content-Length。 对于\"Transfer-Encoding\"为chunked的response，golang的http包会在WriteBody时自动补上分块传输编码分隔的CRLF换行符；客户端收到response后按照分块传输编码，解码拼接成完整的报文。 接下来，我们将返回body的内容设置为为2048个字节 w.Write(bytes.Repeat(unitByte, 2048)) 看一下修改后返回的消息头 可以看到，返回的消息头里明确设定了Content-Length，采用正常整包传输。 自动chunk可能带来的问题 服务端返回chunked报文时需要考虑接收方是否能够正确解析。比如接收方使用低版本的python httplib包发起请求，就可能因返回报文头部没有确切的报文长度而导致解析失败 File \"entities/common_server/Lib/httplib.py\", line 588, in read return self._read_chunked(amt) File \"entities/common_server/Lib/httplib.py\", line 642, in _read_chunked raise IncompleteRead(''.join(value)) httplib.IncompleteRead: IncompleteRead(0 bytes read) 由于分块传输编码是HTTP/1.1后新增的功能，一些低版本的程序支持HTTP/1.0，但是对HTTP/1.1没有很好的支持，就可能导致解析分块传输报文失败。 设置golang http服务器是否chunk 虽然golang底层帮我们做了报文自动chunk，但是我们能不能根据服务器的实际需要，显式地设定返回报文是否chunk呢？答案是肯定的。 以上是golang http官方包对response的写接口Write的生存周期说明。服务器默认写入body的时候，是没有设定Content-Length的；如果传输的body长度不超过chunking buffer size(2048字节)，http包会根据自动计算的body长度设定Content-Length，进行整包传输；如果超过了2048字节，就会进行分块传输。 设置no-chunk 通过官方包net/http/transfer.go: func newTransferWriter(r interface{}) (t *transferWriter, err error)方法可以看到，设定chunked的一个首要条件是t.ContentLength 。golang http包对t.ContentLength的值是按照以下顺序进行设置的： 若Body为空，则设为0 若设定了头部的\"Content-Length\"，则使用设定的\"Content-Length\"（当设定的Content-Length和实际写入的Body大小不一致时，在调用net/http/transfer.go: func (t *transferWriter) WriteBody(w io.Writer) error方法写入body时会报错） 若没有设定头部的\"Content-Length\"，则设为-1 因此，只要我们显式地设置http返回头部的\"Content-Length\"，就可以让golang服务器不进行分块传输。 package main import ( \"bytes\" \"log\" \"net/http\" \"strconv\" ) func main() { handler := func(w http.ResponseWriter, req *http.Request) { body := bytes.Repeat([]byte(\"1\"), 2049) w.Header().Set(\"Content-Length\", strconv.Itoa(len(body))) w.Write(body) } http.HandleFunc(\"/test_chunked\", handler) log.Fatal(http.ListenAndServe(\":8080\", nil)) } 这里我们通过w.Header().Set(\"Content-Length\", strconv.Itoa(len(body)))的方法设定了头部长度。访问127.0.0.1:8080/test_chunked，看一下返回的消息头 可以看到，虽然body长度超过了2048，但是返回的消息仍然采用了整包传输(没有设定chunked) 设置chunk http头部的chunked设置，是golang http包底层是否采用分块传输的依据。golang http包默认对2048字节以上的body做分块传输，那么如果我们想要对2048字节以下的body也进行分块传输，只要显式地设置http返回头部的\"Transfer-Encoding\"为chunked即可。 package main import ( \"bytes\" \"log\" \"net/http\" ) func main() { handler := func(w http.ResponseWriter, req *http.Request) { body := bytes.Repeat([]byte(\"1\"), 2047) w.Header().Set(\"Transfer-Encoding\", \"chunked\") w.Write(body) } http.HandleFunc(\"/test_chunked\", handler) log.Fatal(http.ListenAndServe(\":8080\", nil)) } 这里我们返回的body长度只有2047(127.0.0.1:8080/test_chunked，看一下返回的消息头 可以看到，这里使用了分块传输编码，头部不设定\"Content-Length\"。 总结 HTTP/1.1中引入了更高效的数据传输方式 —— 分块传输编码。 golang的http包在传输数据body超过2048字节时，会自动采用分块传输编码(chunk)。 当显式地设置response头部的\"Content-Length\"后，golang将强制采用整包传输，不会使用分块传输编码。 当显式地设置response头部的\"Transfer-Encoding\"为chunked后，golang将强制采用分块传输编码。 参考链接: wiki: 分块传输编码 "}}
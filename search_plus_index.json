{"./":{"url":"./","title":"Introduction","keywords":"","body":"tech talk 技术笔记及分享 书籍地址 "},"git/user.html":{"url":"git/user.html","title":"I. 为不同的git项目配置各自独立的用户","keywords":"","body":"为不同的git项目配置各自独立的用户 我们在自己的开发机上往往会管理多个git仓库，可能有些git仓库是属于自己的私人github账号，有些是属于公司的个人gitlab开发账号，这样就需要为不同的仓库配置不同的用户 方法1: config命令 在git仓库目录下执行 $ git config user.name 'xxx' $ git config user.email 'xxx' ps: 配置全局git用户的方法： $ git config --global user.name 'xxx' $ git config --global user.email 'xxx' 方法2: 修改git配置 git仓库目录下，在.git/config文件中添加以下内容 [user] name = xxx email = xxx "},"git/gitbook.html":{"url":"git/gitbook.html","title":"II. gitbook的使用","keywords":"","body":"gitbook的使用 安装gitbook mac下安装gitbook 目录结构 gitbook项目的目录结构如下: - SUMMARY.md - README.md - book.json - _book/ - node_modules/ 其中，我们需要首先创建的是SUMMARY.md(书籍目录) 和 README.md(书籍介绍) SUMMARY.md 书籍目录是gitbook的基础，可以有层级结构，使用markdown写法 # Summary * [Introduction](README.md) * [git相关](git.md) * [I. 为不同的git项目配置各自独立的用户](./git/user.md) * [II. gitbook的使用](./git/gitbook.md) ... 编译和预览书籍 书籍目录和目录中链接的内容(*.md)文件编辑完成后，执行gitbook serve即可完成书籍的编译 $ gitbook serve Live reload server started on port: 35729 Press CTRL+C to quit ... info: 7 plugins are installed info: loading plugin \"livereload\"... OK info: loading plugin \"highlight\"... OK info: loading plugin \"search\"... OK info: loading plugin \"lunr\"... OK info: loading plugin \"sharing\"... OK info: loading plugin \"fontsettings\"... OK info: loading plugin \"theme-default\"... OK info: found 4 pages info: found 1 asset files info: >> generation finished with success in 0.7s ! Starting server ... Serving book on http://localhost:4000 按照提示信息，访问本机4000端口，即可看到预览结果 执行完成后，会在项目下自动生成书籍的文件目录_book/ 配置书籍 book.json 在项目目录下新建book.json文件，可以进行书籍配置；book.json示例如下: { \"author\": \"mania_fish\", \"description\": \"How to build effective golang project\", \"extension\": null, \"generator\": \"site\", \"links\": { \"sharing\": { \"all\": null, \"facebook\": null, \"google\": null, \"twitter\": null, \"weibo\": null }, \"sidebar\": { \"mania_fish's github\": \"https://github.com/maniafish\" } }, \"output\": null, \"pdf\": { \"fontSize\": 12, \"footerTemplate\": null, \"headerTemplate\": null, \"margin\": { \"bottom\": 36, \"left\": 62, \"right\": 62, \"top\": 36 }, \"pageNumbers\": false, \"paperSize\": \"a4\" }, \"plugins\": [ \"-lunr\", \"-search\", \"search-pro\", \"anchor-navigation-ex\", \"splitter\", \"sectionx\", \"prism\", \"-highlight\", \"prism-themes\" ], \"title\": \"real effective go\", \"variables\": {}, \"pluginsConfig\": { \"anchor-navigation-ex\": { \"isShowTocTitleIcon\": true, \"tocLevel2Icon\": \"fa fa-hand-o-right\", \"tocLevel3Icon\": \"fa fa-hand-o-right\", \"tocLevel4Icon\": \"fa fa-hand-o-right\" }, \"prism\": { \"css\": [ \"prism-themes/themes/prism-base16-ateliersulphurpool.light.css\" ], \"lang\": { \"flow\": \"typescript\" }, \"ignore\": [ \"mermaid\", \"eval-js\" ] } } } 官方配置字段说明 插件plugins \"-lunr\", \"-search\", \"search-pro\": 禁用掉gitbook默认的搜索插件，使用search-pro, 支持中文搜索 \"anchor-navigation-ex\": 页面章节锚点 由于前三级的标题会被自动锚点并编号，为了文章标题不被锚点，我们采用如下格式: #### 标题 --- # 文章第一节 ## 文章第一节的第一小节 效果如下: \"-highlight\", \"prism\", \"prism-themes\": 禁用原代码高亮功能，使用prism代码主题 更多插件，详见官网 载入配置 在项目目录下执行gitbook install即可安装配置插件；安装完成后，项目下会出现一个node_modules/目录 然后执行gitbook serve即可看到配置完成后的主页 集成发布到github pages 添加git仓库 在项目目录下执行git init新建git仓库 git remote add origin 添加github仓库 touch .gitignore 并且在里面添加以下内容 *~ *.swp *.DS_Store _book/ node_modules/ git add . 添加文件到git版本控制 git commit -m 'git init' 提交变动 git push origin master 推送分支 发布github pages git clone 在下执行git checkout --orphan gh-pages 创建孤儿分支gh-pages git rm --cached -r . 删除暂存区目录 git clean -df 删除未track的目录，不影响.gitignore中的文件 touch .gitignore 并且在里面添加以下内容 *~ *.swp *.DS_Store cp -rf /_book/* ./ 将生成的书籍html内容copy出来 git add . git commit -m 'publish book' git push origin gh-pages 推送完成后，进入github仓库主页，会多出一个environment图标 点击environment图标后，进入如下页面 点击view deployment图标，即可看到发布的gitbook书籍 后续更新github pages 只需执行上述6 - 9 步即可 参考链接： gitbook简明教程 "},"linux/vim_replace.html":{"url":"linux/vim_replace.html","title":"I. vim替换特殊符号","keywords":"","body":"vim替换特殊符号 替换特殊字符为实际控制符 替换换行符 :%s/\\\\r\\\\n/\\r/g 替换tab :%s/\\\\t/\\t/g ps: 设置tab为四个空格的方法 :set tabstop=4 :set expandtab 替换跨平台的控制符 替换^M换行符 :%s/[Ctrl-v][Ctrl-M]/\\r/g 替换^I制表符 :%s/[Ctrl-v][Ctrl-I]/\\t/g 替换首尾字符 第7-15行开头插入* :7,15s/^/* /g 第7-15行末尾插入* :7,15s/$/ */g "},"linux/vim_paste.html":{"url":"linux/vim_paste.html","title":"II. vim剪贴板的使用","keywords":"","body":"vim剪贴板的使用 vim复制命令 常用方法 复制当前行: yy 复制自选区域: 先 v 进入visual模式，用kjhl控制上下左右选择好要复制的区域，然后 y 复制选中区域 如果要按行选择的话，则使用[Shift-v]进入visual line模式即可 黏贴: 光标后黏贴: p 光标前黏贴: [Shift-p] 其他用法 nyy：n表示大于1的数字，复制n行 yw：从光标处复制至一个单子/单词的末尾，包括空格 ye：从光标处复制至一个单子/单词的末尾，不包括空格 y$：从当前光标复制到行末 y0：从当前光标位置（不包括光标位置）复制之行首 y3l：从光标位置（包括光标位置）向右复制3个字符 y5G：将当前行（包括当前行）至第5行（不包括它）复制 y3B：从当前光标位置（不包括光标位置）反向复制3个单词 使用寄存器实现丰富的剪贴板功能 vim提供了10类寄存器: 匿名寄存器 \"\" 编号寄存器 \"0 到 \"9 小删除寄存器 \"- 26个命名寄存器 \"a 到 \"z 3个只读寄存器 \":, \"., \"% Buffer交替文件寄存器 \"# 表达式寄存器 \"= 选择和拖放寄存器 \"*, \"+, \"~ 黑洞寄存器 \"_ 搜索模式寄存器 \"/ 可在vim中通过:help registers查看帮助，通过:reg可以查看当前各寄存器中的值。 匿名寄存器 使用d, c, s, x等删除字符的命令或者y等复制字符的命令时，被操作的字符会进入匿名寄存器\"\"。当你执行黏贴命令p时，黏贴的就是匿名寄存器里的值。 编号寄存器 编号寄存器从\"0到\"9共10个，其中\"0保存这最近拷贝的字符串，\"1到\"9保存着最近9次删除掉的字符串。 当用户指定拷贝操作的寄存器（如\"ap）时，该拷贝数据不会被写入\"0。 \"0寄存器很有用，比如我们copy了一段文本然后用它替换另一段文本。 这时默认匿名寄存器\"\"中的值就变成了被替换文本，如果还需要用copy的文本继续替换的话就需要\"0p了。 小删除寄存器 不足一行的小删除则会被放到小删除寄存器中（\"-），起作用的删除操作符也包括s, c, d, x。 例如： dw # 删除一个词 d9l # 删除9个字符 cb # 向前更改一个词 与\"0寄存器类似，当用户指定寄存器并进行删除时，\"-不会被写入。 命名寄存器 命名寄存器有\"a到\"z共26个，这些寄存器只有当我们指定时才会被使用。比如我们要复制一段文字，存入匿名寄存器\"a，只要使用v选中这段文字，执行\"ay录制宏，这段文字就进入了\"a寄存器；然后使用\"ap即可黏贴这段文字。 只读寄存器 只读寄存器共3个，它们的值是由vim提供的，不允许改变： \".：上次insert模式中插入的字符串。使用.命令可以重复上次操作，使用的就是\".寄存器。 \"%：当前文件名，不是全路径，也不是纯文件名，而是从当前vim的工作目录到该文件的路径。比如你执行vim golang/gc.md打开了一个文件，那么\"%p输出的就是golang/gc.md \":：上次命令模式下键入的命令。使用@:可以执行上次命令。 交替文件寄存器 交替文件寄存器\"#存储着当前vim窗口（Window）的交替文件。交替文件（alternate file）是指 Buffer中的上一个文件，可通过Ctrl+^来切换交替文件与当前文件。 表达式寄存器 表达式寄存器\"=主要用于计算vim脚本的返回值，并插入到文本中。当我们键入\"=后光标会移动到命令行，此时我们可以输入任何vim脚本的表达式。 例如3+2，按下回车并且p则会得到5。 选择和拖放寄存器 选择和拖放寄存器包括\"*, \"+, 和\"~，这三个寄存器的行为是和GUI相关的。 \"*和\"+都是指系统剪切板（clipboard），例如\"*yy即可复制当前行到剪切板，以供其他程序中粘贴；其他程序中复制的内容也会被存储到这两个寄存器中，可以通过\"*p在vim中进行黏贴。 在Mac下执行:set clipboard=unnamed会使得系统剪切板寄存器\"*和vim默认的匿名寄存器\"\"始终保有同样的值，即vim和系统共用剪切板。 有文本拖拽到vim时，被拖拽的文本被存储在\"~中。vim默认的行为是将\"~中内容插入到光标所在位置。 黑洞寄存器 所有删除或拷贝到黑洞寄存器\"_的文本将会消失。这是为了在删除文本的同时不影响任何寄存器的值。 搜索寄存器 搜索寄存器\"/用于存储上一次搜索的关键词。在normal模式下按下/即进入search模式，输入关键字并按下回车即可。 该寄存器是可写的，例如:let @/ = \"maniafish\"将会把\"maniafish\"写入该寄存器。 下次使用/搜索时不输入搜索词直接回车便会搜索\"maniafish\"。 参考链接: 使用 Vim 寄存器 "},"linux/vim_conf.html":{"url":"linux/vim_conf.html","title":"III. vim的插件及配置","keywords":"","body":"vim的插件及配置 我的vim配置 \" Uncomment the next line to make Vim more Vi-compatible \" NOTE: debian.vim sets 'nocompatible'. Setting 'compatible' changes numerous \" options, so any other options should be set AFTER setting 'compatible'. set nocompatible filetype off \" required \" set the runtime path to include Vundle and initialize set rtp+=~/.vim/bundle/Vundle.vim call vundle#begin() \" 4 vundle \" let Vundle manage Vundle Plugin 'gmarik/Vundle.vim' \" 4 the syntax checking when saving Plugin 'scrooloose/syntastic' \" 4 pep8 style checking Plugin 'nvie/vim-flake8' \" 4 background color Plugin 'altercation/vim-colors-solarized' \" 4 file tree init input :NERDTree in vim Plugin 'scrooloose/nerdtree' \" 4 search file Plugin 'kien/ctrlp.vim' \" 4 vim-go Plugin 'fatih/vim-go' \" 4 YouCompleteMe 2 complete the code Plugin 'Valloric/YouCompleteMe' \" 4 vim-python-pep8-indent Plugin 'hynek/vim-python-pep8-indent' \" 4 minibufexpl Plugin 'fholgado/minibufexpl.vim' call vundle#end() \" required \" To ignore plugin indent changes, instead use: \"filetype plugin on filetype on filetype plugin on filetype indent on \" \" Brief help \" :PluginList - lists configured plugins \" :PluginInstall - installs plugins; append `!` to update or just :PluginUpdate \" :PluginSearch foo - searches for foo; append `!` to refresh local cache \" :PluginClean - confirms removal of unused plugins; append `!` to auto-approve removal \" \" see :h vundle for more details or wiki for FAQ \" Put your non-Plugin stuff after this line set backspace=indent,eol,start \" Vim5 and later versions support syntax highlighting. Uncommenting the next \" line enables syntax highlighting by default. syntax enable syntax on \" colorscheme darkblue let g:molokai_original = 1 let g:rehash256 = 1 colorscheme molokai set tabstop=4 set softtabstop=4 set shiftwidth=4 set expandtab set autoindent set cindent set smartindent set nu set ic set statusline=%f%r%m%*%=[Line:%l/%L,Col:%c] set laststatus=2 set ruler set incsearch \"set hlsearch set cursorline \"set textwidth=79 set fileformat=unix let &termencoding=&encoding set fileencodings=utf-8,gb18030,gbk,gb2312,big5 set nobackup set nowritebackup \" 4 code fold set foldmethod=indent set foldlevelstart=99 map za mapc :set paste mapv :set nopaste mapd :sp mapf :vs \" 4 vim-flake8 let g:flake8_cmd=\"/usr/local/bin/flake8\" \" 4 syntastic let g:syntastic_python_checkers = ['flake8'] \" 4 vim-go let g:go_highlight_functions = 1 let g:go_highlight_methods = 1 let g:go_highlight_fields = 1 let g:go_highlight_types = 1 let g:go_highlight_operators = 1 let g:go_highlight_build_constraints = 1 let g:go_fmt_command = \"goimports\" mapg :GoMetaLinter mapw :GoDef \" 4 NERDTree silent! mapA :NERDTree silent! mapa :NERDTreeFind silent! maps :NERDTreeClose \" 4 ycm nnoremap q :YcmCompleter GoToDefinitionElseDeclaration set completeopt=menu,menuone TODO: 注释说明, vundle及部分插件安装 "},"python/character.html":{"url":"python/character.html","title":"I. 字符编码问题","keywords":"","body":"字符编码问题 了解python字符编码之前，要先了解一个老生常谈的问题，\"unicode\" 和 \"str\" 有什么区别 unicode 和 str unicode是通用的字符编码，它被不同的编码方式(如utf-8, gbk...)编码后，变成由不同byte组成的str Unicode 提供了所有我们需要的字符的空间，但是计算机的传输只能通过bytes 。我们需要一种用 bytes 来表示 Unicode 的方法这样才可以存储和传播他们，这个过程就是encoding 在python中，unicode通过encode转换成str，str通过decode转换成unicode >>> a = \"测试\" >>> type(a), a (, '\\xe6\\xb5\\x8b\\xe8\\xaf\\x95') # a是utf-8编码的str >>> b = a.decode(\"utf-8\") >>> type(b), b (, u'\\u6d4b\\u8bd5') # b是a用utf-8解码后的unicode >>> c = b.encode(\"gbk\") >>> type(c), c (, '\\xb2\\xe2\\xca\\xd4') # c是b用gbk编码后的str，可以看到，编码后的c和a已经不同了，虽然它在gbk终端下显示出来的仍然是中文\"测试\" python2对unicode和str会做一些隐式操作，允许二者混用 当你进行unicode 和 str 拼接的时候，python会对str做decode操作，隐式转换成unicode进行拼接 >>> a = \"test\" >>> b = u\"test\" >>> type(a), type(b) (, ) >>> type(a + b) # 拼接后的结果为unicode，因为python帮你完成了b(str)到b(unicode)的转换 python默认用ascii编码来对str做decode，这种转换，在字符串是全英文时没有任何问题；但是当字符串存在中文时，一旦编码不符，这种隐式转换就会报错 >>> a = \"测试\" >>> b = u\"测试\" >>> type(a), type(b) (, ) >>> c = a + b Traceback (most recent call last): File \"\", line 1, in UnicodeDecodeError: 'ascii' codec can't decode byte 0xe6 in position 0: ordinal not in range(128) # 这里的报错原因是：\"测试\"是utf-8终端编码输入的str，在用ascii编码方式做decode时，会出现解码错误 理论上，str是编码后的字符串，只允许做解码(decode)；unicode是解码后的字符串，只允许做编码(encode)。但是实际上，python的隐式操作使得二者可以任意编解码 >>> a = \"test\" >>> type(a) >>> a.encode(\"utf-8\") # python底层处理为a.decode(\"ascii\").encode(\"utf-8\") 'test' >>> a.decode(\"utf-8\") u'test' >>> b = u\"test\" >>> type(b) >>> b.encode(\"utf-8\") 'test' >>> b.decode(\"utf-8\") # python底层处理为a.encode(\"ascii\").decode(\"utf-8\") u'test' # 同样，当字符串中存在中文时，这种通过ascii编码方式做的隐式转换，在编码不符时就会报错 >>> a = \"测试\" >>> type(a) >>> a.encode(\"utf-8\") Traceback (most recent call last): File \"\", line 1, in UnicodeDecodeError: 'ascii' codec can't decode byte 0xe6 in position 0: ordinal not in range(128) python2这种隐式转换的存在，看起来是让程序员在写程序的时候不用考虑unicode和str的类型；但实际上看看上面演示的那些情况，当你的接口处理过程中存在中文字符，而你又忽略了unicode和str的区别，在python2做隐式转换时，程序就会出错 最安全的做法是，在程序处理返回时，对字符串采用统一的编码；不同编码的str按照各自编码decode成unicode后，再采用统一的编码方式encode成str来进行返回 >>> a = u\"测试\".encode(\"utf-8\") >>> b = u\"测试\".encode(\"gbk\") >>> c = (a.decode(\"utf-8\") + b.decode(\"gbk\")).encode(\"utf-8\") >>> print c 测试测试 参考链接 python unicode 之痛 json处理中的字符编码问题 python的官方json包用于做字典字符串之间的转换工作，然而这个转换的过程中，对字符编码的处理上有一些需要额外注意的地方 >>> a = {\"data\": \"测试\"} >>> print json.dumps(a) {\"data\": \"\\u6d4b\\u8bd5\"} 可以看到，当通过json.dumps()将字典a转换为字符串的过程中，对字典中的元素返回的是unicode的结果(\"\\u6d4b\\u8bd5\")。我们知道，unicode是通过str解码来的。在调用json.dumps()时，可以指定一个参数encoding，这个参数默认为utf-8，也就是默认以utf-8编码方式来进行解码，官方包里对encoding的描述如下： ``encoding`` is the character encoding for str instances, default is UTF-8. 因此，如果你需要解析一个gbk编码的字典对象，就需要指定encoding=\"gbk\" >>> a = {\"data\": u\"测试\".encode(\"gbk\")} >>> print json.dumps(a) # 没有指定编码方式时，默认用utf-8解码，会报错 Traceback (most recent call last): File \"\", line 1, in File \"/usr/local/Cellar/python/2.7.13_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/json/__init__.py\", line 244, in dumps return _default_encoder.encode(obj) File \"/usr/local/Cellar/python/2.7.13_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/json/encoder.py\", line 207, in encode chunks = self.iterencode(o, _one_shot=True) File \"/usr/local/Cellar/python/2.7.13_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/json/encoder.py\", line 270, in iterencode return _iterencode(o, 0) UnicodeDecodeError: 'utf8' codec can't decode byte 0xb2 in position 0: invalid start byte >>> print json.dumps(a, encoding=\"gbk\") # 指定encoding=\"gbk\"后，可以正常输出json字符串 {\"data\": \"\\u6d4b\\u8bd5\"} 不过，此时输出的json字符串中，中文字符是unicode的，不能正常显示；当你的接口想要返回一个可正常显示的含有中文字符的json字符串时，需要在调用json.dumps()时指定ensure_ascii参数为False >>> a = {\"data\": u\"测试\".encode(\"gbk\")} >>> print json.dumps(a, encoding=\"gbk\", ensure_ascii=False) {\"data\": \"测试\"} 虽然可以正常显示了，但是这时候引入了一个新的问题 >>> a = {\"data\": u\"测试\".encode(\"gbk\")} >>> b = json.dumps(a, encoding=\"gbk\") >>> c = json.dumps(a, encoding=\"gbk\", ensure_ascii=False) >>> print type(b), b {\"data\": \"\\u6d4b\\u8bd5\"} # 原始json.dumps()的结果类型为str >>> print type(c), c {\"data\": \"测试\"} # 设置ensure_ascii后json.dumps()的结果类型为unicode 要知道，当结果中存在中文字符的时候，是需要格外注意字符串类型是unicode还是str的，否则会在程序处理过程中出现问题。比如我们的接口中需要处理一个含有gbk编码元素的字典，然后返回utf-8编码的json结果 >>> a = {\"data\": u\"测试\".encode(\"gbk\")} >>> b = json.dumps(a, encoding=\"gbk\", ensure_ascii=False) >>> b.decode(\"gbk\").encode(\"utf-8\") # 进行gbk解码，并进行utf-8编码返回 Traceback (most recent call last): File \"\", line 1, in UnicodeEncodeError: 'ascii' codec can't encode characters in position 10-11: ordinal not in range(128) # 由于设置ensure_ascii=False时，json.dumps()返回的结果从str变成了unicode；因此当我们对一个unicode的结果进行decode解码时，就会报错 可能有人会说，那我碰到ensure_ascii=False的情况时，既然都知道返回的和原来不一样，是个unicode了；那我直接对它做encode，不按照原来处理str的方法(先decode成unicode，再encode成目标编码的str)，不就行了吗？但是事实上并没有那么简单。当我们的原始编码是utf-8，目标编码是gbk时，情况又不一样了 >>> a = {\"data\": u\"测试\".encode(\"utf-8\")} >>> b = json.dumps(a, encoding=\"utf-8\", ensure_ascii=False) >>> b.encode(\"gbk\") Traceback (most recent call last): File \"\", line 1, in UnicodeDecodeError: 'ascii' codec can't decode byte 0xe6 in position 10: ordinal not in range(128) 当ensure_ascii=False的时候，json.dumps()返回的结果不是unicode吗？对一个unicdoe的字符串，我们应该是可以encode成任意str的，怎么上面又报错了呢？我们来看一下现在json.dumps()的结果类型 >>> type(b) 说好的unicode，在utf-8编码下又变回了str。我们来看下这个ensure_ascii的官方注解 可以看到，json.dumps()当设定ensure_ascii=False，且使用了encoding参数时，才会返回unicode。encoding=utf-8时之所以返回的是str，是因为json.dumps()方法默认的encoding=utf-8，相当于encoding parameter is not used，因此仍然保持原str返回。 总结 当使用json.dumps()处理含有中文字符的字典时，需要格外注意编码问题 如果源输入是utf-8编码，直接使用json.dumps(a, ensure_ascii=False)即可，默认encoding=utf-8，返回的就是一个utf-8编码的str 如果源输入是其他编码，如gbk，则使用json.dumps(a, ensure_ascii=False, encoding=\"gbk\")，返回的是一个unicode，可以根据需要encode成目标编码的str进行传输 "},"golang/performance.html":{"url":"golang/performance.html","title":"I. Go的性能指标","keywords":"","body":"Go的性能指标 指标 latency cost 影响Go性能指标的几个因素 algorithm gc mechanical sympathy "},"golang/heap_stack.html":{"url":"golang/heap_stack.html","title":"II. Go的堆栈分配","keywords":"","body":"Go的堆栈分配 Golang的程序栈 每个goroutine维护着一个栈空间，默认最大为4KB 当goroutine的栈空间不足时，golang会调用runtime.morestack(汇编实现：asm_xxx.s)来进行动态扩容 连续栈：当栈空间不足的时候申请一个2倍于当前大小的新栈，并把所有数据拷贝到新栈， 接下来的所有调用执行都发生在新栈上。 每个function维护着各自的栈帧(stack frame)，当function退出时会释放栈帧 参考链接： go语言连续栈 为何说Goroutine的栈空间可以无限大 Goroutine stack function内部的栈操作 用一段简单的代码来说明Go函数调用及传参时的栈操作： package main func g(p int) int { return p+1; } func main() { c := g(4) + 1 _ = c } 执行go tool compile -S main.go生成汇编，并截取其中的一部分来说明一下程序调用时的栈操作 \"\".g t=1 size=17 args=0x10 locals=0x0 // 初始化函数的栈地址 // 0-16表示函数初始地址为0，数据大小为16字节(input: 8字节，output: 8字节) // SB是函数寄存器 0x0000 00000 (test_stack.go:3) TEXT \"\".g(SB), $0-16 // 函数的gc收集提示。提示0和1是用于局部函数调用参数，需要进行回收 0x0000 00000 (test_stack.go:3) FUNCDATA $0, gclocals·aef1f7ba6e2630c93a51843d99f5a28a(SB) 0x0000 00000 (test_stack.go:3) FUNCDATA $1, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) // FP(frame point)指向栈底 // 将FP+8位置的数据(参数p)放入寄存器AX 0x0000 00000 (test_stack.go:4) MOVQ \"\".p+8(FP), AX 0x0005 00005 (test_stack.go:4) MOVQ (AX), AX // 寄存器值自增 0x0008 00008 (test_stack.go:4) INCQ AX // 从寄存器中取出值，放入FP+16位置(返回值) 0x000b 00011 (test_stack.go:4) MOVQ AX, \"\".~r1+16(FP) // 返回，返回后程序栈的空间会被回收 0x0010 00016 (test_stack.go:4) RET 0x0000 48 8b 44 24 08 48 8b 00 48 ff c0 48 89 44 24 10 H.D$.H..H..H.D$. 0x0010 c3 . \"\".main t=1 size=32 args=0x0 locals=0x10 0x0000 00000 (test_stack.go:7) TEXT \"\".main(SB), $16-0 0x0000 00000 (test_stack.go:7) SUBQ $16, SP 0x0004 00004 (test_stack.go:7) MOVQ BP, 8(SP) 0x0009 00009 (test_stack.go:7) LEAQ 8(SP), BP 0x000e 00014 (test_stack.go:7) FUNCDATA $0, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 0x000e 00014 (test_stack.go:7) FUNCDATA $1, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) // SP(stack point)指向栈顶 // 把4存入SP的位置 0x000e 00014 (test_stack.go:8) MOVQ $4, \"\".c(SP) // 这里会看到没有第9行`call g()`的调用出现，这是因为go汇编编译器会把一些短函数变成内嵌函数，减少函数调用 0x0016 00022 (test_stack.go:10) MOVQ 8(SP), BP 0x001b 00027 (test_stack.go:10) ADDQ $16, SP 0x001f 00031 (test_stack.go:10) RET 事实上，即便我定义了指针调用，以上的数据也都是在栈上拷贝的；那么Golang中的数据什么时候会被分配到堆上呢？ 参考链接： Golang汇编快速指南 Golang汇编 Golang汇编命令解读 Golang逃逸分析 在编译程序优化理论中，逃逸分析是一种确定指针动态范围的方法，用于分析在程序的哪些地方可以访问到指针。 Golang在编译时的逃逸分析可以减少gc的压力，不逃逸的对象分配在栈上，当函数返回时就回收了资源，不需要gc标记清除。 如果你定义的对象的方法上有同步锁，但在运行时，却只有一个线程在访问，此时逃逸分析后的机器码，会去掉同步锁运行，提高效率。 举个栗子 还是1.1里的那段程序代码，我们可以执行go build -gcflags '-m -l' test_stack.go来进行逃逸分析，输出结果如下 # command-line-arguments ./test_stack.go:3: g p does not escape ./test_stack.go:9: main &c does not escape 可以看到，对象c是没有逃逸的，还是分配在栈上。 即便在一开始定义的时候直接把c定义为指针： package main func g(p *int) int { return *p + 1 } func main() { c := new(int) (*c) = 4 _ = g(c) } 逃逸分析的结果仍然不会改变 # command-line-arguments ./test_stack.go:3: g p does not escape ./test_stack.go:8: main new(int) does not escape 那么，什么时候指针对象才会逃逸呢？ 按值传递和按址传递 按值传递 package main func g(p int) int { ret := p + 1 return ret } func main() { c := 4 _ = g(c) } 返回值ret是按值传递的，执行的是栈拷贝，不存在逃逸 按址传递 package main func g(p *int) *int { ret := *p + 1 return &ret } func main() { c := new(int) *c = 4 _ = g(c) } 返回值&ret是按址传递，传递的是指针对象，发生了逃逸，将对象存放在堆上以便外部调用 # command-line-arguments ./test_stack.go:5:9: &ret escapes to heap ./test_stack.go:4:14: moved to heap: ret ./test_stack.go:3:17: g p does not escape ./test_stack.go:9:10: main new(int) does not escape golang只有在function内的对象可能被外部访问时，才会把该对象分配在堆上 在g()方法中，ret对象的引用被返回到了方法外，因此会发生逃逸；而p对象只在g()内被引用，不会发生逃逸 在main()方法中，c对象虽然被g()方法引用了，但是由于引用的对象c没有在g()方法中发生逃逸，因此对象c的生命周期还是在main()中的，不会发生逃逸 再看一个栗子 package main type Ret struct { Data *int } func g(p *int) *Ret { var ret Ret ret.Data = p return &ret } func main() { c := new(int) *c = 4 _ = g(c) } 逃逸分析结果 # command-line-arguments ./test_stack.go:10:9: &ret escapes to heap ./test_stack.go:8:6: moved to heap: ret ./test_stack.go:7:17: leaking param: p to result ~r1 level=-1 ./test_stack.go:14:10: new(int) escapes to heap 可以看到，ret和2.2中一样，存在外部引用，发生了逃逸 由于ret.Data是一个指针对象，p赋值给ret.Data后，也伴随p发生了逃逸 main()中的对象c，由于作为参数p传入g()后发生了逃逸，因此c也发生了逃逸 当然，如果定义ret.Data为int(instead of *int)的话，对象p也是不会逃逸的(执行了拷贝) 参考链接： Go语言逃逸分析 对开发者的一些建议 大对象按址传递，小对象按值传递 按址传递更高效，按值传递更安全(from William Kennedy) 90%的bug都来自于指针调用 初始化一个结构体，使用引用的方式来传递指针 func r() *Ret{ var ret Ret ret.Data = ... ... return &ret } 只有返回ret对象的引用时才会把对象分配在堆上，我们不必要在一开始的时候就显式地把ret定义为指针 ret = &Ret{} ... return ret 对阅读代码也容易产生误导 "},"golang/gc.html":{"url":"golang/gc.html","title":"III. Go的垃圾回收","keywords":"","body":"Go的垃圾回收 GC算法 go1.5以前使用标记清除法(Mark-Sweep)： 从程序根节点开始递归遍历所有对象，将能遍历到的对象打上标记 将所有未标记的的对象当作垃圾销毁 不用担心循环引用问题，但是需要一段时间来暂停程序以便标记 go1.5后采用的是三色标记算法(white-grey-black)： 打开write barrier(写屏障) write barrier是编译器在每个内存写操作前生成的一个小的代码段，用于在golang gc时监控指针的引用操作，防止误回收。 将所有escape to heap的对象放入白色集合中 遍历程序栈(非递归)，将遍历到白色集合中的对象放入灰色集合中 遍历灰色集合中的对象，将遍历到的灰色对象放到黑色集合中，并将此灰色对象引用到的白色对象放入灰色集合中 重复4，直到灰色集合中没有对象。在此过程中，若write barrier检测到有黑色对象引用了白色对象，会将此白色对象放入灰色集合中 回收掉白色集合中的对象 STW(Stop the World) golang在进行GC的时候是需要一小段时间来暂停程序的运行的。golang每升级一个大版本，都会对GC做一定的优化，以提升GC效率、缩短STW的时间： go1.4前使用标记清除法，在每次GC标记内存对象时都需要一段STW时间(毫秒到秒级) go1.4并行处理标记和清理协程，但是仍然需要在标记时STW go1.5-1.7使用三色标记算法，只在write barrier和rescan grey stacks时STW(毫秒级) go1.8使用hybrid write barrier，去除了rescan grey stacks的STW，STW时间在10-100微秒 go1.9后提升了对大对象的收集效率，STW时间基本稳定在100微秒内 参考链接： gotraining/pointers/gc golang垃圾回收机制 Golang 垃圾回收剖析 知乎: write barrier 为Go语言GC正名－2秒到1毫秒的演变史 go 1.8 eliminate stw stack re-scanning 减轻GC压力 golang gc的时间长短，主要和待GC的对象数量有关，待GC的对象越少，GC的时间越短。 sync.Pool 临时对象池，用于复用已产生的对象，减少程序内对象的数量，减轻GC压力。sync.Pool是并发安全的。 参考链接： sync.Pool "},"golang/goroutine.html":{"url":"golang/goroutine.html","title":"IV. Go的协程","keywords":"","body":"Go的协程 Go协程和线程的区别 资源调度 线程由内核调度，根据cpu时间片执行抢占式调度 协程由程序调度(runtime包)，执行协同式调度(2中会详述) 内存占用 执行线程所需的栈内存至少是MB级别 执行协程只需要4KB左右的栈内存 上下文切换 线程涉及到用户态和内核态的切换：需要切换通用寄存器(8个)，程序计数器PC，指令寄存器IR，地址寄存器AR，累加寄存器AC，状态寄存器EFLAGS等 协程上下文切换只涉及到栈指针和三个寄存器(程序计数器PC, 栈指针寄存器SP, 数据寄存器DX）的切换 参考链接： Golang协程详解 通用寄存器 Go协程调度 M：内核线程 G：goroutine，并发的最小逻辑单元，由程序创建 P：处理器，执行G的上下文环境，每个P会维护一个本地的goroutine队列 goroutine有三个状态： waiting: 协程处于全局的队列等待调度 runnable: 协程处于本地队列，等待执行 running: 协程正在运行 G的创建 go调用runtime.newproc()方法来创建G 首先，检查当前P的空闲队列中有没有可用的G，如果有，就直接从中取一个；如果没有，则分配一个新的G，挂载到P的本地队列中 获取了G之后，将调用参数保存到G的栈中，将SP, PC等上下文环境保存到G的sched域中 此时的G处于runnable状态，一旦分配到CPU，就可以进入running状态 G何时被调度 当G被创建时，会立即获得一次运行的机会 如果此时正在运行的P的数量没有达到上限，go会调用runtime.wakep()方法唤醒P；然后调度器选择M绑定P来执行G，必要时会新建M 当此时正在运行的P数量到达上限时，G会进入本地队列等待，当队列前面的G处于以下几种状态时，会触发切换，进入waiting状态： 加锁 io操作 系统调用 运行时间过长(runnable) G的消亡 当G执行完毕返回后，go会调用runtime.exit()方法回收G(包括回收栈指针, 清空寄存器SP、 PC...) 然后将G放入P的空闲队列中，等待runtime.newproc()方法取出 参考链接： golang之协程 goroutine的生老病死 谈goroutine调度器 Go channel channel是go协程通信的主要方式。channel不是队列，可以把它理解为一种信号模型(from William Kennedy) channel分为以下两种类型： 一种是无缓冲的channel，在创建channel时不指定长度。无缓冲的channel若没有用户读取，在写入时会始终阻塞，通常可以作为保证信号使用 另一种是缓冲的channel，即buffer channel，在创建channel时指定长度(>=1)。buffer channel为空时会阻塞读，buffer channel满时会阻塞写，可以作为数据传输使用 当buffer channel的长度指定为1时，可以作为延迟保证信号使用(信号发送方发送信号后不阻塞等待接收方接收) channel有以下三种状态： nil：初始化channel。无法读写 open：通过make分配channel空间。可读可写 close: 通过close()关闭channel。close的channel != nil；可以继续从中读取数据，但是不能写入(panic) 参考链接： gotraining/concurrency/channels 基于channel实现的异步日志模型 package main import ( \"fmt\" \"io\" \"os\" \"strconv\" \"sync\" ) var globalWg sync.WaitGroup // Logger struct implement log type Logger struct { channel chan string wg sync.WaitGroup } // NewLog return a new Logger func NewLog(w io.Writer, cap int) *Logger { l := Logger{ channel: make(chan string, cap), } l.wg.Add(1) go func() { defer l.wg.Done() for v := range l.channel { fmt.Fprintln(w, v) } fmt.Println(\"close\") }() return &l } // Close close logger func (l *Logger) Close() { close(l.channel) l.wg.Wait() } // Println print msg func (l *Logger) Println(v string) { select { case l.channel 执行结果： output: 11 0 5 1 2 3 4 8 6 7 9 10 close 可以看到，超过并发数的时候执行了default行为输出了output: 11 当然，我们也可以自定义default行为，比如超过并发数的时候停等一小段时间再写入；或者是不设置default行为，超过并发时阻塞写入直到解除阻塞为止。 这个模型还可以结合协程池grpool，来做一个后台并发写入的日志系统 效率和安全始终是一对矛盾，异步日志虽然能很大程度提高程序效率(不需要等待io操作)；但是如果程序crash，在channel中尚未写入的数据就会丢失。因此在使用的时候也要注意channel的长度设置，如果需要guarantee的，甚至要设置成unbuffer(基本等于同步日志)或者buffer = 1。 Suggestion 单核过多线程未必会提高效率，更多的抢占式调度和上下文切换，有时反而会让效率降低；经验之谈：3 thread per core is best(from William Kennedy) 对于cpu-bound work，高并发未必会提高效率(cpu密集型工作的切换还是需要cpu来调度) 对于io-bound work，应该最大限度地利用并发来提高效率 "},"golang/stack_trace.html":{"url":"golang/stack_trace.html","title":"V. Go的调试信息","keywords":"","body":"Go的调试信息 当golang程序出现panic的时候会输出一段堆栈调试信息，开发人员可以通过这些调试信息快速地定位问题。 举个栗子 我们通过下面这段程序，直接让程序panic package main func main() { slice := make([]string, 2, 4) Example(slice, \"hello\", 10) } func Example(slice []string, str string, i int) { panic(\"stack trace\") } 运行后输出的调试信息如下 panic: stack trace goroutine 1 [running]: main.Example(0xc42003ff30, 0x2, 0x4, 0x106b75a, 0x5, 0xa) /Users/maniafish/Myworkspace/go_project/src/test/test_panic.go:9 +0x39 main.main() /Users/maniafish/Myworkspace/go_project/src/test/test_panic.go:5 +0x76 exit status 2 第一行是panic信息: stack trace 第二行是发生panic的goroutine及其运行状态(running) 接下来就是发生panic的function调用情况了。我们通常会关注显示的文件和行号，可以快速定位到是哪一行代码抛出的异常 除此之外我们还可以从中看到发生panic的function的输入参数，如main.Example(0xc42003ff30, 0x2, 0x4, 0x106b75a, 0x5, 0xa)对应func Example(slice []string, str string, i int)的三个输入参数： slice: 0xc42003ff30(slice指针地址), 0x2(slice的长度), 0x4(slice的容量) str: 0x106b75a(str字符串头指针地址), 0x5(str字符串长度) i: 0xa(i = 10) 空指针错误 package main import \"fmt\" type S struct { Msg string } func (s *S) f(a int) { fmt.Printf(\"%v: %d\\n\", s.Msg, a) } func main() { Example(nil) } func Example(s *S) { s.f(1) } 以上这段程序运行结果如下： panic: runtime error: invalid memory address or nil pointer dereference [signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x1095257] goroutine 1 [running]: main.(*S).f(0x0, 0x1) /Users/maniafish/Myworkspace/go_project/src/test/test_panic.go:10 +0x57 main.Example(0x0) /Users/maniafish/Myworkspace/go_project/src/test/test_panic.go:18 +0x34 main.main() /Users/maniafish/Myworkspace/go_project/src/test/test_panic.go:14 +0x2a exit status 2 panic信息(invalid memory address or nil pointer dereference)告诉我们是无效的地址调用 我们通过main.(*S).f(0x0, 0x1)的第一个参数，可以知道这个指针*S的方法f()调用时使用的是空指针 然后通过main.Example(0x0)，知道这个空指针是通过Example()方法传进来的，定位到了问题所在。 参考链接： Go stack trace "},"golang/composition.html":{"url":"golang/composition.html","title":"VI. Go的interface","keywords":"","body":"Go的interface go的interface类型定义了一组方法，如果某个对象实现了某个interface的所有方法，此对象就实现了此interface。 interface focus on what the data does, instead of what the data is(From William Kennedy) interface能够帮助我们更好地做泛型编程，实现代码逻辑的抽象和灵活组合，更方便地进行面向对象的编程。 下面通过一个例子来说明一下go中基于interface的编程设计思路。 场景1 设计思路 定义结构体A，实现方法Store() 定义结构体B，实现方法Pull() 定义System封装A和B，并通过System向外提供api 代码示例 // A is a system for data collection type A struct { ... } // Store function for storing data func (a *A) Store(data interface{}) { ... } // B is a system for data pulling type B struct { ... } // Pull function for pulling data func (b *B) Pull(data interface{}) { ... } // System wraps A and B together type System struct { A B } // Api providing api for users func Api(s *System, data []interface{}) error { ... for _, v := range data { s.Store(v) } ... dp := ... err = s.Pull(dp) ... return } func main() { a := A { ... } b := B { ... } s := System{a, b} data := ... err := Api(&s, data) if err != nil { ... } ... } 场景2 设计思路 系统组件A1~A3都实现了同样的方法Store()，B1~B3实现了Pull()，考虑使用interface进行抽象解耦 system无需关心具体的A和B，只需要做interface的组合即可 代码示例 // Storer is an interface for data collection type Storer interface { Store(data interface{}) } // A1 is a system for data collection type A1 struct { ... } // Store function for storing data func (a *A1) Store(data interface{}) { ... } // define A2 ~ A3 implementing Storer ... // Puller is an interface for data pulling type Puller interface { Pull(data interface{}) } // B1 is a system for data pulling type B1 struct { ... } // Pull function for pulling data func (b *B1) Pull(data interface{}) { ... } // define B2 ~ B3 implementing Puller ... // System wraps Storer and Puller together type System struct { Storer Puller } // Api providing api for users func Api(s *System, data []interface{}) error { ... for _, v := range data { s.Store(v) } ... dp := ... err = s.Pull(dp) ... return } func main() { ... a := A1 { ... } b := B1 { ... } // s can be any composition of An and Bn s := System{&a, &b} data := ... err := Api(&s, data) if err != nil { ... } ... } 进一步抽象 我们希望Api()方法变得更加通用，它无需关心System的具体结构，只关心System提供的Pull()和Store()方法 因此我们可以定义一个PullStorer来做Puller和Storer的interface组合，这样一来只要是实现了Puller和Storer的结构体，都可以由Api()方法调用来对外提供服务 ... // PullStorer is an interface implementing Storer and Puller type PullStorer interface { Storer Puller } // Api providing api for users func Api(s PullStorer, data []interface{}) error { ... for _, v := range data { s.Store(v) } ... dp := ... err = s.Pull(dp) ... return } func main() { ... // s can be any composition of An and Bn s := System{ ... } data := ... err := Api(&s, data) if err != nil { ... } ... } interface滥用问题 我们现在定义了以下interface // Storer is an interface for data collection type Storer interface { Store(data interface{}) } // Puller is an interface for data pulling type Puller interface { Pull(data interface{}) } // PullStorer is an interface implementing Storer and Puller type PullStorer interface { Storer Puller } 我们的Api()里关注的是Store()和Pull()方法 // Api providing api for users func Api(s PullStorer, data []interface{}) error { ... for _, v := range data { s.Store(v) } ... dp := ... err = s.Pull(dp) ... return } 这个传入Api()的s，可以是任意实现了Store()方法的An和任意实现了Pull()方法的Bn的组合 我们在Api()中调用s.Store()，实际上调用的是s.Storer.Store()；调用s.Pull()，实际上调用的是s.Puller.Pull() 既然我们的Api()关注的只是Puller和Storer，那么我们为什么要额外让他们组合成一个PullStorer来传入呢 基于以上设计思路，我们可以去掉System和PullStorer，得到以下简洁且可扩展性强的代码 // Storer is an interface for data collection type Storer interface { Store(data interface{}) } // A1 is a system for data collection type A1 struct { ... } // Store function for storing data func (a *A1) Store(data interface{}) { ... } // define A2 ~ A3 implementing Storer ... // Puller is an interface for data pulling type Puller interface { Pull(data interface{}) } // B1 is a system for data pulling type B1 struct { ... } // Pull function for pulling data func (b *B1) Pull(data interface{}) { ... } // define B2 ~ B3 implementing Puller ... // Api providing api for users func Api(s Storer, p Puller, data []interface{}) error { ... for _, v := range data { s.Store(v) } ... dp := ... err = p.Pull(dp) ... return } func main() { ... a := A1 { ... } b := B1 { ... } // a can be any An, b can be any Bn data := ... err := Api(&a, &b, data) if err != nil { ... } ... } "},"golang/operator.html":{"url":"golang/operator.html","title":"VII. Go的变量作用域","keywords":"","body":"Go的变量作用域 变量作用域 全局变量 package a var g int // 本包内可见 var G int // 外部import a后可见 局部变量 func Test() { var a int // a在Test()内可见 ... for i := 1; i 参数变量 func Test(a int) { // a在Test()方法内可见，在Test()外赋值。 ... } 局部变量声明后未使用会编译失败；参数变量在function内可以不使用，比如以下情况也是可以编译通过的。 func main() { a := 1 Test(a) // a作为参数调用 } func Test(a) { // a在Test()内部没有使用 fmt.Println(\"test\") } 对按值传参的情况，方法内对参数a的修改不影响传入前的原参数a 对按址传参的情况，方法内对参数a的修改也会影响到传入前的原参数a 循环并发中的变量传参问题 理解了go中的变量作用域后，我们来看看下面这段代码 package main import ( \"fmt\" \"sync\" ) var wg sync.WaitGroup func main() { for i := 0; i 输出结果如下 10 10 10 10 10 10 10 10 10 10 这是因为变量i作为局部变量，同时在for循环和go协程中被引用，循环递增和打印的是同一个地址的数据 实际上这个输出是无法预期的，这里都输出10是因为后台协程完成创建时，for循环已经完成了对i的递增操作 如果要想让循环中的go协程如我们预期的一样输出1~10的值，要采取以下写法，使用参数变量 package main import ( \"fmt\" \"sync\" ) var wg sync.WaitGroup func main() { for i := 0; i Go的:=操作符 Go的:=操作符用于声明变量的同时给变量赋值，它也会定义新变量的作用域。以下面这段代码为例 package main import ( \"fmt\" \"sync\" ) var wg sync.WaitGroup func main() { a := 1 fmt.Printf(\"a in main: %p, %d\\n\", &a, a) // a in main: 0xc420016090, 1 // 在main中声明了变量a，地址为0xc420016090，并给a赋值为1 for a := 2; a "},"golang/slice.html":{"url":"golang/slice.html","title":"VIII. Go的slice","keywords":"","body":"Go的slice go的slice可以理解为一种动态可变长的数组，初始化时可以指定长度len和容量cap；可以通过append()方法在slice末尾追加元素。 一个append的栗子 package main import \"fmt\" func main() { s0 := []int{1, 2, 3, 4} fmt.Printf(\"s0: %v, len(s): %d, cap(s): %d\\n\\n\", s0, len(s0), cap(s0)) // s0: [1 2 3 4], len(s): 4, cap(s): 4 // 初始化一个slice s0，len = cap = 4(不指定cap的情况下，默认cap = len) s1 := s0[:2] fmt.Printf(\"s1: %v, len(s1): %d, cap(s1): %d\\n\\n\", s1, len(s1), cap(s1)) // s1: [1 2], len(s1): 2, cap(s1): 4 // 取s0的前个元素构成s1，len = 2, cap = 4 s2 := append(s1, 5, 6, 7) fmt.Printf(\"s2: %v, len(s2): %d, cap(s2): %d\\n\", s2, len(s2), cap(s2)) fmt.Printf(\"s0: %v, len(s0): %d, cap(s0): %d\\n\\n\", s0, len(s0), cap(s0)) // s2: [1 2 5 6 7], len(s2): 5, cap(s2): 8 // append 5, 6, 7到s1，此时空间不足，按照两倍cap动态扩容，分配一块新的内存空间给s2 // s0: [1 2 3 4], len(s0): 4, cap(s0): 4 // s0不变 s3 := append(s1, 8, 9) fmt.Printf(\"s3: %v, len(s3): %d, cap(s3): %d\\n\", s3, len(s3), cap(s3)) fmt.Printf(\"s0: %v, len(s0): %d, cap(s0): %d\\n\\n\", s0, len(s0), cap(s0)) // s3: [1 2 8 9], len(s3): 4, cap(s3): 4 // append 8, 9到s1，空间足够，无须扩容 // s0: [1 2 8 9], len(s0): 4, cap(s0): 4 // s0的后两个元素被append的8, 9取代 } 通过以上栗子可以看出： go的slice只有在空间不足时，才会进行动态扩容，分配新的内存地址。所以在日常开发的时候，要尽量避免以下操作： func A(i []int){ ... b := append(i, ...) ... } func main(){ ... a := []int{...} A(a[:2]) ... } 要防止slice b的操作影响到slice a，可以使用copy()方法 func A(i []int){ ... b := append(i, ...) ... } func main(){ ... a := []int{...} i := make([]int, 2) copy(i, a[:2]) A(i) ... } go的slice执行的动态扩容是一个内存拷贝的操作，分配一块新的2倍cap的空间给slice。因此在平时开发的时候，应该尽可能地分配确定的len和cap给slice，防止频繁append进行内存拷贝带来的性能损耗。 比如以下这段代码 func main() { a := make([]int, 0) for i := 0; i 可以改写成下面这样，使用确定的len func main() { a := make([]int, 10) for i := 0; i 即便在不确定len的情况下，也应该尽量预留一个相对充足的cap，来减少2倍cap扩容的次数 func main() { a := make([]int, 0, 10) for i := 0; i 默认按地址传递 通过1.1中的栗子 func A(i []int){ ... b := append(i, ...) // 操作b的时候也会影响到a ... } func main(){ ... a := []int{...} A(a[:2]) ... } 就可以知道，go中slice传参默认是按址传递的，因此在function内对传入的slice进行写操作的时候要注意：这种操作是会影响到function调用方的原slice的。go的map也是默认按址传递 "},"golang/defer.html":{"url":"golang/defer.html","title":"IX. Go的defer处理","keywords":"","body":"Go的defer处理 package main import \"fmt\" func deferFunc() (b int) { b = 1 a := true defer func() { b = 2 }() return } func main() { fmt.Println(deferFunc()) // 这里打印出来的是1，而不是2 // https://stackoverflow.com/questions/37248898/how-does-defer-and-named-return-value-work-in-golang } TODO: go的defer底层机制 "},"network/chunk.html":{"url":"network/chunk.html","title":"I. HTTP协议之chunk(分块传输编码)","keywords":"","body":"HTTP协议之chunk(分块传输编码) 分块传输编码 分块传输编码（Chunked transfer encoding）是超文本传输协议（HTTP）中的一种数据传输机制，允许HTTP由应用服务器发送给客户端应用（通常是网页浏览器）的数据可以分成多个部分。在HTTP协议1.1版本（HTTP/1.1）中提供。 通常，HTTP应答消息中发送的数据是整个发送的，Content-Length消息头字段表示数据的长度。数据的长度很重要，因为客户端需要知道哪里是应答消息的结束，以及后续应答消息的开始。然而，使用分块传输编码，数据分解成一系列数据块，并以一个或多个块流式传输，这样服务器可以发送数据而不需要预先知道发送内容的总大小。 HTTP 1.1引入分块传输编码提供了以下几点好处： HTTP分块传输编码允许服务器为动态生成的内容维持HTTP持久链接。通常，持久链接需要服务器在开始发送消息体前发送Content-Length消息头字段，但是对于动态生成的内容来说，在内容创建完之前是不可知的。 分块传输编码允许服务器在最后发送消息头字段。对于那些头字段值在内容被生成之前无法知道的情形非常重要，例如消息的内容要使用散列进行签名，散列的结果通过HTTP消息头字段进行传输。没有分块传输编码时，服务器必须缓冲内容直到完成后计算头字段的值并在发送内容前发送这些头字段的值。 HTTP服务器有时使用压缩以缩短传输花费的时间。分块传输编码可以用来分隔压缩对象的多个部分。在这种情况下，块不是分别压缩的，而是整个负载进行压缩，压缩的输出使用本文描述的方案进行分块传输。在压缩的情形中，分块编码有利于一边进行压缩一边发送数据，而不是先完成压缩过程以得知压缩后数据的大小。 分块传输编码的格式： 如果一个HTTP消息（请求消息或应答消息）的Transfer-Encoding消息头的值为chunked，那么，消息体由数量未定的块组成，并以最后一个大小为0的块为结束。 每一个非空的块都以该块包含数据的字节数（字节数以十六进制表示）开始，跟随一个CRLF（回车及换行），然后是数据本身，最后块CRLF结束。在一些实现中，块大小和CRLF之间填充有白空格（0x20）。 最后一块是单行，由块大小（0），一些可选的填充白空格，以及CRLF。最后一块不再包含任何数据，但是可以发送可选的尾部，包括消息头字段。消息最后以CRLF结尾。 参考链接: wiki: 分块传输编码 golang http server 与 chunked golang http 包中，处理请求返回的response结构体里，用于写入body的Writer是一个chunkWriter。我们可以通过官方包net/http/server.go: func (c *conn) readRequest(ctx context.Context) (w *response, err error)方法看到： 这里使用w.cw(chunkWriter)生成一个*bufio.Writer，并赋值给w.w(response.Writer)，设定的bufferSize为bufferBeforeChunkingSize。http包中，bufferBeforeChunkingSize的值为2048 net/http/server.go: func (cw *chunkWriter) writeHeader(p []byte) "}}
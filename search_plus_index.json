{"./":{"url":"./","title":"Introduction","keywords":"","body":"tech talk 技术笔记及分享 书籍地址 "},"git/user.html":{"url":"git/user.html","title":"I. 为不同的git项目配置各自独立的用户","keywords":"","body":"为不同的git项目配置各自独立的用户 我们在自己的开发机上往往会管理多个git仓库，可能有些git仓库是属于自己的私人github账号，有些是属于公司的个人gitlab开发账号，这样就需要为不同的仓库配置不同的用户 方法1: config命令 在git仓库目录下执行 $ git config user.name 'xxx' $ git config user.email 'xxx' ps: 配置全局git用户的方法： $ git config --global user.name 'xxx' $ git config --global user.email 'xxx' 方法2: 修改git配置 git仓库目录下，在.git/config文件中添加以下内容 [user] name = xxx email = xxx "},"git/gitbook.html":{"url":"git/gitbook.html","title":"II. gitbook的使用","keywords":"","body":"gitbook的使用 安装gitbook mac下安装gitbook 目录结构 gitbook项目的目录结构如下: - SUMMARY.md - README.md - book.json - _book/ - node_modules/ 其中，我们需要首先创建的是SUMMARY.md(书籍目录) 和 README.md(书籍介绍) SUMMARY.md 书籍目录是gitbook的基础，可以有层级结构，使用markdown写法 # Summary * [git相关](git.md) * [I. 为不同的git项目配置各自独立的用户](./git/user.md) * [II. gitbook的使用](./git/gitbook.md) ... 编译和预览书籍 书籍目录和目录中链接的内容(*.md)文件编辑完成后，执行gitbook serve即可完成书籍的编译 $ gitbook serve Live reload server started on port: 35729 Press CTRL+C to quit ... info: 7 plugins are installed info: loading plugin \"livereload\"... OK info: loading plugin \"highlight\"... OK info: loading plugin \"search\"... OK info: loading plugin \"lunr\"... OK info: loading plugin \"sharing\"... OK info: loading plugin \"fontsettings\"... OK info: loading plugin \"theme-default\"... OK info: found 4 pages info: found 1 asset files info: >> generation finished with success in 0.7s ! Starting server ... Serving book on http://localhost:4000 按照提示信息，访问本机4000端口，即可看到预览结果 执行完成后，会在项目下自动生成书籍的文件目录_book/ 默认的\"Introduction\"页面就是README.md 配置书籍 book.json 在项目目录下新建book.json文件，可以进行书籍配置；book.json示例如下: { \"author\": \"mania_fish\", \"description\": \"How to build effective golang project\", \"extension\": null, \"generator\": \"site\", \"links\": { \"sharing\": { \"all\": null, \"facebook\": null, \"google\": null, \"twitter\": null, \"weibo\": null }, \"sidebar\": { \"mania_fish's github\": \"https://github.com/maniafish\" } }, \"output\": null, \"pdf\": { \"fontSize\": 12, \"footerTemplate\": null, \"headerTemplate\": null, \"margin\": { \"bottom\": 36, \"left\": 62, \"right\": 62, \"top\": 36 }, \"pageNumbers\": false, \"paperSize\": \"a4\" }, \"plugins\": [ \"-lunr\", \"-search\", \"search-pro\", \"anchor-navigation-ex\", \"splitter\", \"sectionx\", \"prism\", \"-highlight\", \"prism-themes\" ], \"title\": \"real effective go\", \"variables\": {}, \"pluginsConfig\": { \"anchor-navigation-ex\": { \"isShowTocTitleIcon\": true, \"tocLevel2Icon\": \"fa fa-hand-o-right\", \"tocLevel3Icon\": \"fa fa-hand-o-right\", \"tocLevel4Icon\": \"fa fa-hand-o-right\" }, \"prism\": { \"css\": [ \"prism-themes/themes/prism-base16-ateliersulphurpool.light.css\" ], \"lang\": { \"flow\": \"typescript\" }, \"ignore\": [ \"mermaid\", \"eval-js\" ] } } } 官方配置字段说明 插件plugins \"-lunr\", \"-search\", \"search-pro\": 禁用掉gitbook默认的搜索插件，使用search-pro, 支持中文搜索 \"anchor-navigation-ex\": 页面章节锚点 由于前三级的标题会被自动锚点并编号，为了文章标题不被锚点，我们采用如下格式: #### 标题 --- # 文章第一节 ## 文章第一节的第一小节 效果如下: \"-highlight\", \"prism\", \"prism-themes\": 禁用原代码高亮功能，使用prism代码主题 更多插件，详见官网 载入配置 在项目目录下执行gitbook install即可安装配置插件；安装完成后，项目下会出现一个node_modules/目录 然后执行gitbook serve即可看到配置完成后的主页 集成发布到github pages 添加git仓库 在项目目录下执行git init新建git仓库 git remote add origin 添加github仓库 touch .gitignore 并且在里面添加以下内容 *~ *.swp *.DS_Store _book/ node_modules/ git add . 添加文件到git版本控制 git commit -m 'git init' 提交变动 git push origin master 推送分支 发布github pages git clone 在下执行git checkout --orphan gh-pages 创建孤儿分支gh-pages git rm --cached -r . 删除暂存区目录 git clean -df 删除未track的目录，不影响.gitignore中的文件 touch .gitignore 并且在里面添加以下内容 *~ *.swp *.DS_Store cp -rf /_book/* ./ 将生成的书籍html内容copy出来 git add . git commit -m 'publish book' git push origin gh-pages 推送完成后，进入github仓库主页，会多出一个environment图标 点击environment图标后，进入如下页面 点击view deployment图标，即可看到发布的gitbook书籍 后续更新github pages 只需执行上述6 - 9 步即可 参考链接： gitbook简明教程 "},"linux/vim_replace.html":{"url":"linux/vim_replace.html","title":"I. vim替换特殊符号","keywords":"","body":"vim替换特殊符号 替换特殊字符为实际控制符 替换换行符 :%s/\\\\r\\\\n/\\r/g 替换tab :%s/\\\\t/\\t/g ps: 设置tab为四个空格的方法 :set tabstop=4 :set expandtab 替换跨平台的控制符 替换^M换行符 :%s/[Ctrl-v][Ctrl-M]/\\r/g 替换^I制表符 :%s/[Ctrl-v][Ctrl-I]/\\t/g 替换首尾字符 第7-15行开头插入* :7,15s/^/* /g 第7-15行末尾插入* :7,15s/$/ */g "},"linux/vim_paste.html":{"url":"linux/vim_paste.html","title":"II. vim剪贴板的使用","keywords":"","body":"vim剪贴板的使用 vim复制命令 常用方法 复制当前行: yy 复制自选区域: 先 v 进入visual模式，用kjhl控制上下左右选择好要复制的区域，然后 y 复制选中区域 如果要按行选择的话，则使用[Shift-v]进入visual line模式即可 黏贴: 光标后黏贴: p 光标前黏贴: [Shift-p] 其他用法 nyy：n表示大于1的数字，复制n行 yw：从光标处复制至一个单子/单词的末尾，包括空格 ye：从光标处复制至一个单子/单词的末尾，不包括空格 y$：从当前光标复制到行末 y0：从当前光标位置（不包括光标位置）复制之行首 y3l：从光标位置（包括光标位置）向右复制3个字符 y5G：将当前行（包括当前行）至第5行（不包括它）复制 y3B：从当前光标位置（不包括光标位置）反向复制3个单词 使用寄存器实现丰富的剪贴板功能 vim提供了10类寄存器: 匿名寄存器 \"\" 编号寄存器 \"0 到 \"9 小删除寄存器 \"- 26个命名寄存器 \"a 到 \"z 3个只读寄存器 \":, \"., \"% Buffer交替文件寄存器 \"# 表达式寄存器 \"= 选择和拖放寄存器 \"*, \"+, \"~ 黑洞寄存器 \"_ 搜索模式寄存器 \"/ 可在vim中通过:help registers查看帮助，通过:reg可以查看当前各寄存器中的值。 匿名寄存器 使用d, c, s, x等删除字符的命令或者y等复制字符的命令时，被操作的字符会进入匿名寄存器\"\"。当你执行黏贴命令p时，黏贴的就是匿名寄存器里的值。 编号寄存器 编号寄存器从\"0到\"9共10个，其中\"0保存这最近拷贝的字符串，\"1到\"9保存着最近9次删除掉的字符串。 当用户指定拷贝操作的寄存器（如\"ay）时，该拷贝数据不会被写入\"0。 \"0寄存器很有用，比如我们copy了一段文本然后用它替换另一段文本。 这时默认匿名寄存器\"\"中的值就变成了被替换文本，如果还需要用copy的文本继续替换的话就需要\"0p了。 小删除寄存器 不足一行的小删除则会被放到小删除寄存器中（\"-），起作用的删除操作符也包括s, c, d, x。 例如： dw # 删除一个词 d9l # 删除9个字符 cb # 向前更改一个词 与\"0寄存器类似，当用户指定寄存器并进行删除时，\"-不会被写入。 命名寄存器 命名寄存器有\"a到\"z共26个，这些寄存器只有当我们指定时才会被使用。比如我们要复制一段文字，存入匿名寄存器\"a，只要使用v选中这段文字，执行\"ay录制宏，这段文字就进入了\"a寄存器；然后使用\"ap即可黏贴这段文字。 只读寄存器 只读寄存器共3个，它们的值是由vim提供的，不允许改变： \".：上次insert模式中插入的字符串。使用.命令可以重复上次操作，使用的就是\".寄存器。 \"%：当前文件名，不是全路径，也不是纯文件名，而是从当前vim的工作目录到该文件的路径。比如你执行vim golang/gc.md打开了一个文件，那么\"%p输出的就是golang/gc.md \":：上次命令模式下键入的命令。使用@:可以执行上次命令。 交替文件寄存器 交替文件寄存器\"#存储着当前vim窗口（Window）的交替文件。交替文件（alternate file）是指 Buffer中的上一个文件，可通过Ctrl+^来切换交替文件与当前文件。 表达式寄存器 表达式寄存器\"=主要用于计算vim脚本的返回值，并插入到文本中。当我们键入\"=后光标会移动到命令行，此时我们可以输入任何vim脚本的表达式。 例如3+2，按下回车并且p则会得到5。 选择和拖放寄存器 选择和拖放寄存器包括\"*, \"+, 和\"~，这三个寄存器的行为是和GUI相关的。 \"*和\"+都是指系统剪切板（clipboard），例如\"*yy即可复制当前行到剪切板，以供其他程序中粘贴；其他程序中复制的内容也会被存储到这两个寄存器中，可以通过\"*p在vim中进行黏贴。 在Mac下执行:set clipboard=unnamed会使得系统剪切板寄存器\"*和vim默认的匿名寄存器\"\"始终保有同样的值，即vim和系统共用剪切板。 有文本拖拽到vim时，被拖拽的文本被存储在\"~中。vim默认的行为是将\"~中内容插入到光标所在位置。 黑洞寄存器 所有删除或拷贝到黑洞寄存器\"_的文本将会消失。这是为了在删除文本的同时不影响任何寄存器的值。 搜索寄存器 搜索寄存器\"/用于存储上一次搜索的关键词。在normal模式下按下/即进入search模式，输入关键字并按下回车即可。 该寄存器是可写的，例如:let @/ = \"maniafish\"将会把\"maniafish\"写入该寄存器。 下次使用/搜索时不输入搜索词直接回车便会搜索\"maniafish\"。 参考链接: 使用 Vim 寄存器 "},"linux/vim_conf.html":{"url":"linux/vim_conf.html","title":"III. vim的插件及配置","keywords":"","body":"vim的插件及配置 我的vim配置 \" Uncomment the next line to make Vim more Vi-compatible \" NOTE: debian.vim sets 'nocompatible'. Setting 'compatible' changes numerous \" options, so any other options should be set AFTER setting 'compatible'. set nocompatible filetype off \" required \" set the runtime path to include Vundle and initialize set rtp+=~/.vim/bundle/Vundle.vim call vundle#begin() \" 4 vundle \" let Vundle manage Vundle Plugin 'gmarik/Vundle.vim' \" 4 the syntax checking when saving Plugin 'scrooloose/syntastic' \" 4 pep8 style checking Plugin 'nvie/vim-flake8' \" 4 background color Plugin 'altercation/vim-colors-solarized' \" 4 file tree init input :NERDTree in vim Plugin 'scrooloose/nerdtree' \" 4 search file Plugin 'kien/ctrlp.vim' \" 4 vim-go Plugin 'fatih/vim-go' \" 4 YouCompleteMe 2 complete the code Plugin 'Valloric/YouCompleteMe' \" 4 vim-python-pep8-indent Plugin 'hynek/vim-python-pep8-indent' \" 4 minibufexpl Plugin 'fholgado/minibufexpl.vim' call vundle#end() \" required \" To ignore plugin indent changes, instead use: \"filetype plugin on filetype on filetype plugin on filetype indent on \" \" Brief help \" :PluginList - lists configured plugins \" :PluginInstall - installs plugins; append `!` to update or just :PluginUpdate \" :PluginSearch foo - searches for foo; append `!` to refresh local cache \" :PluginClean - confirms removal of unused plugins; append `!` to auto-approve removal \" \" see :h vundle for more details or wiki for FAQ \" Put your non-Plugin stuff after this line set backspace=indent,eol,start \" Vim5 and later versions support syntax highlighting. Uncommenting the next \" line enables syntax highlighting by default. syntax enable syntax on \" colorscheme darkblue let g:molokai_original = 1 let g:rehash256 = 1 colorscheme molokai set tabstop=4 set softtabstop=4 set shiftwidth=4 set expandtab set autoindent set cindent set smartindent set nu set ic set statusline=%f%r%m%*%=[Line:%l/%L,Col:%c] set laststatus=2 set ruler set incsearch \"set hlsearch set cursorline \"set textwidth=79 set fileformat=unix let &termencoding=&encoding set fileencodings=utf-8,gb18030,gbk,gb2312,big5 set nobackup set nowritebackup \" 4 code fold set foldmethod=indent set foldlevelstart=99 map za mapc :set paste mapv :set nopaste mapd :sp mapf :vs \" 4 vim-flake8 let g:flake8_cmd=\"/usr/local/bin/flake8\" \" 4 syntastic let g:syntastic_python_checkers = ['flake8'] \" 4 vim-go let g:go_highlight_functions = 1 let g:go_highlight_methods = 1 let g:go_highlight_fields = 1 let g:go_highlight_types = 1 let g:go_highlight_operators = 1 let g:go_highlight_build_constraints = 1 let g:go_fmt_command = \"goimports\" mapg :GoMetaLinter mapw :GoDef \" 4 NERDTree silent! mapA :NERDTree silent! mapa :NERDTreeFind silent! maps :NERDTreeClose \" 4 ycm nnoremap q :YcmCompleter GoToDefinitionElseDeclaration set completeopt=menu,menuone TODO: 注释说明, vundle及部分插件安装 "},"python/character.html":{"url":"python/character.html","title":"I. 字符编码问题","keywords":"","body":"字符编码问题 了解python字符编码之前，要先了解一个老生常谈的问题，\"unicode\" 和 \"str\" 有什么区别 unicode 和 str unicode是通用的字符编码，它被不同的编码方式(如utf-8, gbk...)编码后，变成由不同byte组成的str Unicode 提供了所有我们需要的字符的空间，但是计算机的传输只能通过bytes 。我们需要一种用 bytes 来表示 Unicode 的方法这样才可以存储和传播他们，这个过程就是encoding 在python中，unicode通过encode转换成str，str通过decode转换成unicode >>> a = \"测试\" >>> type(a), a (, '\\xe6\\xb5\\x8b\\xe8\\xaf\\x95') # a是utf-8编码的str >>> b = a.decode(\"utf-8\") >>> type(b), b (, u'\\u6d4b\\u8bd5') # b是a用utf-8解码后的unicode >>> c = b.encode(\"gbk\") >>> type(c), c (, '\\xb2\\xe2\\xca\\xd4') # c是b用gbk编码后的str，可以看到，编码后的c和a已经不同了，虽然它在gbk终端下显示出来的仍然是中文\"测试\" python2对unicode和str会做一些隐式操作，允许二者混用 当你进行unicode 和 str 拼接的时候，python会对str做decode操作，隐式转换成unicode进行拼接 >>> a = \"test\" >>> b = u\"test\" >>> type(a), type(b) (, ) >>> type(a + b) # 拼接后的结果为unicode，因为python帮你完成了b(str)到b(unicode)的转换 python默认用ascii编码来对str做decode，这种转换，在字符串是全英文时没有任何问题；但是当字符串存在中文时，一旦编码不符，这种隐式转换就会报错 >>> a = \"测试\" >>> b = u\"测试\" >>> type(a), type(b) (, ) >>> c = a + b Traceback (most recent call last): File \"\", line 1, in UnicodeDecodeError: 'ascii' codec can't decode byte 0xe6 in position 0: ordinal not in range(128) # 这里的报错原因是：\"测试\"是utf-8终端编码输入的str，在用ascii编码方式做decode时，会出现解码错误 理论上，str是编码后的字符串，只允许做解码(decode)；unicode是解码后的字符串，只允许做编码(encode)。但是实际上，python的隐式操作使得二者可以任意编解码 >>> a = \"test\" >>> type(a) >>> a.encode(\"utf-8\") # python底层处理为a.decode(\"ascii\").encode(\"utf-8\") 'test' >>> a.decode(\"utf-8\") u'test' >>> b = u\"test\" >>> type(b) >>> b.encode(\"utf-8\") 'test' >>> b.decode(\"utf-8\") # python底层处理为a.encode(\"ascii\").decode(\"utf-8\") u'test' # 同样，当字符串中存在中文时，这种通过ascii编码方式做的隐式转换，在编码不符时就会报错 >>> a = \"测试\" >>> type(a) >>> a.encode(\"utf-8\") Traceback (most recent call last): File \"\", line 1, in UnicodeDecodeError: 'ascii' codec can't decode byte 0xe6 in position 0: ordinal not in range(128) python2这种隐式转换的存在，看起来是让程序员在写程序的时候不用考虑unicode和str的类型；但实际上看看上面演示的那些情况，当你的接口处理过程中存在中文字符，而你又忽略了unicode和str的区别，在python2做隐式转换时，程序就会出错 最安全的做法是，在程序处理返回时，对字符串采用统一的编码；不同编码的str按照各自编码decode成unicode后，再采用统一的编码方式encode成str来进行返回 >>> a = u\"测试\".encode(\"utf-8\") >>> b = u\"测试\".encode(\"gbk\") >>> c = (a.decode(\"utf-8\") + b.decode(\"gbk\")).encode(\"utf-8\") >>> print c 测试测试 json处理中的字符编码问题 python的官方json包用于做字典字符串之间的转换工作，然而这个转换的过程中，对字符编码的处理上有一些需要额外注意的地方 >>> a = {\"data\": \"测试\"} >>> print json.dumps(a) {\"data\": \"\\u6d4b\\u8bd5\"} 可以看到，当通过json.dumps()将字典a转换为字符串的过程中，对字典中的元素返回的是unicode的结果(\"\\u6d4b\\u8bd5\")。我们知道，unicode是通过str解码来的。在调用json.dumps()时，可以指定一个参数encoding，这个参数默认为utf-8，也就是默认以utf-8编码方式来进行解码，官方包里对encoding的描述如下： ``encoding`` is the character encoding for str instances, default is UTF-8. 因此，如果你需要解析一个gbk编码的字典对象，就需要指定encoding=\"gbk\" >>> a = {\"data\": u\"测试\".encode(\"gbk\")} >>> print json.dumps(a) # 没有指定编码方式时，默认用utf-8解码，会报错 Traceback (most recent call last): File \"\", line 1, in File \"/usr/local/Cellar/python/2.7.13_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/json/__init__.py\", line 244, in dumps return _default_encoder.encode(obj) File \"/usr/local/Cellar/python/2.7.13_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/json/encoder.py\", line 207, in encode chunks = self.iterencode(o, _one_shot=True) File \"/usr/local/Cellar/python/2.7.13_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/json/encoder.py\", line 270, in iterencode return _iterencode(o, 0) UnicodeDecodeError: 'utf8' codec can't decode byte 0xb2 in position 0: invalid start byte >>> print json.dumps(a, encoding=\"gbk\") # 指定encoding=\"gbk\"后，可以正常输出json字符串 {\"data\": \"\\u6d4b\\u8bd5\"} 不过，此时输出的json字符串中，中文字符是unicode的，不能正常显示；当你的接口想要返回一个可正常显示的含有中文字符的json字符串时，需要在调用json.dumps()时指定ensure_ascii参数为False >>> a = {\"data\": u\"测试\".encode(\"gbk\")} >>> print json.dumps(a, encoding=\"gbk\", ensure_ascii=False) {\"data\": \"测试\"} 虽然可以正常显示了，但是这时候引入了一个新的问题 >>> a = {\"data\": u\"测试\".encode(\"gbk\")} >>> b = json.dumps(a, encoding=\"gbk\") >>> c = json.dumps(a, encoding=\"gbk\", ensure_ascii=False) >>> print type(b), b {\"data\": \"\\u6d4b\\u8bd5\"} # 原始json.dumps()的结果类型为str >>> print type(c), c {\"data\": \"测试\"} # 设置ensure_ascii后json.dumps()的结果类型为unicode 要知道，当结果中存在中文字符的时候，是需要格外注意字符串类型是unicode还是str的，否则会在程序处理过程中出现问题。比如我们的接口中需要处理一个含有gbk编码元素的字典，然后返回utf-8编码的json结果 >>> a = {\"data\": u\"测试\".encode(\"gbk\")} >>> b = json.dumps(a, encoding=\"gbk\", ensure_ascii=False) >>> b.decode(\"gbk\").encode(\"utf-8\") # 进行gbk解码，并进行utf-8编码返回 Traceback (most recent call last): File \"\", line 1, in UnicodeEncodeError: 'ascii' codec can't encode characters in position 10-11: ordinal not in range(128) # 由于设置ensure_ascii=False时，json.dumps()返回的结果从str变成了unicode；因此当我们对一个unicode的结果进行decode解码时，就会报错 可能有人会说，那我碰到ensure_ascii=False的情况时，既然都知道返回的和原来不一样，是个unicode了；那我直接对它做encode，不按照原来处理str的方法(先decode成unicode，再encode成目标编码的str)，不就行了吗？但是事实上并没有那么简单。当我们的原始编码是utf-8，目标编码是gbk时，情况又不一样了 >>> a = {\"data\": u\"测试\".encode(\"utf-8\")} >>> b = json.dumps(a, encoding=\"utf-8\", ensure_ascii=False) >>> b.encode(\"gbk\") Traceback (most recent call last): File \"\", line 1, in UnicodeDecodeError: 'ascii' codec can't decode byte 0xe6 in position 10: ordinal not in range(128) 当ensure_ascii=False的时候，json.dumps()返回的结果不是unicode吗？对一个unicdoe的字符串，我们应该是可以encode成任意str的，怎么上面又报错了呢？我们来看一下现在json.dumps()的结果类型 >>> type(b) 说好的unicode，在utf-8编码下又变回了str。我们来看下这个ensure_ascii的官方注解 可以看到，json.dumps()当设定ensure_ascii=False，且使用了encoding参数时，才会返回unicode。encoding=utf-8时之所以返回的是str，是因为json.dumps()方法默认的encoding=utf-8，相当于encoding parameter is not used，因此仍然保持原str返回。 总结 当使用json.dumps()处理含有中文字符的字典时，需要格外注意编码问题 如果源输入是utf-8编码，直接使用json.dumps(a, ensure_ascii=False)即可，默认encoding=utf-8，返回的就是一个utf-8编码的str 如果源输入是其他编码，如gbk，则使用json.dumps(a, ensure_ascii=False, encoding=\"gbk\")，返回的是一个unicode，可以根据需要encode成目标编码的str进行传输 参考链接: python unicode 之痛 "},"golang/performance.html":{"url":"golang/performance.html","title":"I. Go的性能指标","keywords":"","body":"Go的性能指标 指标 latency cost 影响Go性能指标的几个因素 algorithm gc mechanical sympathy "},"golang/heap_stack.html":{"url":"golang/heap_stack.html","title":"II. Go的堆栈分配","keywords":"","body":"Go的堆栈分配 Golang的程序栈 每个goroutine维护着一个栈空间，默认最大为4KB 当goroutine的栈空间不足时，golang会调用runtime.morestack(汇编实现：asm_xxx.s)来进行动态扩容 连续栈：当栈空间不足的时候申请一个2倍于当前大小的新栈，并把所有数据拷贝到新栈， 接下来的所有调用执行都发生在新栈上。 每个function维护着各自的栈帧(stack frame)，当function退出时会释放栈帧 function内部的栈操作 用一段简单的代码来说明Go函数调用及传参时的栈操作： package main func g(p int) int { return p+1; } func main() { c := g(4) + 1 _ = c } 执行go tool compile -S main.go生成汇编，并截取其中的一部分来说明一下程序调用时的栈操作 \"\".g t=1 size=17 args=0x10 locals=0x0 // 初始化函数的栈地址 // 0-16表示函数初始地址为0，数据大小为16字节(input: 8字节，output: 8字节) // SB是函数寄存器 0x0000 00000 (test_stack.go:3) TEXT \"\".g(SB), $0-16 // 函数的gc收集提示。提示0和1是用于局部函数调用参数，需要进行回收 0x0000 00000 (test_stack.go:3) FUNCDATA $0, gclocals·aef1f7ba6e2630c93a51843d99f5a28a(SB) 0x0000 00000 (test_stack.go:3) FUNCDATA $1, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) // FP(frame point)指向栈底 // 将FP+8位置的数据(参数p)放入寄存器AX 0x0000 00000 (test_stack.go:4) MOVQ \"\".p+8(FP), AX 0x0005 00005 (test_stack.go:4) MOVQ (AX), AX // 寄存器值自增 0x0008 00008 (test_stack.go:4) INCQ AX // 从寄存器中取出值，放入FP+16位置(返回值) 0x000b 00011 (test_stack.go:4) MOVQ AX, \"\".~r1+16(FP) // 返回，返回后程序栈的空间会被回收 0x0010 00016 (test_stack.go:4) RET 0x0000 48 8b 44 24 08 48 8b 00 48 ff c0 48 89 44 24 10 H.D$.H..H..H.D$. 0x0010 c3 . \"\".main t=1 size=32 args=0x0 locals=0x10 0x0000 00000 (test_stack.go:7) TEXT \"\".main(SB), $16-0 0x0000 00000 (test_stack.go:7) SUBQ $16, SP 0x0004 00004 (test_stack.go:7) MOVQ BP, 8(SP) 0x0009 00009 (test_stack.go:7) LEAQ 8(SP), BP 0x000e 00014 (test_stack.go:7) FUNCDATA $0, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 0x000e 00014 (test_stack.go:7) FUNCDATA $1, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) // SP(stack point)指向栈顶 // 把4存入SP的位置 0x000e 00014 (test_stack.go:8) MOVQ $4, \"\".c(SP) // 这里会看到没有第9行`call g()`的调用出现，这是因为go汇编编译器会把一些短函数变成内嵌函数，减少函数调用 0x0016 00022 (test_stack.go:10) MOVQ 8(SP), BP 0x001b 00027 (test_stack.go:10) ADDQ $16, SP 0x001f 00031 (test_stack.go:10) RET 事实上，即便我定义了指针调用，以上的数据也都是在栈上拷贝的；那么Golang中的数据什么时候会被分配到堆上呢？ Golang逃逸分析 在编译程序优化理论中，逃逸分析是一种确定指针动态范围的方法，用于分析在程序的哪些地方可以访问到指针。 Golang在编译时的逃逸分析可以减少gc的压力，不逃逸的对象分配在栈上，当函数返回时就回收了资源，不需要gc标记清除。 如果你定义的对象的方法上有同步锁，但在运行时，却只有一个线程在访问，此时逃逸分析后的机器码，会去掉同步锁运行，提高效率。 举个栗子 还是1.1里的那段程序代码，我们可以执行go build -gcflags '-m -l' test_stack.go来进行逃逸分析，输出结果如下 # command-line-arguments ./test_stack.go:3: g p does not escape ./test_stack.go:9: main &c does not escape 可以看到，对象c是没有逃逸的，还是分配在栈上。 即便在一开始定义的时候直接把c定义为指针： package main func g(p *int) int { return *p + 1 } func main() { c := new(int) (*c) = 4 _ = g(c) } 逃逸分析的结果仍然不会改变 # command-line-arguments ./test_stack.go:3: g p does not escape ./test_stack.go:8: main new(int) does not escape 那么，什么时候指针对象才会逃逸呢？ 按值传递和按址传递 按值传递 package main func g(p int) int { ret := p + 1 return ret } func main() { c := 4 _ = g(c) } 返回值ret是按值传递的，执行的是栈拷贝，不存在逃逸 按址传递 package main func g(p *int) *int { ret := *p + 1 return &ret } func main() { c := new(int) *c = 4 _ = g(c) } 返回值&ret是按址传递，传递的是指针对象，发生了逃逸，将对象存放在堆上以便外部调用 # command-line-arguments ./test_stack.go:5:9: &ret escapes to heap ./test_stack.go:4:14: moved to heap: ret ./test_stack.go:3:17: g p does not escape ./test_stack.go:9:10: main new(int) does not escape golang只有在function内的对象可能被外部访问时，才会把该对象分配在堆上 在g()方法中，ret对象的引用被返回到了方法外，因此会发生逃逸；而p对象只在g()内被引用，不会发生逃逸 在main()方法中，c对象虽然被g()方法引用了，但是由于引用的对象c没有在g()方法中发生逃逸，因此对象c的生命周期还是在main()中的，不会发生逃逸 再看一个栗子 package main type Ret struct { Data *int } func g(p *int) *Ret { var ret Ret ret.Data = p return &ret } func main() { c := new(int) *c = 4 _ = g(c) } 逃逸分析结果 # command-line-arguments ./test_stack.go:10:9: &ret escapes to heap ./test_stack.go:8:6: moved to heap: ret ./test_stack.go:7:17: leaking param: p to result ~r1 level=-1 ./test_stack.go:14:10: new(int) escapes to heap 可以看到，ret和2.2中一样，存在外部引用，发生了逃逸 由于ret.Data是一个指针对象，p赋值给ret.Data后，也伴随p发生了逃逸 main()中的对象c，由于作为参数p传入g()后发生了逃逸，因此c也发生了逃逸 当然，如果定义ret.Data为int(instead of *int)的话，对象p也是不会逃逸的(执行了拷贝) 对开发者的一些建议 大对象按址传递，小对象按值传递 按址传递更高效，按值传递更安全(from William Kennedy) 90%的bug都来自于指针调用 初始化一个结构体，使用引用的方式来传递指针 func r() *Ret{ var ret Ret ret.Data = ... ... return &ret } 只有返回ret对象的引用时才会把对象分配在堆上，我们不必要在一开始的时候就显式地把ret定义为指针 ret = &Ret{} ... return ret 对阅读代码也容易产生误导 参考链接： Golang汇编快速指南 Golang汇编 Golang汇编命令解读 Go语言逃逸分析 go语言连续栈 为何说Goroutine的栈空间可以无限大 Goroutine stack "},"golang/gc.html":{"url":"golang/gc.html","title":"III. Go的垃圾回收","keywords":"","body":"Go的垃圾回收 GC算法 go1.5以前使用标记清除法(Mark-Sweep)： 从程序根节点开始递归遍历所有对象，将能遍历到的对象打上标记 将所有未标记的的对象当作垃圾销毁 不用担心循环引用问题，但是需要一段时间来暂停程序以便标记 go1.5后采用的是三色标记算法(white-grey-black)： 打开write barrier(写屏障) write barrier是编译器在每个内存写操作前生成的一个小的代码段，用于在golang gc时监控指针的引用操作，防止误回收。 将所有escape to heap的对象放入白色集合中 遍历程序栈(非递归)，将遍历到白色集合中的对象放入灰色集合中 遍历灰色集合中的对象，将遍历到的灰色对象放到黑色集合中，并将此灰色对象引用到的白色对象放入灰色集合中 重复4，直到灰色集合中没有对象。在此过程中，若write barrier检测到有黑色对象引用了白色对象，会将此白色对象放入灰色集合中 回收掉白色集合中的对象 STW(Stop the World) golang在进行GC的时候是需要一小段时间来暂停程序的运行的。golang每升级一个大版本，都会对GC做一定的优化，以提升GC效率、缩短STW的时间： go1.4前使用标记清除法，在每次GC标记内存对象时都需要一段STW时间(毫秒到秒级) go1.4并行处理标记和清理协程，但是仍然需要在标记时STW go1.5-1.7使用三色标记算法，只在write barrier和rescan grey stacks时STW(毫秒级) go1.8使用hybrid write barrier，去除了rescan grey stacks的STW，STW时间在10-100微秒 go1.9后提升了对大对象的收集效率，STW时间基本稳定在100微秒内 减轻GC压力 golang gc的时间长短，主要和待GC的对象数量有关，待GC的对象越少，GC的时间越短。 sync.Pool 临时对象池，用于复用已产生的对象，减少程序内对象的数量，减轻GC压力。sync.Pool是并发安全的。 参考链接： gotraining/pointers/gc golang垃圾回收机制 Golang 垃圾回收剖析 知乎: write barrier 为Go语言GC正名－2秒到1毫秒的演变史 go 1.8 eliminate stw stack re-scanning sync.Pool "},"golang/goroutine.html":{"url":"golang/goroutine.html","title":"IV. Go的协程","keywords":"","body":"Go的协程 Go协程和线程的区别 资源调度 线程由内核调度，根据cpu时间片执行抢占式调度 协程由程序调度(runtime包)，执行协同式调度(2中会详述) 内存占用 执行线程所需的栈内存至少是MB级别 执行协程只需要4KB左右的栈内存 上下文切换 线程涉及到用户态和内核态的切换：需要切换通用寄存器(8个)，程序计数器PC，指令寄存器IR，地址寄存器AR，累加寄存器AC，状态寄存器EFLAGS等 协程上下文切换只涉及到栈指针和三个寄存器(程序计数器PC, 栈指针寄存器SP, 数据寄存器DX）的切换 Go协程调度 M：内核线程 G：goroutine，并发的最小逻辑单元，由程序创建 P：处理器，执行G的上下文环境，每个P会维护一个本地的goroutine队列 goroutine有三个状态： waiting: 协程处于全局的队列等待调度 runnable: 协程处于本地队列，等待执行 running: 协程正在运行 G的创建 go调用runtime.newproc()方法来创建G 首先，检查当前P的空闲队列中有没有可用的G，如果有，就直接从中取一个；如果没有，则分配一个新的G，挂载到P的本地队列中 获取了G之后，将调用参数保存到G的栈中，将SP, PC等上下文环境保存到G的sched域中 此时的G处于runnable状态，一旦分配到CPU，就可以进入running状态 G何时被调度 当G被创建时，会立即获得一次运行的机会 如果此时正在运行的P的数量没有达到上限，go会调用runtime.wakep()方法唤醒P；然后调度器选择M绑定P来执行G，必要时会新建M 当此时正在运行的P数量到达上限时，G会进入本地队列等待，当队列前面的G处于以下几种状态时，会触发切换，进入waiting状态： 加锁 io操作 系统调用 运行时间过长(runnable) G的消亡 当G执行完毕返回后，go会调用runtime.exit()方法回收G(包括回收栈指针, 清空寄存器SP、 PC...) 然后将G放入P的空闲队列中，等待runtime.newproc()方法取出 Go channel channel是go协程通信的主要方式。channel不是队列，可以把它理解为一种信号模型(from William Kennedy) channel分为以下两种类型： 一种是无缓冲的channel，在创建channel时不指定长度。无缓冲的channel若没有用户读取，在写入时会始终阻塞，通常可以作为保证信号使用 另一种是缓冲的channel，即buffer channel，在创建channel时指定长度(>=1)。buffer channel为空时会阻塞读，buffer channel满时会阻塞写，可以作为数据传输使用 当buffer channel的长度指定为1时，可以作为延迟保证信号使用(信号发送方发送信号后不阻塞等待接收方接收) channel有以下三种状态： nil：初始化channel。无法读写 open：通过make分配channel空间。可读可写 close: 通过close()关闭channel。close的channel != nil；可以继续从中读取数据，但是不能写入(panic) 基于channel实现的异步日志模型 package main import ( \"fmt\" \"io\" \"os\" \"strconv\" \"sync\" ) var globalWg sync.WaitGroup // Logger struct implement log type Logger struct { channel chan string wg sync.WaitGroup } // NewLog return a new Logger func NewLog(w io.Writer, cap int) *Logger { l := Logger{ channel: make(chan string, cap), } l.wg.Add(1) go func() { defer l.wg.Done() for v := range l.channel { fmt.Fprintln(w, v) } fmt.Println(\"close\") }() return &l } // Close close logger func (l *Logger) Close() { close(l.channel) l.wg.Wait() } // Println print msg func (l *Logger) Println(v string) { select { case l.channel 执行结果： output: 11 0 5 1 2 3 4 8 6 7 9 10 close 可以看到，超过并发数的时候执行了default行为输出了output: 11 当然，我们也可以自定义default行为，比如超过并发数的时候停等一小段时间再写入；或者是不设置default行为，超过并发时阻塞写入直到解除阻塞为止。 这个模型还可以结合协程池grpool，来做一个后台并发写入的日志系统 效率和安全始终是一对矛盾，异步日志虽然能很大程度提高程序效率(不需要等待io操作)；但是如果程序crash，在channel中尚未写入的数据就会丢失。因此在使用的时候也要注意channel的长度设置，如果需要guarantee的，甚至要设置成unbuffer(基本等于同步日志)或者buffer = 1。 Suggestion 单核过多线程未必会提高效率，更多的抢占式调度和上下文切换，有时反而会让效率降低；经验之谈：3 thread per core is best(from William Kennedy) 对于cpu-bound work，高并发未必会提高效率(cpu密集型工作的切换还是需要cpu来调度) 对于io-bound work，应该最大限度地利用并发来提高效率 参考链接： golang之协程 goroutine的生老病死 谈goroutine调度器 Golang协程详解 通用寄存器 gotraining/concurrency/channels "},"golang/stack_trace.html":{"url":"golang/stack_trace.html","title":"V. Go的调试信息","keywords":"","body":"Go的调试信息 当golang程序出现panic的时候会输出一段堆栈调试信息，开发人员可以通过这些调试信息快速地定位问题。 举个栗子 我们通过下面这段程序，直接让程序panic package main func main() { slice := make([]string, 2, 4) Example(slice, \"hello\", 10) } func Example(slice []string, str string, i int) { panic(\"stack trace\") } 运行后输出的调试信息如下 panic: stack trace goroutine 1 [running]: main.Example(0xc42003ff30, 0x2, 0x4, 0x106b75a, 0x5, 0xa) /Users/maniafish/Myworkspace/go_project/src/test/test_panic.go:9 +0x39 main.main() /Users/maniafish/Myworkspace/go_project/src/test/test_panic.go:5 +0x76 exit status 2 第一行是panic信息: stack trace 第二行是发生panic的goroutine及其运行状态(running) 接下来就是发生panic的function调用情况了。我们通常会关注显示的文件和行号，可以快速定位到是哪一行代码抛出的异常 除此之外我们还可以从中看到发生panic的function的输入参数，如main.Example(0xc42003ff30, 0x2, 0x4, 0x106b75a, 0x5, 0xa)对应func Example(slice []string, str string, i int)的三个输入参数： slice: 0xc42003ff30(slice指针地址), 0x2(slice的长度), 0x4(slice的容量) str: 0x106b75a(str字符串头指针地址), 0x5(str字符串长度) i: 0xa(i = 10) 空指针错误 package main import \"fmt\" type S struct { Msg string } func (s *S) f(a int) { fmt.Printf(\"%v: %d\\n\", s.Msg, a) } func main() { Example(nil) } func Example(s *S) { s.f(1) } 以上这段程序运行结果如下： panic: runtime error: invalid memory address or nil pointer dereference [signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x1095257] goroutine 1 [running]: main.(*S).f(0x0, 0x1) /Users/maniafish/Myworkspace/go_project/src/test/test_panic.go:10 +0x57 main.Example(0x0) /Users/maniafish/Myworkspace/go_project/src/test/test_panic.go:18 +0x34 main.main() /Users/maniafish/Myworkspace/go_project/src/test/test_panic.go:14 +0x2a exit status 2 panic信息(invalid memory address or nil pointer dereference)告诉我们是无效的地址调用 我们通过main.(*S).f(0x0, 0x1)的第一个参数，可以知道这个指针*S的方法f()调用时使用的是空指针 然后通过main.Example(0x0)，知道这个空指针是通过Example()方法传进来的，定位到了问题所在。 参考链接： Go stack trace "},"golang/composition.html":{"url":"golang/composition.html","title":"VI. Go的interface","keywords":"","body":"Go的interface go的interface类型定义了一组方法，如果某个对象实现了某个interface的所有方法，此对象就实现了此interface。 interface focus on what the data does, instead of what the data is(From William Kennedy) interface能够帮助我们更好地做泛型编程，实现代码逻辑的抽象和灵活组合，更方便地进行面向对象的编程。 下面通过一个例子来说明一下go中基于interface的编程设计思路。 场景1 设计思路 定义结构体A，实现方法Store() 定义结构体B，实现方法Pull() 定义System封装A和B，并通过System向外提供api 代码示例 // A is a system for data collection type A struct { ... } // Store function for storing data func (a *A) Store(data interface{}) { ... } // B is a system for data pulling type B struct { ... } // Pull function for pulling data func (b *B) Pull(data interface{}) { ... } // System wraps A and B together type System struct { A B } // Api providing api for users func Api(s *System, data []interface{}) error { ... for _, v := range data { s.Store(v) } ... dp := ... err = s.Pull(dp) ... return } func main() { a := A { ... } b := B { ... } s := System{a, b} data := ... err := Api(&s, data) if err != nil { ... } ... } 场景2 设计思路 系统组件A1~A3都实现了同样的方法Store()，B1~B3实现了Pull()，考虑使用interface进行抽象解耦 system无需关心具体的A和B，只需要做interface的组合即可 代码示例 // Storer is an interface for data collection type Storer interface { Store(data interface{}) } // A1 is a system for data collection type A1 struct { ... } // Store function for storing data func (a *A1) Store(data interface{}) { ... } // define A2 ~ A3 implementing Storer ... // Puller is an interface for data pulling type Puller interface { Pull(data interface{}) } // B1 is a system for data pulling type B1 struct { ... } // Pull function for pulling data func (b *B1) Pull(data interface{}) { ... } // define B2 ~ B3 implementing Puller ... // System wraps Storer and Puller together type System struct { Storer Puller } // Api providing api for users func Api(s *System, data []interface{}) error { ... for _, v := range data { s.Store(v) } ... dp := ... err = s.Pull(dp) ... return } func main() { ... a := A1 { ... } b := B1 { ... } // s can be any composition of An and Bn s := System{&a, &b} data := ... err := Api(&s, data) if err != nil { ... } ... } 进一步抽象 我们希望Api()方法变得更加通用，它无需关心System的具体结构，只关心System提供的Pull()和Store()方法 因此我们可以定义一个PullStorer来做Puller和Storer的interface组合，这样一来只要是实现了Puller和Storer的结构体，都可以由Api()方法调用来对外提供服务 ... // PullStorer is an interface implementing Storer and Puller type PullStorer interface { Storer Puller } // Api providing api for users func Api(s PullStorer, data []interface{}) error { ... for _, v := range data { s.Store(v) } ... dp := ... err = s.Pull(dp) ... return } func main() { ... // s can be any composition of An and Bn s := System{ ... } data := ... err := Api(&s, data) if err != nil { ... } ... } interface滥用问题 我们现在定义了以下interface // Storer is an interface for data collection type Storer interface { Store(data interface{}) } // Puller is an interface for data pulling type Puller interface { Pull(data interface{}) } // PullStorer is an interface implementing Storer and Puller type PullStorer interface { Storer Puller } 我们的Api()里关注的是Store()和Pull()方法 // Api providing api for users func Api(s PullStorer, data []interface{}) error { ... for _, v := range data { s.Store(v) } ... dp := ... err = s.Pull(dp) ... return } 这个传入Api()的s，可以是任意实现了Store()方法的An和任意实现了Pull()方法的Bn的组合 我们在Api()中调用s.Store()，实际上调用的是s.Storer.Store()；调用s.Pull()，实际上调用的是s.Puller.Pull() 既然我们的Api()关注的只是Puller和Storer，那么我们为什么要额外让他们组合成一个PullStorer来传入呢 基于以上设计思路，我们可以去掉System和PullStorer，得到以下简洁且可扩展性强的代码 // Storer is an interface for data collection type Storer interface { Store(data interface{}) } // A1 is a system for data collection type A1 struct { ... } // Store function for storing data func (a *A1) Store(data interface{}) { ... } // define A2 ~ A3 implementing Storer ... // Puller is an interface for data pulling type Puller interface { Pull(data interface{}) } // B1 is a system for data pulling type B1 struct { ... } // Pull function for pulling data func (b *B1) Pull(data interface{}) { ... } // define B2 ~ B3 implementing Puller ... // Api providing api for users func Api(s Storer, p Puller, data []interface{}) error { ... for _, v := range data { s.Store(v) } ... dp := ... err = p.Pull(dp) ... return } func main() { ... a := A1 { ... } b := B1 { ... } // a can be any An, b can be any Bn data := ... err := Api(&a, &b, data) if err != nil { ... } ... } "},"golang/operator.html":{"url":"golang/operator.html","title":"VII. Go的变量作用域","keywords":"","body":"Go的变量作用域 变量作用域 全局变量 package a var g int // 本包内可见 var G int // 外部import a后可见 局部变量 func Test() { var a int // a在Test()内可见 ... for i := 1; i 参数变量 func Test(a int) { // a在Test()方法内可见，在Test()外赋值。 ... } 局部变量声明后未使用会编译失败；参数变量在function内可以不使用，比如以下情况也是可以编译通过的。 func main() { a := 1 Test(a) // a作为参数调用 } func Test(a) { // a在Test()内部没有使用 fmt.Println(\"test\") } 对按值传参的情况，方法内对参数a的修改不影响传入前的原参数a 对按址传参的情况，方法内对参数a的修改也会影响到传入前的原参数a 循环并发中的变量传参问题 理解了go中的变量作用域后，我们来看看下面这段代码 package main import ( \"fmt\" \"sync\" ) var wg sync.WaitGroup func main() { for i := 0; i 输出结果如下 10 10 10 10 10 10 10 10 10 10 这是因为变量i作为局部变量，同时在for循环和go协程中被引用，循环递增和打印的是同一个地址的数据 实际上这个输出是无法预期的，这里都输出10是因为后台协程完成创建时，for循环已经完成了对i的递增操作 如果要想让循环中的go协程如我们预期的一样输出1~10的值，要采取以下写法，使用参数变量 package main import ( \"fmt\" \"sync\" ) var wg sync.WaitGroup func main() { for i := 0; i Go的:=操作符 Go的:=操作符用于声明变量的同时给变量赋值，它也会定义新变量的作用域。以下面这段代码为例 package main import ( \"fmt\" \"sync\" ) var wg sync.WaitGroup func main() { a := 1 fmt.Printf(\"a in main: %p, %d\\n\", &a, a) // a in main: 0xc420016090, 1 // 在main中声明了变量a，地址为0xc420016090，并给a赋值为1 for a := 2; a "},"golang/slice.html":{"url":"golang/slice.html","title":"VIII. Go的slice","keywords":"","body":"Go的slice go的slice可以理解为一种动态可变长的数组，初始化时可以指定长度len和容量cap；可以通过append()方法在slice末尾追加元素。 一个append的栗子 package main import \"fmt\" func main() { s0 := []int{1, 2, 3, 4} fmt.Printf(\"s0: %v, len(s): %d, cap(s): %d\\n\\n\", s0, len(s0), cap(s0)) // s0: [1 2 3 4], len(s): 4, cap(s): 4 // 初始化一个slice s0，len = cap = 4(不指定cap的情况下，默认cap = len) s1 := s0[:2] fmt.Printf(\"s1: %v, len(s1): %d, cap(s1): %d\\n\\n\", s1, len(s1), cap(s1)) // s1: [1 2], len(s1): 2, cap(s1): 4 // 取s0的前个元素构成s1，len = 2, cap = 4 s2 := append(s1, 5, 6, 7) fmt.Printf(\"s2: %v, len(s2): %d, cap(s2): %d\\n\", s2, len(s2), cap(s2)) fmt.Printf(\"s0: %v, len(s0): %d, cap(s0): %d\\n\\n\", s0, len(s0), cap(s0)) // s2: [1 2 5 6 7], len(s2): 5, cap(s2): 8 // append 5, 6, 7到s1，此时空间不足，按照两倍cap动态扩容，分配一块新的内存空间给s2 // s0: [1 2 3 4], len(s0): 4, cap(s0): 4 // s0不变 s3 := append(s1, 8, 9) fmt.Printf(\"s3: %v, len(s3): %d, cap(s3): %d\\n\", s3, len(s3), cap(s3)) fmt.Printf(\"s0: %v, len(s0): %d, cap(s0): %d\\n\\n\", s0, len(s0), cap(s0)) // s3: [1 2 8 9], len(s3): 4, cap(s3): 4 // append 8, 9到s1，空间足够，无须扩容 // s0: [1 2 8 9], len(s0): 4, cap(s0): 4 // s0的后两个元素被append的8, 9取代 } 通过以上栗子可以看出： go的slice只有在空间不足时，才会进行动态扩容，分配新的内存地址。所以在日常开发的时候，要尽量避免以下操作： func A(i []int){ ... b := append(i, ...) ... } func main(){ ... a := []int{...} A(a[:2]) ... } 要防止slice b的操作影响到slice a，可以使用copy()方法 func A(i []int){ ... b := append(i, ...) ... } func main(){ ... a := []int{...} i := make([]int, 2) copy(i, a[:2]) A(i) ... } go的slice执行的动态扩容是一个内存拷贝的操作，分配一块新的2倍cap的空间给slice。因此在平时开发的时候，应该尽可能地分配确定的len和cap给slice，防止频繁append进行内存拷贝带来的性能损耗。 比如以下这段代码 func main() { a := make([]int, 0) for i := 0; i 可以改写成下面这样，使用确定的len func main() { a := make([]int, 10) for i := 0; i 即便在不确定len的情况下，也应该尽量预留一个相对充足的cap，来减少2倍cap扩容的次数 func main() { a := make([]int, 0, 10) for i := 0; i 默认按地址传递 通过1.1中的栗子 func A(i []int){ ... b := append(i, ...) // 操作b的时候也会影响到a ... } func main(){ ... a := []int{...} A(a[:2]) ... } 就可以知道，go中slice传参默认是按址传递的，因此在function内对传入的slice进行写操作的时候要注意：这种操作是会影响到function调用方的原slice的。go的map也是默认按址传递 "},"golang/defer.html":{"url":"golang/defer.html","title":"IX. Go的defer处理","keywords":"","body":"Go的defer处理 package main import \"fmt\" func deferFunc() (b int) { b = 1 a := true defer func() { b = 2 }() return } func main() { fmt.Println(deferFunc()) // 这里打印出来的是1，而不是2 // https://stackoverflow.com/questions/37248898/how-does-defer-and-named-return-value-work-in-golang } TODO: go的defer底层机制 "},"golang/rand.html":{"url":"golang/rand.html","title":"X. Go随机数生成的并发安全问题","keywords":"","body":"Go随机数生成的并发安全问题 问题分析 golang中的随机数生成是由官方包math/rand来处理的，使用方法很简单： package main import ( \"fmt\" \"math/rand\" \"time\" ) func main() { // 使用当前的纳秒时间作为随机因子，生成一个rand对象 r := rand.New(rand.NewSource(time.Now().UnixNano())) // 生成100以内的随机数 fmt.Println(r.Intn(100)) } 在实际的使用场景中，我们经常会碰到需要重复生成随机数的情况。最常见的就是，在调用某个方法A时，在A的逻辑中需要用到一个范围内的随机数，我们就在A方法中采用r.Intn(n)生成这样一个随机数；由于每次调用A时，都要使用rand对象r来生成一个随机数，因此我们通常会对这个rand对象做提前定义，以免每次生成随机数都要重复创建对象造成不必要的开销。 package main import ( \"math/rand\" \"time\" ) var Rand = rand.New(rand.NewSource(time.Now().UnixNano())) func A() { ... p := Rand.Intn(n) ... } func main() { ... A() ... } 这种做法在平时单协程内做随机数生成时没有任何问题，但是一旦碰到高并发的情况，问题就来了。我们来看下面这段服务器代码。 package main import ( \"log\" \"math/rand\" \"net/http\" \"time\" ) // base64使用的字符集 const letterBytes = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789/+=\" var letterRand = rand.New(rand.NewSource(time.Now().UnixNano())) func main() { handler := func(w http.ResponseWriter, req *http.Request) { body := make([]byte, 1024) for i := range body { body[i] = letterBytes[letterRand.Intn(len(letterBytes))] } w.Write(body) } http.HandleFunc(\"/random_bytes\", handler) log.Fatal(http.ListenAndServe(\":8080\", nil)) } 这段代码的功能是返回长度为1k的随机base64字符串，接下来，我们通过ab压测工具来并发访问一下这个接口 $ ab -n 10000 -c 100 '127.0.0.1:8080/random_bytes' This is ApacheBench, Version 2.3 Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking 127.0.0.1 (be patient) Completed 1000 requests Completed 2000 requests Completed 3000 requests Completed 4000 requests Completed 5000 requests Completed 6000 requests Completed 7000 requests Completed 8000 requests Completed 9000 requests Completed 10000 requests Finished 10000 requests Server Software: Server Hostname: 127.0.0.1 Server Port: 8080 Document Path: /random_bytes Document Length: 1024 bytes Concurrency Level: 100 Time taken for tests: 1.240 seconds Complete requests: 10000 Failed requests: 94 (Connect: 0, Receive: 0, Length: 94, Exceptions: 0) Total transferred: 11322542 bytes HTML transferred: 10143744 bytes Requests per second: 8063.88 [#/sec] (mean) Time per request: 12.401 [ms] (mean) Time per request: 0.124 [ms] (mean, across all concurrent requests) Transfer rate: 8916.37 [Kbytes/sec] received Connection Times (ms) min mean[+/-sd] median max Connect: 0 5 2.3 5 15 Processing: 0 7 3.7 6 36 Waiting: 0 5 3.7 5 36 Total: 1 12 3.6 12 38 Percentage of the requests served within a certain time (ms) 50% 12 66% 13 75% 13 80% 14 90% 16 95% 18 98% 22 99% 27 100% 38 (longest request) 这里我们设定的是100并发，共10000个请求，可以看到，其中有94个请求都失败了。 Failed requests: 94 检查服务端输出，发现抛出了panic http: panic serving 127.0.0.1:57330: runtime error: index out of range goroutine 19898 [running]: net/http.(*conn).serve.func1(0xc42054c320) /go/src/net/http/server.go:1697 +0xd0 panic(0x1250aa0, 0x13f9e20) /go/src/runtime/panic.go:491 +0x283 math/rand.(*rngSource).Uint64(...) /go/src/math/rand/rng.go:246 math/rand.(*rngSource).Int63(0xc420097500, 0xf67aee49c000000) /go/src/math/rand/rng.go:231 +0x8a math/rand.(*Rand).Int63(0xc42007cbd0, 0xf67aee49c000000) /go/src/math/rand/rand.go:82 +0x33 math/rand.(*Rand).Int31(0xc42007cbd0, 0xf67aee4) /go/src/math/rand/rand.go:96 +0x2b math/rand.(*Rand).Int31n(0xc42007cbd0, 0xc400000041, 0xc400000019) /go/src/math/rand/rand.go:131 +0x4f math/rand.(*Rand).Intn(0xc42007cbd0, 0x41, 0x19) /go/src/math/rand/rand.go:145 +0x45 main.main.func1(0x13d0da0, 0xc420561260, 0xc4203d8d00) /go_project/src/test/test_server/main.go:19 +0xaf net/http.HandlerFunc.ServeHTTP(0x12af8a0, 0x13d0da0, 0xc420561260, 0xc4203d8d00) /go/src/net/http/server.go:1918 +0x44 net/http.(*ServeMux).ServeHTTP(0x1403920, 0x13d0da0, 0xc420561260, 0xc4203d8d00) /go/src/net/http/server.go:2254 +0x130 net/http.serverHandler.ServeHTTP(0xc420082dd0, 0x13d0da0, 0xc420561260, 0xc4203d8d00) /go/src/net/http/server.go:2619 +0xb4 net/http.(*conn).serve(0xc42054c320, 0x13d1220, 0xc42027c800) /go/src/net/http/server.go:1801 +0x71d created by net/http.(*Server).Serve /go/src/net/http/server.go:2720 +0x288 根据报错信息，我们可以定位到panic位置在官方包math/rand/rng.go: func (rng *rngSource) Uint64() uint64方法的以下行： 实际上rand包在生成随机数时，底层都是通过上面这个方法，从vec数组中取出int64元素来进行计算，返回一个伪随机数的。这个方法中对数组的两个索引值tap和feed，都存在着一个递减到0以下时增加_LEN值的非原子操作。 也就是说，在并发环境下，如果其中一个协程A对tap(或feed)递减到0以下，在重设tap(或feed)前，协程B同时在进行以下操作 x := rng.vec[rng.feed] + rng.vec[rng.tap] rng.vec[rng.feed] = x 就会因为取数组的索引为负数(如vec[-1])，导致panic。 全局rand对象 我们在生成rand对象时使用的NewSource()方法，在官方包里有明确注释说明，使用该方法返回的对象是非协程安全的 事实上，官方的rand包里提供了一个全局的rand对象var globalRand = New(&lockedSource{src: NewSource(1).(Source64)})，这个对象使用的是lockedSource，通过加锁来保证随机数生成时的协程安全。在使用时，直接通过rand.Intn(n)调用官方包方法，默认就会使用这个globalRand对象来生成随机数。 我们将之前服务端生成随机字符串的那行代码改为 body[i] = letterBytes[rand.Intn(len(letterBytes))] 使用官方包的全局rand对象来生成随机数，然后通过ab压测看一下效果 $ ab -n 10000 -c 100 '127.0.0.1:8080/random_bytes' This is ApacheBench, Version 2.3 Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking 127.0.0.1 (be patient) apr_socket_recv: Connection refused (61) maniafish:tech_talk/ (master✗) $ ab -n 10000 -c 100 '127.0.0.1:8080/random_bytes' This is ApacheBench, Version 2.3 Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking 127.0.0.1 (be patient) Completed 1000 requests Completed 2000 requests Completed 3000 requests Completed 4000 requests Completed 5000 requests Completed 6000 requests Completed 7000 requests Completed 8000 requests Completed 9000 requests Completed 10000 requests Finished 10000 requests Server Software: Server Hostname: 127.0.0.1 Server Port: 8080 Document Path: /random_bytes Document Length: 1024 bytes Concurrency Level: 100 Time taken for tests: 7.892 seconds Complete requests: 10000 Failed requests: 0 Total transferred: 11429968 bytes HTML transferred: 10240000 bytes Requests per second: 1267.06 [#/sec] (mean) Time per request: 78.923 [ms] (mean) Time per request: 0.789 [ms] (mean, across all concurrent requests) Transfer rate: 1414.30 [Kbytes/sec] received Connection Times (ms) min mean[+/-sd] median max Connect: 0 50 297.4 16 2958 Processing: 0 28 55.7 22 923 Waiting: 0 22 54.0 18 914 Total: 1 78 302.0 38 2991 Percentage of the requests served within a certain time (ms) 50% 38 66% 43 75% 46 80% 48 90% 57 95% 78 98% 888 99% 2927 100% 2991 (longest request) 可以看到，现在没有失败的请求了 Complete requests: 10000 Failed requests: 0 但是使用全局rand对象有一个问题，由于全局对象使用的随机因子固定是1，因此每次重启服务器后，顺序生成的随机数都会是一样的。 以上面那段服务端代码为例，每次重启程序后，访问返回的随机字符串都是： $ curl '127.0.0.1:8080/random_bytes' KVLoZ6Oavp=40jWjUThPTPHn/h/x3fqn5PyFwFOPxOessrsjXCLqNjOOCsn8lTT4ZnPrMq+4Q+hymRlJWWcWZ2sRFr6ZbGasr6usOZEw/aJaJrxRbr=5Qmq24/KoAkWq=lcTTzGtC1NnNGLLvNkA44k9yIkW4fcCGAsjLn56RHFf8zNBmfZof1Oj8s3tmfawtksZ8b8gyBPBUO2rQ/HPd1M4eVw0EZ+aGxY4UcJk5XbTYeNozbgVKfj5WZNYoT=SYmTE7dTRZ3=D3v+couthoigsrYc9c9uLNhSA9JUHWUIrHsdstD8=KclVXHeUCI5VI=4g1MlAr/Pgz/jxm8Ino9mxkv1JTvOq=g4kYNLBs3Wf6Pa62ws/dVsiBUHsF=bJqVG5XMOqwmD46iPTBJIlXyESXmy5RoEOD=ONq4Za2nEwcJcmHQtwzuAyoRShs7zapSiT=hOlM+yte9VgJF5bo6T2A31A4EEhn7=JqK=MbGnRYUtzyTZfvyoAd3vBXIFSFTp+2kZXVU14LgaQ6wnLeEdEQ=V+LcehPjIbtjHLeIJo6p=YFRq6/DwCZJ8TQmZClVckA5WYDfyRO5/XELRqKKudG1PA121ThZlui39HMmpOUCFw=jWKZu0IIsnOnk35Jq2ODTAPZGa2M0i0+3+ibAngLLhQNOcB8f1kDVrkS5MKM4YpzGXCDJJsuY=H4c1vg288l6SxAYTqARMAroM15r+HkkmZF0nVtNlLDWmkQdfB7Cd0Wyw4ACGxklqgX0l12S5xsou58I/s0z9RXr9u0DuXdNaa=LEu1nkiPaLB5sDCNCtUgm0M26bMvCyaa4pHiqKa/HNqm1qTZtCoFsFPqKXFLe5MAPNW=ldNurqh8GtHV14dcD9AEpkptPitNcdgERJVhG2MqfLV6tDjyHrCTOCmk6oEzGKQ24/1Un1HdqRIPW+qyDsfgShBIIDu6nk0wrQKcd/3if66k49TUA2bSDdhf/goqCo4i0hxAJJwTNdh9hIQr21/=8D=yc9YQBfH 另外一个问题是，加锁会带来严重的性能下降。之前使用本地生成的rand对象，压测的rps为 Requests per second: 8063.88 [#/sec] (mean) 使用全局对象后，rps连原来的1/6都达不到 Requests per second: 1267.06 [#/sec] (mean) 开发建议 鉴于官方包的全局rand对象存在 随机因子固定 加锁效率低下 两大缺陷；不建议直接调用rand.Intn(n)，使用全局rand对象 不同协程使用各自独立的rand对象来生成随机数 对golang http server而言，每次收到请求时，底层都会启动新的goroutine来进行处理，因此每次handler处理都需要使用新的rand对象；虽然增加了一点回收开销，但是比起用一个对象同步加锁的开销已经是九牛一毛了 随机数的生成受限于生成rand对象时使用的随机因子，若随机因子相同，则生成的随机数序列就是重复的。建议使用纳秒级时间戳。 "},"go_tool/go_test.html":{"url":"go_tool/go_test.html","title":"I. Go程序基准测试","keywords":"","body":"Go程序基准测试 TODO "},"go_tool/delve.html":{"url":"go_tool/delve.html","title":"II. Go调试工具delve","keywords":"","body":"Go调试工具delve 开发程序过程中调试代码是开发者经常要做的一件事情，当然Go语言可以通过Println之类的打印数据来调试，但是每次都需要重新编译，这是一件相当麻烦的事情。庆幸的是golang内置支持gdb来进行调试，但是对于golang这种多用于并发编程的语言，gdb调试对于goroutine协程来说并不是特别友好。因此，我们需要一个更加适合golang的调试器。这里介绍一个github上star数超高，简单易用的golang调试器 —— delve。 安装 按照github官网上的教程进行安装即可，首先检查xcode-select是否安装 $ xcode-select -v 通过go get安装（鉴于各人代理加速的情况，可能会很慢，请耐心等待） $ go get -u github.com/go-delve/delve/cmd/dlv TODO "},"go_tool/trace.html":{"url":"go_tool/trace.html","title":"III. Go程序运行跟踪器trace","keywords":"","body":"Go程序运行跟踪器trace TODO 参考链接: 7种go程序性能分析的方法 深入浅出 Go trace "},"kubernetes/traefik.html":{"url":"kubernetes/traefik.html","title":"I. Kubernetes使用Traefik反向代理","keywords":"","body":"Kubernetes使用Traefik反向代理 Traefik 官方地址 github地址 反向代理实践(Deployment模式) 准备工作 启动k8s: mac下载桌面版docker，打开Enable Kubernetes即可启动 安装MiniKube 启动MiniKube: minikube start 运行Traefik 下载github代码: git clone https://github.com/containous/traefik 进入traefik/examples/k8s目录 deployment模式部署，创建对外服务：kubectl create -f traefik-deployment.yaml 加载资源: kubectl apply -f traefik-deployment.yaml 去除资源：kubectl delete -f traefik-deployment.yaml kind: Service apiVersion: v1 metadata: name: traefik-ingress-service namespace: kube-system spec: selector: k8s-app: traefik-ingress-lb ports: - protocol: TCP port: 80 nodePort: 32044 name: web - protocol: TCP port: 8080 nodePort: 30423 name: admin type: NodePort 默认type: NodePort会随机指定一个对外服务端口，若需要设定指定的端口，要在ports里配置实际的nodePort kubectl get pods -n kube-system可以看到trafik-ingress-controller已启动 NAME READY STATUS RESTARTS AGE coredns-86c58d9df4-cffc8 1/1 Running 0 8h coredns-86c58d9df4-n5dsv 1/1 Running 0 8h etcd-minikube 1/1 Running 0 7h kube-addon-manager-minikube 1/1 Running 0 7h kube-apiserver-minikube 1/1 Running 0 7h kube-controller-manager-minikube 1/1 Running 0 7h kube-proxy-ltkl5 1/1 Running 0 8h kube-scheduler-minikube 1/1 Running 1 7h storage-provisioner 1/1 Running 0 8h traefik-ingress-controller-8c8b85bbc-9kn5p 1/1 Running 0 11m kubectl get services -n kube-system可以看到服务启动的ip和端口 NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kube-dns ClusterIP 10.96.0.10 53/UDP,53/TCP 7h traefik-ingress-service NodePort 10.98.51.165 80:32044/TCP,8080:30423/TCP 11m 访问$(minikube ip):32044可以看到当前对外端口返回的页面 访问$(minikube ip):30423可以看到当前Traefik的dashboard 配置服务路由 启动后端服务 kubectl apply -f cheese-deployments.yaml kubectl apply -f cheese-services.yaml kubectl get services可以看到，启动的TYPE都是ClusterIP，集群内部服务，不对外暴露端口 NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE cheddar ClusterIP 10.98.97.163 80/TCP 17s kubernetes ClusterIP 10.96.0.1 443/TCP 7h stilton ClusterIP 10.108.91.83 80/TCP 17s wensleydale ClusterIP 10.110.187.225 80/TCP 17s 通过Ingress建立路由规则：kubectl apply -f cheeses-ingress.yaml，配置如下： apiVersion: extensions/v1beta1 kind: Ingress metadata: name: cheeses annotations: traefik.frontend.rule.type: PathPrefixStrip spec: rules: - host: stilton.minikube http: paths: - path: / backend: serviceName: stilton servicePort: http - host: cheeses.minikube http: paths: - path: /cheddar backend: serviceName: cheddar servicePort: http - path: /wensleydale backend: serviceName: wensleydale servicePort: http kubectl describe ingress cheeses 查看 Ingress Name: cheeses Namespace: default Address: Default backend: default-http-backend:80 () Rules: Host Path Backends ---- ---- -------- stilton.minikube / stilton:http () cheeses.minikube /cheddar cheddar:http () /wensleydale wensleydale:http () Annotations: kubectl.kubernetes.io/last-applied-configuration: {\"apiVersion\":\"extensions/v1beta1\",\"kind\":\"Ingress\",\"metadata\":{\"annotations\":{\"traefik.frontend.rule.type\":\"PathPrefixStrip\"},\"name\":\"cheeses\",\"namespace\":\"default\"},\"spec\":{\"rules\":[{\"host\":\"stilton.minikube\",\"http\":{\"paths\":[{\"backend\":{\"serviceName\":\"stilton\",\"servicePort\":\"http\"},\"path\":\"/\"}]}},{\"host\":\"cheeses.minikube\",\"http\":{\"paths\":[{\"backend\":{\"serviceName\":\"cheddar\",\"servicePort\":\"http\"},\"path\":\"/cheddar\"},{\"backend\":{\"serviceName\":\"wensleydale\",\"servicePort\":\"http\"},\"path\":\"/wensleydale\"}]}}]}} traefik.frontend.rule.type: PathPrefixStrip Events: 添加dns: echo \"$(minikube ip) cheeses.minikube stilton.minikube\" | sudo tee -a /etc/hosts 开启rbac，授权角色访问dashboard权限kubectl apply -f traefik-rbac.yaml 访问$(minikube ip):30423查看当前Traefik的dashboard 访问以下地址，可以看到根据路由规则返回了相应的服务页面；访问其他地址会返回404 not found http://stilton.minikube:32044/ http://cheeses.minikube:32044/cheddar http://cheeses.minikube:32044/wensleydale Ingress 服务注册 当你启动一个新的服务时，可以通过Ingress将这个服务注册到相应的路由上去。 比如当你启动了一个名为cheddar的服务后，可以通过以下方式为它注册一条cheeses.minikube/cheddar的路由 $ cat cheddar-ingress.yaml apiVersion: extensions/v1beta1 kind: Ingress metadata: name: cheddar annotations: traefik.frontend.rule.type: PathPrefixStrip spec: rules: - host: cheeses.minikube http: paths: - path: /cheddar backend: serviceName: cheddar servicePort: http $ kubectl apply -f cheddar-ingress.yaml 注意： 当你需要通过cheddar-ingress更新cheddar服务的路由时；在执行kubectl apply -f cheddar-ingress.yaml的过程中，cheddar-ingress会中断导致路由不可用 若使用新的xxx-ingress.yaml注册路由时，存在一条和已有路由重复的路由；会将该路由对应的服务更新为新注册的服务； 更新过程中，该路由会中断 负载均衡 Traefik可以做到细粒度的负载均衡，适合做灰度发布。 比如我们现在有两个服务，cheddar和wensleydale，我们希望同一个入口75%的流量导向cheddar，25%的流量导向wensleydale，那么可以做以下配置 $ cat cheeses-ingress.yaml apiVersion: extensions/v1beta1 kind: Ingress metadata: name: cheeses annotations: kubernetes.io/ingress.class: traefik traefik.frontend.rule.type: PathPrefixStrip traefik.ingress.kubernetes.io/service-weights: | cheddar: 75% wensleydale: 25% spec: rules: - host: cheeses.minikube http: paths: - path: / backend: serviceName: cheddar servicePort: http - path: / backend: serviceName: wensleydale servicePort: http $ kubectl apply -f cheeses-ingress.yaml 接下来批量访问cheeses.minikube:32044/，就会发现流量按照比例被导入到两个服务上去了 Traefik也支持默认自动配置。比如上面这个例子，如果你只配置了wensleydale: 25%，即便不配置cheddar: 75%，Traefik也会把余下75%的流量自动导入到cheddar上去。 配置服务优先级 Traefik-Ingress路由默认采用最长路径匹配原则，比如以下两个Ingress都使用前缀匹配 $ cat cheddar-ingress.yaml apiVersion: extensions/v1beta1 kind: Ingress metadata: name: cheddar annotations: kubernetes.io/ingress.class: traefik traefik.frontend.rule.type: PathPrefixStrip spec: rules: - host: cheeses.minikube http: paths: - path: /cheddar backend: serviceName: cheddar servicePort: http $ cat wensleydale-ingress.yaml apiVersion: extensions/v1beta1 kind: Ingress metadata: name: wensleydale annotations: kubernetes.io/ingress.class: traefik traefik.frontend.rule.type: PathPrefixStrip spec: rules: - host: cheeses.minikube http: paths: - path: /cheddar/wensleydale backend: serviceName: wensleydale servicePort: http 我们载入这两个Ingress：kubectl apply -f cheddar-ingress.yaml，kubectl apply -f wensleydale-ingress.yaml，当你访问cheeses.minikube:32044/cheddar/wensleydale/xxx时，请求会被分发到wensleydale服务上。 我们可以通过配置指定路由优先级，使用traefik.ingress.kubernetes.io/priority，对应的值越大，优先级越高。 $ cat cheddar-ingress.yaml apiVersion: extensions/v1beta1 kind: Ingress metadata: name: cheddar annotations: kubernetes.io/ingress.class: traefik traefik.frontend.rule.type: PathPrefixStrip traefik.ingress.kubernetes.io/priority: \"2\" spec: rules: - host: cheeses.minikube http: paths: - path: /cheddar backend: serviceName: cheddar servicePort: http $ cat wensleydale-ingress.yaml apiVersion: extensions/v1beta1 kind: Ingress metadata: name: wensleydale annotations: kubernetes.io/ingress.class: traefik traefik.frontend.rule.type: PathPrefixStrip traefik.ingress.kubernetes.io/priority: \"1\" spec: rules: - host: cheeses.minikube http: paths: - path: /cheddar/wensleydale backend: serviceName: wensleydale servicePort: http 此时访问cheeses.minikube:32044/cheddar/wensleydale/xxx时，请求会被分发到cheddar服务上。 参考链接 traefik kubernetes user guide traefik ingress provider kubernetes ingress kubernetes官网 kubernetes中文手册 例程1 例程2 TODO apply的时候是否会中断服务: 见 3. Ingress服务注册 版本快速切换做不到了 前置lbc或nginx 日志 进入traefik pods 没有各种sh rule reg opentracing ConfigMap deployment keepalive "},"network/chunk.html":{"url":"network/chunk.html","title":"I. HTTP协议之chunk(分块传输编码)","keywords":"","body":"HTTP协议之chunk(分块传输编码) 分块传输编码 分块传输编码（Chunked transfer encoding）是超文本传输协议（HTTP）中的一种数据传输机制，允许HTTP由应用服务器发送给客户端应用（通常是网页浏览器）的数据可以分成多个部分。在HTTP协议1.1版本（HTTP/1.1）中提供。 通常，HTTP应答消息中发送的数据是整个发送的，Content-Length消息头字段表示数据的长度。数据的长度很重要，因为客户端需要知道哪里是应答消息的结束，以及后续应答消息的开始。然而，使用分块传输编码，数据分解成一系列数据块，并以一个或多个块流式传输，这样服务器可以发送数据而不需要预先知道发送内容的总大小。 HTTP 1.1引入分块传输编码提供了以下几点好处： HTTP分块传输编码允许服务器为动态生成的内容维持HTTP持久链接。通常，持久链接需要服务器在开始发送消息体前发送Content-Length消息头字段，但是对于动态生成的内容来说，在内容创建完之前是不可知的。 分块传输编码允许服务器在最后发送消息头字段。对于那些头字段值在内容被生成之前无法知道的情形非常重要，例如消息的内容要使用散列进行签名，散列的结果通过HTTP消息头字段进行传输。没有分块传输编码时，服务器必须缓冲内容直到完成后计算头字段的值并在发送内容前发送这些头字段的值。 HTTP服务器有时使用压缩以缩短传输花费的时间。分块传输编码可以用来分隔压缩对象的多个部分。在这种情况下，块不是分别压缩的，而是整个负载进行压缩，压缩的输出使用本文描述的方案进行分块传输。在压缩的情形中，分块编码有利于一边进行压缩一边发送数据，而不是先完成压缩过程以得知压缩后数据的大小。 分块传输编码的格式： 如果一个HTTP消息（请求消息或应答消息）的Transfer-Encoding消息头的值为chunked，那么，消息体由数量未定的块组成，并以最后一个大小为0的块为结束。传输过程中的消息头没有Content-Length字段 每一个非空的块都以该块包含数据的字节数（字节数以十六进制表示）开始，跟随一个CRLF（回车及换行），然后是数据本身，最后块CRLF结束。在一些实现中，块大小和CRLF之间填充有白空格（0x20）。 最后一块是单行，由块大小（0），一些可选的填充白空格，以及CRLF。最后一块不再包含任何数据，但是可以发送可选的尾部，包括消息头字段。消息最后以CRLF结尾。 golang http server 与 chunk golang http 包中，处理请求返回的response结构体里，用于写入body的Writer是一个chunkWriter。我们可以通过官方包net/http/server.go: func (c *conn) readRequest(ctx context.Context) (w *response, err error)方法看到： 这里使用w.cw(定义为response.chunkWriter)生成一个*bufio.Writer，设定buffer大小为bufferBeforeChunkingSize，并赋值给w.w(定义为response.Writer)。在http包中，bufferBeforeChunkingSize的值为2048 因此，当返回的response写入的内容超过2048个字节时，golang的http包底层会自动进行分块传输编码(chunk)。这里我们可以通过一个简单的demo来验证一下： package main import ( \"bytes\" \"log\" \"net/http\" ) func main() { handler := func(w http.ResponseWriter, req *http.Request) { unitByte := []byte(\"1\") w.Write(bytes.Repeat(unitByte, 2049)) } http.HandleFunc(\"/test_chunked\", handler) log.Fatal(http.ListenAndServe(\":8080\", nil)) } 这里我们返回2049个字符。访问127.0.0.1:8080/test_chunked，看一下返回的消息头 可以看到，当返回的传输字节超过2048时，服务端的返回默认使用了分块传输编码，头部不包含Content-Length。 对于\"Transfer-Encoding\"为chunked的response，golang的http包会在WriteBody时自动补上分块传输编码分隔的CRLF换行符；客户端收到response后按照分块传输编码，解码拼接成完整的报文。 接下来，我们将返回body的内容设置为为2048个字节 w.Write(bytes.Repeat(unitByte, 2048)) 看一下修改后返回的消息头 可以看到，返回的消息头里明确设定了Content-Length，采用正常整包传输。 自动chunk可能带来的问题 服务端返回chunked报文时需要考虑接收方是否能够正确解析。比如接收方使用低版本的python httplib包发起请求，就可能因返回报文头部没有确切的报文长度而导致解析失败 File \"entities/common_server/Lib/httplib.py\", line 588, in read return self._read_chunked(amt) File \"entities/common_server/Lib/httplib.py\", line 642, in _read_chunked raise IncompleteRead(''.join(value)) httplib.IncompleteRead: IncompleteRead(0 bytes read) 由于分块传输编码是HTTP/1.1后新增的功能，一些低版本的程序支持HTTP/1.0，但是对HTTP/1.1没有很好的支持，就可能导致解析分块传输报文失败。 设置golang http服务器是否chunk 虽然golang底层帮我们做了报文自动chunk，但是我们能不能根据服务器的实际需要，显式地设定返回报文是否chunk呢？答案是肯定的。 以上是golang http官方包对response的写接口Write的生存周期说明。服务器默认写入body的时候，是没有设定Content-Length的；如果传输的body长度不超过chunking buffer size(2048字节)，http包会根据自动计算的body长度设定Content-Length，进行整包传输；如果超过了2048字节，就会进行分块传输。 设置no-chunk 通过官方包net/http/transfer.go: func newTransferWriter(r interface{}) (t *transferWriter, err error)方法可以看到，设定chunked的一个首要条件是t.ContentLength 。golang http包对t.ContentLength的值是按照以下顺序进行设置的： 若Body为空，则设为0 若设定了头部的\"Content-Length\"，则使用设定的\"Content-Length\"（当设定的Content-Length和实际写入的Body大小不一致时，在调用net/http/transfer.go: func (t *transferWriter) WriteBody(w io.Writer) error方法写入body时会报错） 若没有设定头部的\"Content-Length\"，则设为-1 因此，只要我们显式地设置http返回头部的\"Content-Length\"，就可以让golang服务器不进行分块传输。 package main import ( \"bytes\" \"log\" \"net/http\" \"strconv\" ) func main() { handler := func(w http.ResponseWriter, req *http.Request) { body := bytes.Repeat([]byte(\"1\"), 2049) w.Header().Set(\"Content-Length\", strconv.Itoa(len(body))) w.Write(body) } http.HandleFunc(\"/test_chunked\", handler) log.Fatal(http.ListenAndServe(\":8080\", nil)) } 这里我们通过w.Header().Set(\"Content-Length\", strconv.Itoa(len(body)))的方法设定了头部长度。访问127.0.0.1:8080/test_chunked，看一下返回的消息头 可以看到，虽然body长度超过了2048，但是返回的消息仍然采用了整包传输(没有设定chunked) 设置chunk http头部的chunked设置，是golang http包底层是否采用分块传输的依据。golang http包默认对2048字节以上的body做分块传输，那么如果我们想要对2048字节以下的body也进行分块传输，只要显式地设置http返回头部的\"Transfer-Encoding\"为chunked即可。 package main import ( \"bytes\" \"log\" \"net/http\" ) func main() { handler := func(w http.ResponseWriter, req *http.Request) { body := bytes.Repeat([]byte(\"1\"), 2047) w.Header().Set(\"Transfer-Encoding\", \"chunked\") w.Write(body) } http.HandleFunc(\"/test_chunked\", handler) log.Fatal(http.ListenAndServe(\":8080\", nil)) } 这里我们返回的body长度只有2047(127.0.0.1:8080/test_chunked，看一下返回的消息头 可以看到，这里使用了分块传输编码，头部不设定\"Content-Length\"。 总结 HTTP/1.1中引入了更高效的数据传输方式 —— 分块传输编码。 golang的http包在传输数据body超过2048字节时，会自动采用分块传输编码(chunk)。 当显式地设置response头部的\"Content-Length\"后，golang将强制采用整包传输，不会使用分块传输编码。 当显式地设置response头部的\"Transfer-Encoding\"为chunked后，golang将强制采用分块传输编码。 参考链接: wiki: 分块传输编码 "}}